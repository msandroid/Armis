# æœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ (Text Extraction Feature)

## æ¦‚è¦

ã“ã®æ©Ÿèƒ½ã¯ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰TTSï¼ˆText-to-Speechï¼‰ã«æ¸¡ã™ã¹ãæœ¬æ–‡éƒ¨åˆ†ã‚’é©åˆ‡ã«æŠ½å‡ºã™ã‚‹ãŸã‚ã®LangChainãƒ™ãƒ¼ã‚¹ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œèª¬æ˜æ–‡ã‚„è§£èª¬æ–‡ãªã©ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã€ã‚’å…¥åŠ›ã—ãŸéš›ã«ã€æŒ‡ç¤ºæ–‡ã‚„èª¬æ˜æ–‡ã‚’é™¤ã„ã¦ã€ŒéŸ³å£°åŒ–ã™ã¹ãæœ¬æ–‡éƒ¨åˆ†ã€ã®ã¿ã‚’æŠ½å‡ºã—ã€TTSå‡¦ç†ã«æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ã€‚

**æ–°æ©Ÿèƒ½**: llama.cppå¯¾å¿œã«ã‚ˆã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã‚‚æœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€OpenAIã®gpt-ossãƒ¢ãƒ‡ãƒ«ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

## ä¸»è¦æ©Ÿèƒ½

### 1. TextExtractionChain
- **ç›®çš„**: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ¬æ–‡éƒ¨åˆ†ã‚’æŠ½å‡º
- **ç‰¹å¾´**: 
  - LangChainã®LLMChain + OutputParserã‚’ä½¿ç”¨
  - æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ï¼ˆJSONå½¢å¼ï¼‰
  - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ã
  - è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¯¾å¿œï¼ˆOpenAIã€Anthropicã€Googleï¼‰

### 2. TextExtractionAgent
- **ç›®çš„**: æœ¬æ–‡æŠ½å‡ºã¨TTSç”Ÿæˆã‚’çµ±åˆã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- **ç‰¹å¾´**:
  - LangChainã®Agent + Toolsæ§‹æˆ
  - è‡ªå‹•çš„ãªæŠ½å‡ºâ†’TTSå‡¦ç†ãƒ•ãƒ­ãƒ¼
  - é«˜åº¦ãªåˆ¶å¾¡ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### 3. æ‹¡å¼µã•ã‚ŒãŸTTSRequestAnalyzer
- **ç›®çš„**: æ—¢å­˜ã®TTSãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ†ææ©Ÿèƒ½ã‚’æ‹¡å¼µ
- **ç‰¹å¾´**:
  - TextExtractionChainã¨ã®çµ±åˆ
  - ã‚ˆã‚Šé«˜ç²¾åº¦ãªæœ¬æ–‡æŠ½å‡º
  - å¾Œæ–¹äº’æ›æ€§ã®ç¶­æŒ

### 4. ğŸ†• LlamaCppTextExtractionChain
- **ç›®çš„**: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ä½¿ç”¨ã—ãŸæœ¬æ–‡æŠ½å‡º
- **ç‰¹å¾´**:
  - llama.cpp + GGUFãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
  - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã®æœ¬æ–‡æŠ½å‡º
  - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·
  - ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªè¨­å®š

### 5. ğŸ†• LlamaCppTextExtractionAgent
- **ç›®çš„**: ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ä½¿ç”¨ã—ãŸçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- **ç‰¹å¾´**:
  - llama.cpp + Agentæ§‹æˆ
  - ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®æŠ½å‡ºâ†’TTSå‡¦ç†
  - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å°‚ç”¨

### 6. ğŸ†• LlamaCppBackendService
- **ç›®çš„**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆã‚µãƒ¼ãƒ“ã‚¹
- **ç‰¹å¾´**:
  - Electron/Node.jsã‚µãƒ¼ãƒãƒ¼å¯¾å¿œ
  - çµ±åˆã•ã‚ŒãŸAPI
  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
  - çŠ¶æ…‹ç®¡ç†

### 7. ğŸ†• GptOssTextExtractionChain
- **ç›®çš„**: OpenAIã®gpt-ossãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæœ¬æ–‡æŠ½å‡º
- **ç‰¹å¾´**:
  - gpt-oss-20bå¯¾å¿œï¼ˆç´„20Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
  - æ¨è«–ãƒ¬ãƒ™ãƒ«è¨­å®šï¼ˆlow/medium/highï¼‰
  - é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼ˆ8192ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
  - OpenAIç¤¾å†…ãƒ¢ãƒ‡ãƒ«ã€Œo3-miniã€ã¨åŒç­‰ã®æ€§èƒ½

### 8. ğŸ†• GptOssTextExtractionAgent
- **ç›®çš„**: gpt-ossãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
- **ç‰¹å¾´**:
  - gpt-oss + Agentæ§‹æˆ
  - æ¨è«–ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå‡¦ç†
  - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å°‚ç”¨

### 9. ğŸ†• GptOssBackendService
- **ç›®çš„**: gpt-ossãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆã‚µãƒ¼ãƒ“ã‚¹
- **ç‰¹å¾´**:
  - gpt-osså°‚ç”¨ã®æœ€é©åŒ–
  - æ¨è«–ãƒ¬ãƒ™ãƒ«åˆ¶å¾¡
  - é«˜æ€§èƒ½ãªæœ¬æ–‡æŠ½å‡º

## å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«

```
src/services/tts/
â”œâ”€â”€ text-extraction-chain.ts              # æœ¬æ–‡æŠ½å‡ºç”¨Chainï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼‰
â”œâ”€â”€ text-extraction-agent.ts              # æœ¬æ–‡æŠ½å‡ºç”¨Agentï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼‰
â”œâ”€â”€ llama-cpp-text-extraction-chain.ts    # æœ¬æ–‡æŠ½å‡ºç”¨Chainï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMï¼‰
â”œâ”€â”€ llama-cpp-text-extraction-agent.ts    # æœ¬æ–‡æŠ½å‡ºç”¨Agentï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMï¼‰
â”œâ”€â”€ llama-cpp-backend-service.ts          # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆã‚µãƒ¼ãƒ“ã‚¹
â”œâ”€â”€ gpt-oss-text-extraction-chain.ts      # æœ¬æ–‡æŠ½å‡ºç”¨Chainï¼ˆgpt-ossï¼‰
â”œâ”€â”€ gpt-oss-text-extraction-agent.ts      # æœ¬æ–‡æŠ½å‡ºç”¨Agentï¼ˆgpt-ossï¼‰
â”œâ”€â”€ gpt-oss-backend-service.ts            # gpt-ossãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆã‚µãƒ¼ãƒ“ã‚¹
â”œâ”€â”€ tts-request-analyzer.ts               # æ‹¡å¼µã•ã‚ŒãŸTTSãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ†æ
â””â”€â”€ index.ts                              # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®šç¾©

src/examples/
â”œâ”€â”€ text-extraction-example.ts            # ã‚¯ãƒ©ã‚¦ãƒ‰LLMä½¿ç”¨ä¾‹
â”œâ”€â”€ text-extraction-test.ts               # ãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ llama-cpp-text-extraction-example.ts  # ãƒ­ãƒ¼ã‚«ãƒ«LLMä½¿ç”¨ä¾‹
â”œâ”€â”€ llama-cpp-backend-example.ts          # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆä¾‹
â”œâ”€â”€ llama-cpp-environment-check.ts        # ç’°å¢ƒãƒã‚§ãƒƒã‚¯
â”œâ”€â”€ gpt-oss-text-extraction-example.ts    # gpt-ossä½¿ç”¨ä¾‹
â””â”€â”€ gpt-oss-environment-check.ts          # gpt-ossç’°å¢ƒãƒã‚§ãƒƒã‚¯
```

## ä½¿ç”¨æ–¹æ³•

### ã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼ˆOpenAIã€Anthropicã€Googleï¼‰

#### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```typescript
import { createTextExtractionChain } from '../services/tts'

// TextExtractionChainã®ä½œæˆ
const extractionChain = createTextExtractionChain({
  modelType: 'openai',
  modelName: 'gpt-3.5-turbo',
  temperature: 0.1,
  apiKey: 'your-api-key'
})

// åˆæœŸåŒ–
await extractionChain.initialize()

// æœ¬æ–‡æŠ½å‡º
const result = await extractionChain.extractMainText(inputText)
console.log('Extracted Text:', result.mainText)
console.log('Confidence:', result.confidence)
```

#### Agentã‚’ä½¿ç”¨ã—ãŸä¾‹

```typescript
import { createTextExtractionAgent } from '../services/tts'

// TextExtractionAgentã®ä½œæˆ
const extractionAgent = createTextExtractionAgent({
  modelType: 'openai',
  modelName: 'gpt-3.5-turbo',
  temperature: 0.1,
  apiKey: 'your-api-key',
  maxIterations: 3,
  verbose: true
})

// åˆæœŸåŒ–
await extractionAgent.initialize()

// ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ï¼ˆæŠ½å‡º + TTSç”Ÿæˆï¼‰
const result = await extractionAgent.processText(inputText)
console.log('Extracted Text:', result.extractedText)
console.log('TTS Result:', result.ttsResult)
```

### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆllama.cppï¼‰

#### å‰ææ¡ä»¶

1. **å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**:
```bash
npm install node-llama-cpp@3 @langchain/community
```

2. **GGUFãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«**:
```bash
# ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir models

# GGUFãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼‰
# - llama-2-7b-chat.gguf
# - llama-2-13b-chat.gguf
# - mistral-7b-instruct-v0.2.gguf
# - qwen2-7b-instruct.gguf
```

3. **ç’°å¢ƒãƒã‚§ãƒƒã‚¯**:
```bash
npx tsx src/examples/llama-cpp-environment-check.ts
```

### ğŸ†• OpenAI gpt-ossãƒ¢ãƒ‡ãƒ«

#### å‰ææ¡ä»¶

1. **å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**:
```bash
npm install node-llama-cpp@3 @langchain/community
```

2. **gpt-ossãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«**:
```bash
# ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir models

# gpt-ossãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# æ¨å¥¨: gpt-oss-20b-mxfp4.gguf (~15GB)
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ƒ: https://huggingface.co/ggml-org/gpt-oss-20b-GGUF
```

3. **ç’°å¢ƒãƒã‚§ãƒƒã‚¯**:
```bash
npx tsx src/examples/gpt-oss-environment-check.ts
```

#### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```typescript
import { createLlamaCppTextExtractionChain } from '../services/tts'

// LlamaCppTextExtractionChainã®ä½œæˆ
const extractionChain = createLlamaCppTextExtractionChain({
  modelPath: './models/llama-2-7b-chat.gguf',
  temperature: 0.1,
  maxTokens: 2048,
  contextSize: 4096,
  threads: 4,
  gpuLayers: 0,
  verbose: true
})

// åˆæœŸåŒ–
await extractionChain.initialize()

// æœ¬æ–‡æŠ½å‡º
const result = await extractionChain.extractMainText(inputText)
console.log('Extracted Text:', result.mainText)
console.log('Confidence:', result.confidence)
```

#### Agentã‚’ä½¿ç”¨ã—ãŸä¾‹

```typescript
import { createLlamaCppTextExtractionAgent } from '../services/tts'

// LlamaCppTextExtractionAgentã®ä½œæˆ
const extractionAgent = createLlamaCppTextExtractionAgent({
  modelPath: './models/llama-2-7b-chat.gguf',
  temperature: 0.1,
  maxTokens: 2048,
  contextSize: 4096,
  threads: 4,
  gpuLayers: 0,
  verbose: true,
  maxIterations: 3
})

// åˆæœŸåŒ–
await extractionAgent.initialize()

// ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ï¼ˆæŠ½å‡º + TTSç”Ÿæˆï¼‰
const result = await extractionAgent.processText(inputText)
console.log('Extracted Text:', result.extractedText)
console.log('TTS Result:', result.ttsResult)
```

#### ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆ

```typescript
import { createLlamaCppBackendService } from '../services/tts'

// ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã®ä½œæˆ
const backendService = createLlamaCppBackendService({
  modelPath: './models/llama-2-7b-chat.gguf',
  temperature: 0.1,
  maxTokens: 2048,
  contextSize: 4096,
  threads: 4,
  gpuLayers: 0,
  verbose: false,
  maxIterations: 3
})

// åˆæœŸåŒ–
await backendService.initialize()

// æœ¬æ–‡æŠ½å‡º
const result = await backendService.extractText({
  text: inputText,
  useAgent: false,
  batchMode: false
})

if (result.success) {
  console.log('Extracted Text:', result.data.mainText)
  console.log('Execution Time:', result.executionTime, 'ms')
}
```

#### ğŸ†• gpt-ossãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ä¾‹

```typescript
import { createGptOssTextExtractionChain } from '../services/tts'

// GptOssTextExtractionChainã®ä½œæˆ
const extractionChain = createGptOssTextExtractionChain({
  modelPath: './models/gpt-oss-20b-mxfp4.gguf',
  temperature: 0.1,
  maxTokens: 2048,
  contextSize: 8192, // gpt-oss-20bã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆ
  threads: 4,
  gpuLayers: 0,
  verbose: true,
  reasoningLevel: 'medium' // æ¨è«–ãƒ¬ãƒ™ãƒ«è¨­å®š
})

// åˆæœŸåŒ–
await extractionChain.initialize()

// æœ¬æ–‡æŠ½å‡º
const result = await extractionChain.extractMainText(inputText)
console.log('Extracted Text:', result.mainText)
console.log('Confidence:', result.confidence)
console.log('Reasoning:', result.reasoning)
```

#### ğŸ†• gpt-ossãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆ

```typescript
import { createGptOssBackendService } from '../services/tts'

// gpt-ossãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã®ä½œæˆ
const backendService = createGptOssBackendService({
  modelPath: './models/gpt-oss-20b-mxfp4.gguf',
  temperature: 0.1,
  maxTokens: 2048,
  contextSize: 8192,
  threads: 4,
  gpuLayers: 0,
  verbose: false,
  maxIterations: 3,
  reasoningLevel: 'medium'
})

// åˆæœŸåŒ–
await backendService.initialize()

// æœ¬æ–‡æŠ½å‡ºï¼ˆæ¨è«–ãƒ¬ãƒ™ãƒ«æŒ‡å®šï¼‰
const result = await backendService.extractText({
  text: inputText,
  useAgent: false,
  batchMode: false,
  reasoningLevel: 'high' // å‹•çš„ã«æ¨è«–ãƒ¬ãƒ™ãƒ«ã‚’å¤‰æ›´
})

if (result.success) {
  console.log('Extracted Text:', result.data.mainText)
  console.log('Execution Time:', result.executionTime, 'ms')
  console.log('Reasoning Level:', result.modelInfo?.reasoningLevel)
}
```

### æ—¢å­˜ã®TTSRequestAnalyzerã¨ã®çµ±åˆ

#### ã‚¯ãƒ©ã‚¦ãƒ‰LLM

```typescript
import { createTTSRequestAnalyzer } from '../services/tts'

// TTSRequestAnalyzerã®ä½œæˆï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰LLMï¼‰
const analyzer = createTTSRequestAnalyzer({
  apiKey: 'your-api-key'
})

// åˆ†æå®Ÿè¡Œ
const analysis = await analyzer.analyzeTTSRequest(inputText)
console.log('TTS Text:', analysis.ttsText)
console.log('Extracted Data:', analysis.extractedData)
```

#### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLM

```typescript
import { createTTSRequestAnalyzer } from '../services/tts'

// TTSRequestAnalyzerã®ä½œæˆï¼ˆllama.cppï¼‰
const analyzer = createTTSRequestAnalyzer({
  useLlamaCpp: true,
  llamaCppConfig: {
    modelPath: './models/llama-2-7b-chat.gguf',
    temperature: 0.1,
    maxTokens: 2048,
    contextSize: 4096,
    threads: 4,
    gpuLayers: 0,
    verbose: false
  }
})

// åˆ†æå®Ÿè¡Œ
const analysis = await analyzer.analyzeTTSRequest(inputText)
console.log('TTS Text:', analysis.ttsText)
console.log('Extracted Data:', analysis.extractedData)
```

#### ğŸ†• gpt-ossãƒ¢ãƒ‡ãƒ«

```typescript
import { createTTSRequestAnalyzer } from '../services/tts'

// TTSRequestAnalyzerã®ä½œæˆï¼ˆgpt-ossï¼‰
const analyzer = createTTSRequestAnalyzer({
  useGptOss: true,
  gptOssConfig: {
    modelPath: './models/gpt-oss-20b-mxfp4.gguf',
    temperature: 0.1,
    maxTokens: 2048,
    contextSize: 8192,
    threads: 4,
    gpuLayers: 0,
    verbose: false,
    reasoningLevel: 'medium'
  }
})

// åˆ†æå®Ÿè¡Œ
const analysis = await analyzer.analyzeTTSRequest(inputText)
console.log('TTS Text:', analysis.ttsText)
console.log('Extracted Data:', analysis.extractedData)
```

## å…¥åŠ›ä¾‹ã¨å‡ºåŠ›ä¾‹

### å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
```
ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¨ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°æ™‚ä»£ï¼ˆViking Ageã€800å¹´ - 1050å¹´ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ç´„250å¹´é–“ã«è¥¿ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘æ²¿æµ·éƒ¨ã‚’ä¾µç•¥ã—ãŸã‚¹ã‚«ãƒ³ãƒ‡ã‚£ãƒŠãƒ´ã‚£ã‚¢ã€ãƒãƒ«ãƒˆæµ·æ²¿å²¸åœ°åŸŸã®æ­¦è£…é›†å›£ã‚’æŒ‡ã™è¨€è‘‰ã€‚é€šä¿—çš„ã«ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯è§’ã®ã‚ã‚‹å…œã‚’è¢«ã£ãŸæµ·è³Šã‚„ç•¥å¥ªã‚’åƒãæˆ¦å£«ã§ã‚ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯å¾Œä¸–ã®æƒ³åƒã®å½±éŸ¿ãŒå¼·ãã€å®Ÿéš›ã«ã¯ç•¥å¥ªã‚’å°‚æ¥­ã¨ã—ã¦ã„ãŸã®ã§ã¯ãªãäº¤æ˜“æ°‘ã§ã‚‚ã‚ã‚Šã€æ•…åœ°ã«ãŠã„ã¦ã¯è¾²æ°‘ã§ã‚ã‚Šæ¼æ°‘ã§ã‚ã£ãŸã€‚å„åœ°ã«é€²å‡ºã—ã€åŒ—ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®æ­´å²ã«å¤§ããªå½±éŸ¿ã‚’æ®‹ã—ãŸãŒã€æ¬¡ç¬¬ã«å„åœ°ã«åœŸç€ã—ã¦ã‚†ãã¨ã¨ã‚‚ã«æµ·ä¸Šã®æ°‘ã¨ã—ã¦ã®æ€§æ ¼ã‚’å¤±ã„ã€13ä¸–ç´€ã¾ã§ã«ã¯ã€æ®†ã©ã®ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯æ¶ˆæ»…ã—ãŸã€‚ä¸Šè¨˜ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚
```

### æŠ½å‡ºçµæœ
```json
{
  "mainText": "ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¨ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°æ™‚ä»£ï¼ˆViking Ageã€800å¹´ - 1050å¹´ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ç´„250å¹´é–“ã«è¥¿ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘æ²¿æµ·éƒ¨ã‚’ä¾µç•¥ã—ãŸã‚¹ã‚«ãƒ³ãƒ‡ã‚£ãƒŠãƒ´ã‚£ã‚¢ã€ãƒãƒ«ãƒˆæµ·æ²¿å²¸åœ°åŸŸã®æ­¦è£…é›†å›£ã‚’æŒ‡ã™è¨€è‘‰ã€‚é€šä¿—çš„ã«ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯è§’ã®ã‚ã‚‹å…œã‚’è¢«ã£ãŸæµ·è³Šã‚„ç•¥å¥ªã‚’åƒãæˆ¦å£«ã§ã‚ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯å¾Œä¸–ã®æƒ³åƒã®å½±éŸ¿ãŒå¼·ãã€å®Ÿéš›ã«ã¯ç•¥å¥ªã‚’å°‚æ¥­ã¨ã—ã¦ã„ãŸã®ã§ã¯ãªãäº¤æ˜“æ°‘ã§ã‚‚ã‚ã‚Šã€æ•…åœ°ã«ãŠã„ã¦ã¯è¾²æ°‘ã§ã‚ã‚Šæ¼æ°‘ã§ã‚ã£ãŸã€‚å„åœ°ã«é€²å‡ºã—ã€åŒ—ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®æ­´å²ã«å¤§ããªå½±éŸ¿ã‚’æ®‹ã—ãŸãŒã€æ¬¡ç¬¬ã«å„åœ°ã«åœŸç€ã—ã¦ã‚†ãã¨ã¨ã‚‚ã«æµ·ä¸Šã®æ°‘ã¨ã—ã¦ã®æ€§æ ¼ã‚’å¤±ã„ã€13ä¸–ç´€ã¾ã§ã«ã¯ã€æ®†ã©ã®ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯æ¶ˆæ»…ã—ãŸã€‚",
  "confidence": 0.95,
  "reasoning": "ã€Œä¸Šè¨˜ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€ã¨ã„ã†æ˜ç¢ºãªTTSæŒ‡ç¤ºãŒã‚ã‚Šã€ãã®å‰ã®éƒ¨åˆ†ãŒæœ¬æ–‡ã¨ã—ã¦æŠ½å‡ºã§ãã‚‹ã€‚",
  "hasInstructions": true,
  "instructionType": "tts_request"
}
```

## æŠ€è¡“ä»•æ§˜

### å¯¾å¿œLLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼

#### ã‚¯ãƒ©ã‚¦ãƒ‰LLM
- **OpenAI**: GPT-3.5-turbo, GPT-4
- **Anthropic**: Claude-3-sonnet, Claude-3-haiku
- **Google**: Gemini Pro

#### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆllama.cppï¼‰
- **Llama 2**: 7B, 13B, 70B
- **Mistral**: 7B Instruct
- **Qwen2**: 7B Instruct
- **Gemma**: 2B, 7B, 9B
- **CodeLlama**: 7B, 13B, 34B
- **ãã®ä»–**: GGUFå½¢å¼å¯¾å¿œãƒ¢ãƒ‡ãƒ«

#### ğŸ†• OpenAI gpt-ossãƒ¢ãƒ‡ãƒ«
- **gpt-oss-20b**: ç´„20Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ¨å¥¨ï¼‰
- **gpt-oss-120b**: ç´„120Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¤§è¦æ¨¡ï¼‰
- **ç‰¹å¾´**: OpenAIç¤¾å†…ãƒ¢ãƒ‡ãƒ«ã€Œo3-miniã€ã¨åŒç­‰ã®æ€§èƒ½
- **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: Apache 2.0
- **çŸ¥è­˜ã‚«ãƒƒãƒˆã‚ªãƒ•**: 2024å¹´6æœˆ

### æŠ½å‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
1. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º**: TTSé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡º
2. **LLMè§£æ**: é«˜åº¦ãªè‡ªç„¶è¨€èªå‡¦ç†ã«ã‚ˆã‚‹æœ¬æ–‡æŠ½å‡º
3. **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: LLMãŒåˆ©ç”¨ã§ããªã„å ´åˆã®åŸºæœ¬çš„ãªæŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯

### å‡ºåŠ›å½¢å¼
```typescript
interface ExtractedText {
  mainText: string                    // æŠ½å‡ºã•ã‚ŒãŸæœ¬æ–‡
  confidence: number                  // æŠ½å‡ºã®ä¿¡é ¼åº¦ï¼ˆ0-1ï¼‰
  reasoning: string                   // æŠ½å‡ºç†ç”±
  hasInstructions: boolean           // æŒ‡ç¤ºæ–‡ã®æœ‰ç„¡
  instructionType?: 'tts_request' | 'explanation' | 'other'  // æŒ‡ç¤ºæ–‡ã®ç¨®é¡
}
```

## ãƒ†ã‚¹ãƒˆ

### ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

#### ã‚¯ãƒ©ã‚¦ãƒ‰LLM
```bash
# åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆ
npx tsx src/examples/text-extraction-test.ts

# å®Œå…¨ãªãƒ‡ãƒ¢ï¼ˆAPIã‚­ãƒ¼ãŒå¿…è¦ï¼‰
npx tsx src/examples/text-extraction-example.ts
```

#### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLM
```bash
# ç’°å¢ƒãƒã‚§ãƒƒã‚¯
npx tsx src/examples/llama-cpp-environment-check.ts

# ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ‡ãƒ¢ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ï¼‰
npx tsx src/examples/llama-cpp-text-extraction-example.ts

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆãƒ‡ãƒ¢
npx tsx src/examples/llama-cpp-backend-example.ts
```

#### ğŸ†• gpt-ossãƒ¢ãƒ‡ãƒ«
```bash
# ç’°å¢ƒãƒã‚§ãƒƒã‚¯
npx tsx src/examples/gpt-oss-environment-check.ts

# gpt-ossãƒ‡ãƒ¢ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ï¼‰
npx tsx src/examples/gpt-oss-text-extraction-example.ts
```

### ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
- ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã®èª¬æ˜æ–‡ï¼ˆé•·æ–‡ + TTSæŒ‡ç¤ºï¼‰
- ã‚·ãƒ³ãƒ—ãƒ«ãªTTSè¦æ±‚
- æŒ‡ç¤ºæ–‡ãªã—ã®ãƒ†ã‚­ã‚¹ãƒˆ
- è¤‡é›‘ãªèª¬æ˜æ–‡

## è¨­å®š

### ç’°å¢ƒå¤‰æ•°

#### ã‚¯ãƒ©ã‚¦ãƒ‰LLM
```bash
# OpenAI
OPENAI_API_KEY=your-openai-api-key

# Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key

# Google
GOOGLE_API_KEY=your-google-api-key
```

#### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLM
```bash
# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
LLAMA_MODEL_PATH=./models/llama-2-7b-chat.gguf

# ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
LLAMA_THREADS=4
LLAMA_CONTEXT_SIZE=4096
LLAMA_GPU_LAYERS=0
```

#### ğŸ†• gpt-ossãƒ¢ãƒ‡ãƒ«
```bash
# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
GPTOSS_MODEL_PATH=./models/gpt-oss-20b-mxfp4.gguf

# ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
GPTOSS_THREADS=4
GPTOSS_CONTEXT_SIZE=8192
GPTOSS_GPU_LAYERS=0
GPTOSS_REASONING_LEVEL=medium
```

### è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

#### ã‚¯ãƒ©ã‚¦ãƒ‰LLM
```typescript
interface TextExtractionConfig {
  modelType: 'openai' | 'anthropic' | 'google'
  modelName?: string
  temperature?: number
  apiKey?: string
}
```

#### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLM
```typescript
interface LlamaCppTextExtractionConfig {
  modelPath: string
  temperature?: number
  maxTokens?: number
  contextSize?: number
  threads?: number
  gpuLayers?: number
  verbose?: boolean
}
```

#### ğŸ†• gpt-ossãƒ¢ãƒ‡ãƒ«
```typescript
interface GptOssTextExtractionConfig {
  modelPath: string
  temperature?: number
  maxTokens?: number
  contextSize?: number
  threads?: number
  gpuLayers?: number
  verbose?: boolean
  reasoningLevel?: 'low' | 'medium' | 'high'
}
```

## ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

### ã‚¯ãƒ©ã‚¦ãƒ‰LLM
- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š
- æœ‰åŠ¹ãªAPIã‚­ãƒ¼
- é©åˆ‡ãªAPIåˆ¶é™

### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆllama.cppï¼‰
- **OS**: Windows, macOS, Linux
- **ãƒ¡ãƒ¢ãƒª**: 8GBä»¥ä¸Šæ¨å¥¨ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¿œã˜ã¦ï¼‰
- **CPU**: ãƒãƒ«ãƒã‚³ã‚¢CPUæ¨å¥¨
- **GPU**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆCUDA/OpenCLå¯¾å¿œï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ç©ºãå®¹é‡

#### æ¨å¥¨è¨­å®š
- **7Bãƒ¢ãƒ‡ãƒ«**: 8GB RAM, 4-8 CPU cores
- **13Bãƒ¢ãƒ‡ãƒ«**: 16GB RAM, 8-16 CPU cores
- **70Bãƒ¢ãƒ‡ãƒ«**: 32GB+ RAM, 16+ CPU cores, GPUæ¨å¥¨

### ğŸ†• OpenAI gpt-ossãƒ¢ãƒ‡ãƒ«
- **OS**: Windows, macOS, Linux
- **ãƒ¡ãƒ¢ãƒª**: 16GBä»¥ä¸Šæ¨å¥¨ï¼ˆgpt-oss-20bï¼‰
- **CPU**: ãƒãƒ«ãƒã‚³ã‚¢CPUæ¨å¥¨ï¼ˆ4ã‚³ã‚¢ä»¥ä¸Šï¼‰
- **GPU**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆCUDA/OpenCLå¯¾å¿œï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ã®ç©ºãå®¹é‡ï¼ˆ15GB+ï¼‰

#### æ¨å¥¨è¨­å®š
- **gpt-oss-20b**: 16GB RAM, 4-8 CPU cores
- **gpt-oss-120b**: 80GB+ RAM, 16+ CPU cores, GPUå¿…é ˆ

## åˆ¶é™äº‹é …

### ã‚¯ãƒ©ã‚¦ãƒ‰LLM
1. **APIã‚­ãƒ¼ä¾å­˜**: é«˜åº¦ãªæ©Ÿèƒ½ã«ã¯LLM APIã‚­ãƒ¼ãŒå¿…è¦
2. **è¨€èªåˆ¶é™**: ç¾åœ¨ã¯æ—¥æœ¬èªã¨è‹±èªã«æœ€é©åŒ–
3. **å‡¦ç†æ™‚é–“**: LLMä½¿ç”¨æ™‚ã¯å¿œç­”æ™‚é–“ãŒé•·ããªã‚‹å¯èƒ½æ€§
4. **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: ãƒ‡ãƒ¼ã‚¿ãŒå¤–éƒ¨ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã•ã‚Œã‚‹

### ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLM
1. **ç’°å¢ƒåˆ¶é™**: Node.jsç’°å¢ƒã§ã®ã¿å‹•ä½œ
2. **ãƒ¢ãƒ‡ãƒ«ä¾å­˜**: GGUFå½¢å¼ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦
3. **ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚**: ååˆ†ãªãƒ¡ãƒ¢ãƒªã¨CPUæ€§èƒ½ãŒå¿…è¦
4. **åˆæœŸåŒ–æ™‚é–“**: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚‹

### ğŸ†• gpt-ossãƒ¢ãƒ‡ãƒ«
1. **ç’°å¢ƒåˆ¶é™**: Node.jsç’°å¢ƒã§ã®ã¿å‹•ä½œ
2. **ãƒ¢ãƒ‡ãƒ«ä¾å­˜**: GGUFå½¢å¼ã®gpt-ossãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦
3. **ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚**: 16GBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªã¨4ã‚³ã‚¢ä»¥ä¸Šã®CPUãŒå¿…è¦
4. **åˆæœŸåŒ–æ™‚é–“**: å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚èª­ã¿è¾¼ã¿ã«æ™‚é–“ãŒã‹ã‹ã‚‹
5. **æ¨è«–ãƒ¬ãƒ™ãƒ«**: è¨­å®šã«ã‚ˆã£ã¦å‡¦ç†æ™‚é–“ã¨ç²¾åº¦ãŒå¤‰åŒ–

## ä»Šå¾Œã®æ‹¡å¼µäºˆå®š

1. **å¤šè¨€èªå¯¾å¿œ**: ã‚ˆã‚Šå¤šãã®è¨€èªã§ã®æœ¬æ–‡æŠ½å‡º
2. **ã‚«ã‚¹ã‚¿ãƒ æŠ½å‡ºãƒ«ãƒ¼ãƒ«**: ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ã®æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
3. **ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–**: å¤§é‡ãƒ†ã‚­ã‚¹ãƒˆã®åŠ¹ç‡çš„ãªå‡¦ç†
4. **å­¦ç¿’æ©Ÿèƒ½**: æŠ½å‡ºç²¾åº¦ã®ç¶™ç¶šçš„æ”¹å–„
5. **ğŸ†• GPUæœ€é©åŒ–**: CUDA/OpenCLå¯¾å¿œã®å¼·åŒ–
6. **ğŸ†• ãƒ¢ãƒ‡ãƒ«ç®¡ç†**: å‹•çš„ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½
7. **ğŸ†• åˆ†æ•£å‡¦ç†**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸¦åˆ—å‡¦ç†
8. **ğŸ†• æ¨è«–ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–**: gpt-ossã®æ¨è«–ãƒ¬ãƒ™ãƒ«è‡ªå‹•èª¿æ•´
9. **ğŸ†• ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ**: ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½æ¯”è¼ƒæ©Ÿèƒ½

## è²¢çŒ®

ã“ã®æ©Ÿèƒ½ã®æ”¹å–„ã‚„æ‹¡å¼µã«ã”å”åŠ›ã„ãŸã ã‘ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ç‚¹ã«ã”æ³¨æ„ãã ã•ã„ï¼š

1. æ—¢å­˜ã®UIã¯å¤‰æ›´ã—ãªã„
2. å‹å®‰å…¨æ€§ã‚’ç¶­æŒã™ã‚‹
3. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’è¿½åŠ ã™ã‚‹
4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°ã™ã‚‹
5. ğŸ†• ãƒ­ãƒ¼ã‚«ãƒ«LLMå¯¾å¿œã®å ´åˆã¯ç’°å¢ƒãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹
6. ğŸ†• gpt-osså¯¾å¿œã®å ´åˆã¯æ¨è«–ãƒ¬ãƒ™ãƒ«è¨­å®šã‚’è€ƒæ…®ã™ã‚‹
