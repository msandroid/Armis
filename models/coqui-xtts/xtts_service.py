#!/usr/bin/env python3
"""
Coqui XTTS-v2 TTS Service
Node.jsã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹ãƒ­ãƒ¼ã‚«ãƒ«TTSã‚µãƒ¼ãƒ“ã‚¹
"""

import os
import sys
import json
import tempfile
import base64
import time
from pathlib import Path
from typing import Dict, Any, Optional
import torch
import torchaudio
import numpy as np
import soundfile as sf

# XTTS-v2ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from TTS.api import TTS
    from TTS.tts.configs.xtts_config import XttsConfig
    from TTS.tts.models.xtts import Xtts
except ImportError:
    print("âŒ TTS library not found. Please install: pip install TTS")
    sys.exit(1)

class CoquiXTTSService:
    def __init__(self, models_dir: str = "./models/coqui-xtts"):
        self.models_dir = Path(models_dir)
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_name = "tts_models/multilingual/multi-dataset/xtts_v2"
        self.huggingface_model_path = self.models_dir / "xtts_v2_model"
        self.load_model()
    
    def load_model(self):
        """XTTS-v2ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            print(f"ğŸ¤ Loading XTTS-v2 model on {self.device}...")
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            self.models_dir.mkdir(parents=True, exist_ok=True)
            
            # Hugging Faceã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã¯ä½¿ç”¨
            if self.huggingface_model_path.exists():
                print(f"ğŸ“ Using Hugging Face model from: {self.huggingface_model_path}")
                # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ç”¨
                model_path = str(self.huggingface_model_path)
            else:
                print("ğŸŒ Using online model (will download automatically)")
                model_path = self.model_name
            
            # XTTS-v2ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
            self.model = TTS(model_path)
            
            # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•
            if self.device == "cuda":
                self.model.cuda()
            
            print("âœ… XTTS-v2 model loaded successfully")
            
        except Exception as e:
            print(f"âŒ Error loading XTTS-v2 model: {e}")
            raise
    
    def list_voices(self) -> Dict[str, Any]:
        """åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ä¸€è¦§ã‚’è¿”ã™"""
        voices = [
            {"id": "p225", "name": "Female Voice 1", "gender": "female", "language": "en"},
            {"id": "p226", "name": "Male Voice 1", "gender": "male", "language": "en"},
            {"id": "p227", "name": "Female Voice 2", "gender": "female", "language": "en"},
            {"id": "p228", "name": "Male Voice 2", "gender": "male", "language": "en"},
            {"id": "p229", "name": "Female Voice 3", "gender": "female", "language": "en"},
            {"id": "p230", "name": "Male Voice 3", "gender": "male", "language": "en"}
        ]
        
        return {
            "voices": voices,
            "device": self.device,
            "model": self.model_name,
            "model_path": str(self.huggingface_model_path) if self.huggingface_model_path.exists() else "online"
        }
    
    def synthesize(self, text: str, voice_name: str = "p225", 
                   language: str = "en", speed: float = 1.0,
                   output_format: str = "wav") -> Dict[str, Any]:
        """éŸ³å£°åˆæˆã‚’å®Ÿè¡Œ"""
        if not self.model:
            raise ValueError("Model not loaded")
        
        try:
            print(f"ğŸ¤ Synthesizing: {text[:50]}...")
            print(f"Voice: {voice_name}, Language: {language}, Speed: {speed}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with tempfile.NamedTemporaryFile(suffix=f".{output_format}", delete=False) as tmp_file:
                temp_path = tmp_file.name
            
            # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèª
            ref_audio_path = self.models_dir / "reference_audio" / f"{voice_name}.wav"
            
            if not ref_audio_path.exists():
                print(f"âš ï¸ Reference audio not found: {ref_audio_path}")
                print("Creating default reference audio...")
                self._create_default_reference_audio(voice_name)
            
            # éŸ³å£°åˆæˆã‚’å®Ÿè¡Œ
            start_time = time.time()
            
            # XTTS-v2ã§éŸ³å£°åˆæˆ
            wav = self.model.tts(
                text=text,
                speaker_wav=str(ref_audio_path),
                language=language,
                speed=speed
            )
            
            synthesis_time = time.time() - start_time
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            sf.write(temp_path, wav, 24000)
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            audio_data, sample_rate = sf.read(temp_path)
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            with open(temp_path, 'rb') as f:
                audio_base64 = base64.b64encode(f.read()).decode('utf-8')
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(temp_path)
            
            duration = len(audio_data) / sample_rate
            
            print(f"âœ… Synthesis completed in {synthesis_time:.2f}s")
            print(f"Audio duration: {duration:.2f}s, Sample rate: {sample_rate}Hz")
            
            return {
                "success": True,
                "audio": audio_base64,
                "format": output_format,
                "sample_rate": sample_rate,
                "duration": duration,
                "synthesis_time": synthesis_time
            }
            
        except Exception as e:
            print(f"âŒ Synthesis error: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _create_default_reference_audio(self, voice_name: str):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’ä½œæˆ"""
        ref_audio_dir = self.models_dir / "reference_audio"
        ref_audio_dir.mkdir(exist_ok=True)
        
        audio_path = ref_audio_dir / f"{voice_name}.wav"
        
        # ã‚ˆã‚Šè‡ªç„¶ãªéŸ³å£°æ³¢å½¢ã‚’ç”Ÿæˆ
        sample_rate = 24000
        duration = 3.0  # 3ç§’
        samples = int(sample_rate * duration)
        
        # åŸºæœ¬å‘¨æ³¢æ•°ï¼ˆéŸ³å£°ã®é«˜ã•ï¼‰
        base_freq = 220 if voice_name in ['p225', 'p227', 'p229'] else 110
        
        # è¤‡æ•°ã®ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹ã‚’è¿½åŠ ã—ã¦ã‚ˆã‚Šè‡ªç„¶ãªéŸ³å£°ã«
        t = np.linspace(0, duration, samples)
        audio_data = np.zeros(samples)
        
        # åŸºæœ¬å‘¨æ³¢æ•°ã¨ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹
        for i in range(1, 8):  # 7ã¤ã®ãƒãƒ¼ãƒ¢ãƒ‹ã‚¯ã‚¹
            freq = base_freq * i
            amplitude = 0.4 / (i ** 0.8)  # ã‚ˆã‚Šè‡ªç„¶ãªæ¸›è¡°
            audio_data += amplitude * np.sin(2 * np.pi * freq * t)
        
        # ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆï¼ˆéŸ³å£°ã®ç‰¹å¾´çš„ãªå‘¨æ³¢æ•°ï¼‰ã‚’è¿½åŠ 
        formant_freqs = [500, 1500, 2500, 3500] if voice_name in ['p225', 'p227', 'p229'] else [400, 1200, 2200, 3200]
        for freq in formant_freqs:
            amplitude = 0.1
            audio_data += amplitude * np.sin(2 * np.pi * freq * t)
        
        # ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ï¼ˆéŸ³é‡ã®å¤‰åŒ–ï¼‰ã‚’è¿½åŠ 
        envelope = np.exp(-t / (duration * 0.4))  # ã‚ˆã‚Šç·©ã‚„ã‹ãªãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
        audio_data *= envelope
        
        # ãƒã‚¤ã‚ºã‚’å°‘ã—è¿½åŠ ã—ã¦è‡ªç„¶ã•ã‚’å‘ä¸Š
        noise = np.random.normal(0, 0.005, samples)
        audio_data += noise
        
        # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚’é˜²ã
        audio_data = np.clip(audio_data, -0.9, 0.9)
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        sf.write(audio_path, audio_data, sample_rate)
        print(f"Created reference audio: {voice_name}.wav")
    
    def check_model_exists(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        try:
            # TTSãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            import TTS
            
            # Hugging Faceãƒ¢ãƒ‡ãƒ«ã®å­˜åœ¨ç¢ºèª
            if self.huggingface_model_path.exists():
                model_files = list(self.huggingface_model_path.rglob("*.bin")) + list(self.huggingface_model_path.rglob("*.safetensors"))
                if model_files:
                    return {
                        "exists": True, 
                        "message": f"TTS library available, Hugging Face model found ({len(model_files)} files)",
                        "model_path": str(self.huggingface_model_path)
                    }
                else:
                    return {
                        "exists": True, 
                        "message": "TTS library available, but no model files found in Hugging Face directory",
                        "model_path": str(self.huggingface_model_path)
                    }
            else:
                return {
                    "exists": True, 
                    "message": "TTS library available, will use online model",
                    "model_path": "online"
                }
        except ImportError:
            return {"exists": False, "error": "TTS library not installed"}
    
    def download_model(self) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå¾“æ¥ã®æ–¹æ³•ã¨ã®äº’æ›æ€§ï¼‰"""
        try:
            print("ğŸ“¥ Downloading XTTS-v2 model...")
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            self.models_dir.mkdir(parents=True, exist_ok=True)
            
            # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            ref_audio_dir = self.models_dir / "reference_audio"
            ref_audio_dir.mkdir(exist_ok=True)
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’ä½œæˆ
            voices = ["p225", "p226", "p227", "p228", "p229", "p230"]
            for voice in voices:
                self._create_default_reference_audio(voice)
            
            print("âœ… XTTS-v2 model setup completed")
            return {"success": True, "message": "Model setup completed"}
            
        except Exception as e:
            print(f"âŒ Error downloading model: {e}")
            return {"success": False, "error": str(e)}

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•° - Node.jsã‹ã‚‰ã®å‘¼ã³å‡ºã—ç”¨"""
    if len(sys.argv) < 2:
        print("Usage: python xtts_service.py <command> [args...]")
        sys.exit(1)
    
    command = sys.argv[1]
    service = CoquiXTTSService()
    
    if command == "list_voices":
        result = service.list_voices()
        print(json.dumps(result))
    
    elif command == "synthesize":
        if len(sys.argv) < 3:
            print("Usage: python xtts_service.py synthesize <text> [voice_name] [language] [speed]")
            sys.exit(1)
        
        text = sys.argv[2]
        voice_name = sys.argv[3] if len(sys.argv) > 3 else "p225"
        language = sys.argv[4] if len(sys.argv) > 4 else "en"
        speed = float(sys.argv[5]) if len(sys.argv) > 5 else 1.0
        
        result = service.synthesize(text, voice_name, language, speed)
        print(json.dumps(result))
    
    elif command == "check_model":
        result = service.check_model_exists()
        print(json.dumps(result))
    
    elif command == "download_model":
        result = service.download_model()
        print(json.dumps(result))
    
    else:
        print(f"Unknown command: {command}")
        sys.exit(1)

if __name__ == "__main__":
    main()
