import React, { useState, useEffect, useRef } from 'react'
import { ScrollArea } from '@/components/ui/scroll-area'
import { Button } from '@/components/ui/button'
import { ChatMessage, ChatMessageProps } from './ChatMessage'
import { PromptInputBox } from './PromptInputBox'

import { EnhancedFilePreview } from './EnhancedFilePreview'
import { ArmisSettings } from '@/components/settings/ArmisSettings'
import { createTTSManager } from '@/services/tts'
import { AISDKService } from '@/services/llm/ai-sdk-service'
import { GeminiFileService } from '@/services/llm/gemini-file-service'
import { AIProviderConfig, ModelSettings, AVAILABLE_PROVIDERS } from '@/types/ai-sdk'
import { cn } from '@/lib/utils'
import { FactCheckingService, FactCheckResult } from '@/services/llm/fact-checking-service'
import { 
  Settings, 
  Brain, 
  X, 
  Paperclip,
  FileText,
  Image as ImageIcon,
  Video,
  Music,
  File,
  AlertCircle,
  Wrench,
  Bot,
  Zap,
  Terminal as TerminalIcon
} from 'lucide-react'
import { motion, AnimatePresence } from 'framer-motion'
import { JumpingDots } from '@/components/ui/jumping-dots'
import { CircleSpinner } from '@/components/ui/circle-spinner'
import { ShimmerText } from '@/components/ui/shimmer-text'
import { SequentialThinkingPanel } from './SequentialThinkingPanel'
import { SequentialThinkingPlan } from '@/types/llm'
import { LLMManager } from '@/services/llm/llm-manager'
import { InputAnalyzer, InputAnalysis } from '@/services/agent/input-analyzer'
import { AgentType } from '@/types/llm'
import { AgentInfoDisplay } from './AgentInfoDisplay'
import { browserWebSearchService, WebSearchResult } from '@/services/web-search/browser-web-search'
import { webSearchManager } from '@/services/web-search/web-search-manager'
import { EmbeddedCLI } from './EmbeddedCLI'
import { TaskShimmerDisplay } from '@/components/ui/task-shimmer-display'
import { useTaskExecution } from '@/hooks/useTaskExecution'
import { FileCreationLoader } from '@/components/ui/file-creation-loader'
import { useFileCreation } from '@/hooks/useFileCreation'
import { ModelDownloadShimmer } from '@/components/ui/model-download-shimmer'
import { GeminiImageService } from '@/services/llm/gemini-image-service'
import { checkGoogleAIConfig, logConfigStatus } from '@/utils/env-checker'
import { VeoService } from '@/services/video/veo-service'

import { useTheme } from '@/components/theme-provider'
import { STTSettingsService } from '@/services/stt/stt-settings-service'

interface ChatWindowProps {
  className?: string
  useEnhancedPreview?: boolean // Êã°Âºµ„Éó„É¨„Éì„É•„Éº„Çí‰ΩøÁî®„Åô„Çã„Åã„Å©„ÅÜ„Åã
}

// AI Elements helper functions
const createAIElementsMessage = (
  content: string,
  sources?: Array<{ id: string; href: string; title?: string; description?: string }>,
  tasks?: Array<{
    id: string;
    title: string;
    status: 'pending' | 'in_progress' | 'completed' | 'error';
    items?: Array<{
      id: string;
      text: string;
      status: 'pending' | 'in_progress' | 'completed' | 'error';
      file?: { name: string; icon?: React.ReactNode };
    }>;
  }>,
  citations?: Array<{
    id: string;
    text: string;
    sources: Array<{
      id: string;
      url: string;
      title?: string;
      description?: string;
      quote?: string;
    }>;
  }>,
  tools?: Array<{
    id: string;
    type: string;
    state: 'input-streaming' | 'input-available' | 'output-available' | 'output-error';
    input: any;
    output?: any;
    errorText?: string;
  }>,
  webPreviews?: Array<{
    id: string;
    url: string;
    title?: string;
    consoleLogs?: Array<{ level: 'log' | 'warn' | 'error'; message: string; timestamp: Date }>;
  }>
): ChatMessageProps => ({
  id: Date.now().toString(),
  content,
  role: 'assistant',
  useAIElements: true,
  sources,
  tasks,
  citations,
  tools,
  webPreviews,
  isStreaming: false
})

// Sample AI Elements messages for demonstration
const sampleAIElementsMessages: ChatMessageProps[] = [
  createAIElementsMessage(
    `# AI SDK Response Component

This is a **markdown** response that demonstrates various features:

## Features

- **Bold text** and *italic text*
- \`inline code\` and code blocks
- Lists and numbered lists
- Links and images
- Math equations
- Tables

### Code Example

\`\`\`typescript
function greet(name: string): string {
  return \`Hello, \${name}!\`;
}

console.log(greet('World'));
\`\`\`

### Math Equation

Inline math: $E = mc^2$

Block math:
$$
\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}
$$

### Table Example

| Feature | Support | Description |
|---------|---------|-------------|
| Markdown | ‚úÖ | Full markdown support |
| Code Highlighting | ‚úÖ | Syntax highlighting |
| Math Equations | ‚úÖ | KaTeX integration |
| Copy Button | ‚úÖ | One-click code copying |

### Task List

- [x] Implement basic markdown rendering
- [x] Add code syntax highlighting
- [x] Integrate math equation support
- [ ] Add custom components support
- [ ] Implement streaming support

Visit [AI SDK Documentation](https://ai-sdk.dev) for more information.

> This is a blockquote that demonstrates the styling of quoted text.`,
    [
      {
        id: '1',
        href: 'https://ai-sdk.dev/elements/components/response',
        title: 'AI SDK Response Component',
        description: 'Official documentation for the Response component'
      },
      {
        id: '2',
        href: 'https://vercel.com/ai',
        title: 'Vercel AI',
        description: 'Build AI applications with Vercel'
      },
      {
        id: '3',
        href: 'https://radix-ui.com/primitives/docs/components/collapsible',
        title: 'Radix UI Collapsible',
        description: 'Unstyled, accessible collapsible component'
      }
    ],
    [
      {
        id: '1',
        title: 'Project Setup',
        status: 'completed',
        items: [
          { id: '1-1', text: 'Initialize project with npm', status: 'completed' },
          { id: '1-2', text: 'Install dependencies', status: 'completed' },
          { id: '1-3', text: 'Configure build tools', status: 'completed' }
        ]
      },
      {
        id: '2',
        title: 'Component Development',
        status: 'in_progress',
        items: [
          { id: '2-1', text: 'Create component structure', status: 'completed' },
          { id: '2-2', text: 'Implement core functionality', status: 'in_progress' },
          { id: '2-3', text: 'Add styling and animations', status: 'pending' },
          { id: '2-4', text: 'Write unit tests', status: 'pending' }
        ]
      },
      {
        id: '3',
        title: 'Documentation',
        status: 'pending',
        items: [
          { id: '3-1', text: 'Write API documentation', status: 'pending' },
          { id: '3-2', text: 'Create usage examples', status: 'pending' }
        ]
      }
    ]
  )
]

export const ChatWindow: React.FC<ChatWindowProps> = ({ 
  className,
  useEnhancedPreview = true // „Éá„Éï„Ç©„É´„Éà„ÅßÊã°Âºµ„Éó„É¨„Éì„É•„Éº„Çí‰ΩøÁî®
}) => {
  const [messages, setMessages] = useState<ChatMessageProps[]>([])
  const [streamingResponse, setStreamingResponse] = useState('')
  const [isTyping, setIsTyping] = useState(false)
  const [isGenerating, setIsGenerating] = useState(false)
  const [selectedFiles, setSelectedFiles] = useState<File[]>([])
  const [showSettings, setShowSettings] = useState(false)
  const [showSequentialThinking, setShowSequentialThinking] = useState(false)
  const [sequentialThinkingPlan, setSequentialThinkingPlan] = useState<SequentialThinkingPlan | null>(null)
  const [showAgentInfo, setShowAgentInfo] = useState(false)
  const [agentType, setAgentType] = useState<AgentType>('general')
  const [showEmbeddedCLI, setShowEmbeddedCLI] = useState(false)
  const [isWebSearching, setIsWebSearching] = useState(false)
  const [webSearchResults, setWebSearchResults] = useState<WebSearchResult[]>([])
  const [isVideoGenerating, setIsVideoGenerating] = useState(false)
  const [videoGenerationProgress, setVideoGenerationProgress] = useState(0)
  const [isImageGenerating, setIsImageGenerating] = useState(false)
  const [imageGenerationProgress, setImageGenerationProgress] = useState(0)
  const [isAudioGenerating, setIsAudioGenerating] = useState(false)
  const [audioGenerationProgress, setAudioGenerationProgress] = useState(0)
  const [isSTTTranscribing, setIsSTTTranscribing] = useState(false)
  const [sttFileName, setSttFileName] = useState<string>('')
  const [isDragging, setIsDragging] = useState(false)
  
  // Theme management
  const { theme, setTheme } = useTheme()
  
  // isGenerating„ÅÆÁä∂ÊÖãÂ§âÊõ¥„Çí„É≠„Ç∞Âá∫Âäõ
  useEffect(() => {
    console.log('üîÑ ChatWindow isGenerating changed:', isGenerating)
  }, [isGenerating])
  const [isTTSProcessing, setIsTTSProcessing] = useState(false) // TTSÂá¶ÁêÜ‰∏≠Áä∂ÊÖã
  
  // „É¢„Éá„É´„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÁä∂ÊÖã
  const [modelDownloadState, setModelDownloadState] = useState<{
    isDownloading: boolean;
    modelName: string;
    progress: number;
    status: 'starting' | 'downloading' | 'verifying' | 'completed' | 'error';
    downloadedBytes?: number;
    totalBytes?: number;
  }>({
    isDownloading: false,
    modelName: '',
    progress: 0,
    status: 'starting',
    downloadedBytes: undefined,
    totalBytes: undefined
  })

  // „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÁä∂ÊÖã„ÅÆ„Éá„Éê„ÉÉ„Ç∞Áî®„É≠„Ç∞
  useEffect(() => {
    console.log('üîÑ modelDownloadState changed:', modelDownloadState)
  }, [modelDownloadState])

  const [currentPlan, setCurrentPlan] = useState<SequentialThinkingPlan | null>(null)
  const [currentProviderConfig, setCurrentProviderConfig] = useState<AIProviderConfig | null>(null)
  const [webSearchEnabled, setWebSearchEnabled] = useState(false)
  
  // Fact checking settings state
  const [factCheckingSettings, setFactCheckingSettings] = useState(() => {
    try {
      const saved = localStorage.getItem('armis_fact_checking_settings')
      return saved ? JSON.parse(saved) : {
        enabled: false,
        model: 'ollama',
        temperature: 0.1,
        maxTokens: 1000,
        includeSources: true,
        strictMode: false,
        autoCheck: false,
        checkThreshold: 0.7
      }
    } catch (error) {
      console.error('Failed to load fact checking settings from localStorage:', error)
      return {
        enabled: false,
        model: 'ollama',
        temperature: 0.1,
        maxTokens: 1000,
        includeSources: true,
        strictMode: false,
        autoCheck: false,
        checkThreshold: 0.7
      }
    }
  })

  // Generation settings state
  const [generationSettings, setGenerationSettings] = useState(() => {
    // „É≠„Éº„Ç´„É´„Çπ„Éà„É¨„Éº„Ç∏„Åã„ÇâË®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
    try {
      const saved = localStorage.getItem('armis_generation_settings')
      return saved ? JSON.parse(saved) : {
        image: {
          enabled: false, // ÁîªÂÉèÁîüÊàêÊ©üËÉΩ„ÇíÁÑ°ÂäπÂåñ
          provider: 'google',
          models: {
            'gemini-2.0-flash-preview-image-generation': { enabled: false, priority: 1 },
            'imagen-3.0-generate-002': { enabled: false, priority: 2 },
            'imagen-3.0-generate-001': { enabled: false, priority: 3 },
            'imagen-3.0-fast-generate-001': { enabled: false, priority: 4 },
            'imagen-4.0-generate-001': { enabled: false, priority: 5 },
            'imagen-4.0-fast-generate-001': { enabled: false, priority: 6 },
            'imagen-4.0-ultra-generate-001': { enabled: false, priority: 7 }
          }
        },
        audio: {
          enabled: false,
          provider: 'google',
          models: {
            'gemini-2.5-flash-preview-tts': { enabled: false, priority: 1 },
            'gemini-2.5-pro-preview-tts': { enabled: false, priority: 2 }
          },
          tts: {
            defaultVoice: 'Kore',
            defaultLanguage: 'ja-JP',
            defaultStyle: '',
            apiKey: ''
          }
        },
        video: {
          enabled: false,
          provider: 'openai',
          models: {}
        },
        code: {
          enabled: false,
          provider: 'openai',
          models: {}
        }
      }
    } catch (error) {
      console.error('Failed to load generation settings from localStorage:', error)
      return {
        image: {
          enabled: false, // ÁîªÂÉèÁîüÊàêÊ©üËÉΩ„ÇíÁÑ°ÂäπÂåñ
          provider: 'google',
          models: {
            'gemini-2.0-flash-preview-image-generation': { enabled: false, priority: 1 },
            'imagen-3.0-generate-002': { enabled: false, priority: 2 },
            'imagen-3.0-generate-001': { enabled: false, priority: 3 },
            'imagen-3.0-fast-generate-001': { enabled: false, priority: 4 },
            'imagen-4.0-generate-001': { enabled: false, priority: 5 },
            'imagen-4.0-fast-generate-001': { enabled: false, priority: 6 },
            'imagen-4.0-ultra-generate-001': { enabled: false, priority: 7 }
          }
        },
        audio: {
          enabled: false,
          provider: 'google',
          models: {
            'gemini-2.5-flash-preview-tts': { enabled: false, priority: 1 },
            'gemini-2.5-pro-preview-tts': { enabled: false, priority: 2 }
          },
          tts: {
            defaultVoice: 'Kore',
            defaultLanguage: 'ja-JP',
            defaultStyle: '',
            apiKey: ''
          }
        },
        video: {
          enabled: false,
          provider: 'openai',
          models: {}
        },
        code: {
          enabled: false,
          provider: 'openai',
          models: {}
        }
      }
    }
  })
  
  const [createImageEnabled, setCreateImageEnabled] = useState(false)
  const [audioEnabled, setAudioEnabled] = useState(false)
  const [videoEnabled, setVideoEnabled] = useState(false)
  const [isGeneratingVideo, setIsGeneratingVideo] = useState(false)
  const [videoProgress, setVideoProgress] = useState(0)
  const [currentTTSModel, setCurrentTTSModel] = useState<string>(() => {
    // „É≠„Éº„Ç´„É´„Çπ„Éà„É¨„Éº„Ç∏„Åã„ÇâTTS„É¢„Éá„É´Ë®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
    try {
      const saved = localStorage.getItem('armis_tts_model')
      return saved || 'auto'
    } catch (error) {
      console.error('Failed to load TTS model from localStorage:', error)
      return 'auto'
    }
  })

  const [currentSTTModel, setCurrentSTTModel] = useState<string>(() => {
    // „É≠„Éº„Ç´„É´„Çπ„Éà„É¨„Éº„Ç∏„Åã„ÇâSTT„É¢„Éá„É´Ë®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
    try {
      const saved = localStorage.getItem('armis_stt_model')
      return saved || 'auto'
    } catch (error) {
      console.error('Failed to load STT model from localStorage:', error)
      return 'auto'
    }
  })

  // TTS„É¢„Éá„É´Ë®≠ÂÆö„ÇíË®≠ÂÆöÁîªÈù¢„ÅÆAudioË®≠ÂÆö„Å®ÂêåÊúü
  useEffect(() => {
    if (generationSettings.audio.enabled && generationSettings.audio.models) {
      // ÊúâÂäπ„Å™TTS„É¢„Éá„É´„ÇíÂÑ™ÂÖàÂ∫¶È†Ü„Å´„ÇΩ„Éº„Éà
      const enabledTTSModels = Object.entries(generationSettings.audio.models)
        .filter(([_, config]: [string, any]) => config.enabled)
        .sort(([_, a]: [string, any], [__, b]: [string, any]) => (a.priority || 999) - (b.priority || 999))
      
      // ÁèæÂú®ÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãTTS„É¢„Éá„É´„ÅåÊúâÂäπ„Åß„Å™„ÅÑÂ†¥Âêà„ÄÅÊúÄÈ´òÂÑ™ÂÖàÂ∫¶„ÅÆ„É¢„Éá„É´„Å´Ë®≠ÂÆö
      if (currentTTSModel !== 'auto' && !enabledTTSModels.find(([model, _]) => model === currentTTSModel)) {
        const defaultModel = enabledTTSModels.length > 0 ? enabledTTSModels[0][0] : 'auto'
        setCurrentTTSModel(defaultModel)
        localStorage.setItem('armis_tts_model', defaultModel)
        console.log('TTS model synchronized with settings:', defaultModel)
      }
    }
  }, [generationSettings.audio.enabled, generationSettings.audio.models, currentTTSModel])

  // STTË®≠ÂÆö„Çµ„Éº„Éì„Çπ
  const [sttSettingsService] = useState(() => STTSettingsService.getInstance())
  
  // Create Image„Éú„Çø„É≥„ÅÆÁä∂ÊÖã„ÇíGenerationË®≠ÂÆö„Å®ÂêåÊúü
  useEffect(() => {
    // ÂàùÊúüÂåñÊôÇ„ÅØÂøÖ„Åöfalse„Å´Ë®≠ÂÆö
    if (generationSettings.image.enabled === false) {
      setCreateImageEnabled(false)
      console.log('Create Image enabled: false (initialized)')
    } else {
      setCreateImageEnabled(generationSettings.image.enabled)
      console.log('Create Image enabled:', generationSettings.image.enabled)
    }
  }, [generationSettings.image.enabled])

  // Audio„Éú„Çø„É≥„ÅÆÁä∂ÊÖã„ÇíGenerationË®≠ÂÆö„Å®ÂêåÊúü
  useEffect(() => {
    // ÂàùÊúüÂåñÊôÇ„ÅØÂøÖ„Åöfalse„Å´Ë®≠ÂÆö
    if (generationSettings.audio.enabled === false) {
      setAudioEnabled(false)
      console.log('Audio enabled: false (initialized)')
    } else {
      setAudioEnabled(generationSettings.audio.enabled)
      console.log('Audio enabled:', generationSettings.audio.enabled)
    }
  }, [generationSettings.audio.enabled])

  // Video„Éú„Çø„É≥„ÅÆÁä∂ÊÖã„ÇíGenerationË®≠ÂÆö„Å®ÂêåÊúü
  useEffect(() => {
    // ÂàùÊúüÂåñÊôÇ„ÅØÂøÖ„Åöfalse„Å´Ë®≠ÂÆö
    if (generationSettings.video.enabled === false) {
      setVideoEnabled(false)
      console.log('Video enabled: false (initialized)')
    } else {
      setVideoEnabled(generationSettings.video.enabled)
      console.log('Video enabled:', generationSettings.video.enabled)
    }
  }, [generationSettings.video.enabled])

  // ÂàùÊúüÂåñÊôÇ„Å´CreateImage„ÄÅAudio„ÄÅVideo„ÇíÁ¢∫ÂÆü„Å´false„Å´Ë®≠ÂÆö
  useEffect(() => {
    setCreateImageEnabled(false)
    setAudioEnabled(false)
    setVideoEnabled(false)
    console.log('Initialized CreateImage, Audio, and Video to false')
  }, [])

  // GenerationË®≠ÂÆö„ÅÆÊ∞∏Á∂öÂåñ
  useEffect(() => {
    localStorage.setItem('armis_generation_settings', JSON.stringify(generationSettings))
    console.log('üéõÔ∏è Generation settings updated:', {
      audioProvider: generationSettings.audio.provider,
      audioEnabled: generationSettings.audio.enabled,
      audioModels: generationSettings.audio.models,
      videoProvider: generationSettings.video.provider,
      videoEnabled: generationSettings.video.enabled
    })
  }, [generationSettings])

  // „Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØË®≠ÂÆö„ÅÆÊ∞∏Á∂öÂåñ
  useEffect(() => {
    localStorage.setItem('armis_fact_checking_settings', JSON.stringify(factCheckingSettings))
    console.log('üîç Fact checking settings updated:', {
      enabled: factCheckingSettings.enabled,
      model: factCheckingSettings.model,
      autoCheck: factCheckingSettings.autoCheck
    })
  }, [factCheckingSettings])

  // ÂàùÂõûËµ∑ÂãïÊôÇ„Å´localStorage„Çí„ÇØ„É™„Ç¢„Åó„Å¶Êñ∞„Åó„ÅÑË®≠ÂÆö„ÅßÂàùÊúüÂåñ
  useEffect(() => {
    // Âº∑Âà∂ÁöÑ„Å´localStorage„Çí„ÇØ„É™„Ç¢„Åó„Å¶Êñ∞„Åó„ÅÑË®≠ÂÆö„ÅßÂàùÊúüÂåñ
    localStorage.removeItem('armis_generation_settings')
    localStorage.setItem('armis_first_run', 'true')
    console.log('Generation settings reset to default (false)')
    
    // Âº∑Âà∂ÁöÑ„Å´Ë®≠ÂÆö„Çí„É™„Çª„ÉÉ„ÉàÔºàÈñãÁô∫Áî®Ôºâ
    const forceReset = localStorage.getItem('armis_force_reset_generation')
    if (forceReset === 'true') {
      localStorage.removeItem('armis_generation_settings')
      localStorage.removeItem('armis_force_reset_generation')
      console.log('Force reset generation settings')
    }
  }, [])
  
  // „É≠„Éº„Éá„Ç£„É≥„Ç∞Áä∂ÊÖãÁÆ°ÁêÜ
  const [loadingState, setLoadingState] = useState<'idle' | 'text' | 'media'>('idle')
  const [modelSettings, setModelSettings] = useState<ModelSettings>(() => {
    // localStorage„Åã„Çâ„É¢„Éá„É´Ë®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
    try {
      const saved = localStorage.getItem('armis_model_settings')
      return saved ? JSON.parse(saved) : {
        enabledModels: [
          { providerId: 'openai', modelId: 'gpt-4o', enabled: true, priority: 1 },
          { providerId: 'anthropic', modelId: 'claude-opus-4.1', enabled: true, priority: 3 },
          { providerId: 'google', modelId: 'gemini-2.5-flash-lite', enabled: true, priority: 4 },
          { providerId: 'ollama', modelId: 'gemma3:1b', enabled: true, priority: 2 }
        ],
        defaultModel: 'ollama:gemma3:1b',
        autoSwitch: true
      }
    } catch (error) {
      console.error('Failed to load model settings from localStorage:', error)
      return {
        enabledModels: [
          { providerId: 'openai', modelId: 'gpt-4o', enabled: true, priority: 1 },
          { providerId: 'anthropic', modelId: 'claude-opus-4.1', enabled: true, priority: 3 },
          { providerId: 'google', modelId: 'gemini-2.5-flash-lite', enabled: true, priority: 4 },
          { providerId: 'ollama', modelId: 'gemma3:1b', enabled: true, priority: 2 }
        ],
        defaultModel: 'ollama:gemma3:1b',
        autoSwitch: true
      }
    }
  })
  
  // „Éó„É≠„Éê„Ç§„ÉÄ„Éº„Åî„Å®„ÅÆAPI KeyÁÆ°ÁêÜ
  const [providerApiKeys, setProviderApiKeys] = useState<Record<string, string>>(() => {
    // localStorage„Åã„ÇâAPI„Ç≠„Éº„ÇíË™≠„ÅøËæº„Åø
    try {
      const saved = localStorage.getItem('armis_provider_api_keys')
      const apiKeys = saved ? JSON.parse(saved) : {}
      
      // Web Search Manager„Å´API„Ç≠„Éº„ÇíË®≠ÂÆö
      webSearchManager.setProviderApiKeys(apiKeys)
      
      return apiKeys
    } catch (error) {
      console.error('Failed to load API keys from localStorage:', error)
      return {}
    }
  })
  const [aiSDKService] = useState(() => new AISDKService())
  const [geminiFileService] = useState(() => new GeminiFileService())

  // Router Agent SystemÈñ¢ÈÄ£„ÅÆÁä∂ÊÖã
  const [llmManager, setLlmManager] = useState<LLMManager | null>(null)
  const [inputAnalyzer] = useState(() => new InputAnalyzer())
  const [currentAnalysis, setCurrentAnalysis] = useState<InputAnalysis | null>(null)
  const [agentInfo, setAgentInfo] = useState<{
    type: AgentType | null
    confidence: number
    reasoning: string
  } | null>(null)

  // „É¢„Éá„É´„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÈñ¢ÈÄ£„ÅÆÁä∂ÊÖã
  const [downloadProgress, setDownloadProgress] = useState<any>(null)
  const [isDownloading, setIsDownloading] = useState(false)

  // CLIÈñ¢ÈÄ£„ÅÆÁä∂ÊÖã
  const [showCLI, setShowCLI] = useState(false)
  const [isCLIMinimized, setIsCLIMinimized] = useState(false)
  
  // CLI„Éï„Ç©„É≥„ÉàË®≠ÂÆö„ÅÆÁä∂ÊÖã
  const [cliFontSettings, setCliFontSettings] = useState(() => {
    // localStorage„Åã„Çâ„Éï„Ç©„É≥„ÉàË®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
    try {
      const saved = localStorage.getItem('armis_cli_font_settings')
      return saved ? JSON.parse(saved) : {
        fontFamily: 'Cascadia Code',
        fontSize: 12,
        fontLigatures: true
      }
    } catch (error) {
      console.error('Failed to load CLI font settings from localStorage:', error)
      return {
        fontFamily: 'Cascadia Code',
        fontSize: 12,
        fontLigatures: true
      }
    }
  })

  // API„Ç≠„Éº„ÇílocalStorage„Å´‰øùÂ≠ò„Åô„ÇãÈñ¢Êï∞
  const saveApiKeysToStorage = (apiKeys: Record<string, string>) => {
    try {
      localStorage.setItem('armis_provider_api_keys', JSON.stringify(apiKeys))
    } catch (error) {
      console.error('Failed to save API keys to localStorage:', error)
    }
  }

  // CLI„Éï„Ç©„É≥„ÉàË®≠ÂÆö„ÇílocalStorage„Å´‰øùÂ≠ò„Åô„ÇãÈñ¢Êï∞
  const saveCliFontSettingsToStorage = (settings: { fontFamily: string; fontSize: number; fontLigatures: boolean }) => {
    try {
      localStorage.setItem('armis_cli_font_settings', JSON.stringify(settings))
    } catch (error) {
      console.error('Failed to save CLI font settings to localStorage:', error)
    }
  }

  // „É¢„Éá„É´Ë®≠ÂÆö„ÇílocalStorage„Å´‰øùÂ≠ò„Åô„ÇãÈñ¢Êï∞
  const saveModelSettingsToStorage = (settings: ModelSettings) => {
    try {
      localStorage.setItem('armis_model_settings', JSON.stringify(settings))
    } catch (error) {
      console.error('Failed to save model settings to localStorage:', error)
    }
  }

  // API„Ç≠„ÉºÊõ¥Êñ∞ÊôÇ„ÅÆ„Éè„É≥„Éâ„É©„Éº
  const handleProviderApiKeysChange = (newApiKeys: Record<string, string>) => {
    setProviderApiKeys(newApiKeys)
    saveApiKeysToStorage(newApiKeys)
    
    // Web Search Manager„Å´API„Ç≠„Éº„ÇíË®≠ÂÆö
    webSearchManager.setProviderApiKeys(newApiKeys)
  }

  // CLI„Éï„Ç©„É≥„ÉàË®≠ÂÆöÊõ¥Êñ∞ÊôÇ„ÅÆ„Éè„É≥„Éâ„É©„Éº
  const handleCliFontSettingsChange = (settings: { fontFamily: string; fontSize: number; fontLigatures: boolean }) => {
    setCliFontSettings(settings)
    saveCliFontSettingsToStorage(settings)
  }

  // „É¢„Éá„É´Ë®≠ÂÆöÊõ¥Êñ∞ÊôÇ„ÅÆ„Éè„É≥„Éâ„É©„Éº
  const handleModelSettingsChange = (settings: ModelSettings) => {
    setModelSettings(settings)
    saveModelSettingsToStorage(settings)
  }

  // „Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØË®≠ÂÆö„ÇílocalStorage„Å´‰øùÂ≠ò„Åô„ÇãÈñ¢Êï∞
  const saveFactCheckingSettingsToStorage = (settings: any) => {
    try {
      localStorage.setItem('armis_fact_checking_settings', JSON.stringify(settings))
    } catch (error) {
      console.error('Failed to save fact checking settings to localStorage:', error)
    }
  }

  // „Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØË®≠ÂÆöÊõ¥Êñ∞ÊôÇ„ÅÆ„Éè„É≥„Éâ„É©„Éº
  const handleFactCheckingSettingsChange = (settings: any) => {
    setFactCheckingSettings(settings)
    saveFactCheckingSettingsToStorage(settings)
  }

  // „Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØÂÆüË°åÈñ¢Êï∞
  const performFactCheck = async (text: string): Promise<FactCheckResult | null> => {
    if (!factCheckingSettings.enabled) {
      return null
    }

    try {
      // ÁèæÂú®ÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´„Å´Âü∫„Å•„ÅÑ„Å¶„Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØ„É¢„Éá„É´„ÇíÊ±∫ÂÆö
      let factCheckModel = factCheckingSettings.model as any
      let ollamaModel = 'gemma3:1b'
      let ollamaBaseUrl = 'http://localhost:11434'

      // ÁèæÂú®„ÅÆ„É¢„Éá„É´Ë®≠ÂÆö„ÇíÁ¢∫Ë™ç
      if (currentSelectedModel) {
        if (currentSelectedModel.startsWith('ollama:')) {
          factCheckModel = 'ollama'
          ollamaModel = currentSelectedModel.replace('ollama:', '')
        } else if (currentSelectedModel.startsWith('llama-cpp:')) {
          factCheckModel = 'ollama'
          ollamaModel = currentSelectedModel.replace('llama-cpp:', '')
        }
      }

      const factChecker = new FactCheckingService({
        model: factCheckModel,
        temperature: factCheckingSettings.temperature,
        maxTokens: factCheckingSettings.maxTokens,
        includeSources: factCheckingSettings.includeSources,
        strictMode: factCheckingSettings.strictMode,
        ollamaModel: ollamaModel,
        ollamaBaseUrl: ollamaBaseUrl
      })

      const result = await factChecker.checkFacts(text)
      return result
    } catch (error) {
      console.error('Fact checking failed:', error)
      return null
    }
  }

  // „Éè„É´„Ç∑„Éç„Éº„Ç∑„Éß„É≥Ê§úÂá∫ÂÆüË°åÈñ¢Êï∞
  const detectHallucinations = async (text: string): Promise<any | null> => {
    if (!factCheckingSettings.enabled) {
      return null
    }

    try {
      const factChecker = new FactCheckingService({
        model: factCheckingSettings.model as any,
        temperature: factCheckingSettings.temperature,
        maxTokens: factCheckingSettings.maxTokens,
        includeSources: factCheckingSettings.includeSources,
        strictMode: factCheckingSettings.strictMode
      })

      const result = await factChecker.detectHallucinations(text)
      return result
    } catch (error) {
      console.error('Hallucination detection failed:', error)
      return null
    }
  }
  const [lastError, setLastError] = useState<string | null>(null)

  // „Çø„Çπ„ÇØÂÆüË°åÁÆ°ÁêÜ
  const {
    activeTasks,
    addTask,
    updateTask,
    removeTask,
    clearCompletedTasks,
    getTask,
    isTaskActive
  } = useTaskExecution()

  // „Éï„Ç°„Ç§„É´‰ΩúÊàêÁÆ°ÁêÜ
  const {
    activeFileCreations,
    addFileCreation,
    updateFileCreation,
    removeFileCreation,
    clearCompletedFileCreations,
    getFileCreation,
    isFileCreationActive
  } = useFileCreation()

  // LLM ManagerÂàùÊúüÂåñ
  useEffect(() => {
    const initializeLLMManager = async () => {
      try {
        // Áí∞Â¢ÉÂ§âÊï∞„ÅÆË®≠ÂÆöÁä∂Ê≥Å„Çí„É≠„Ç∞Âá∫Âäõ
        logConfigStatus()
        
        // Êó¢„Å´ÂàùÊúüÂåñÊ∏à„Åø„ÅÆÂ†¥Âêà„ÅØÊó©Êúü„É™„Çø„Éº„É≥
        if (llmManager) {
          return
        }
        
        const config: any = { // LLMManager„ÅÆÂûãÂÆöÁæ©„Çí‰øÆÊ≠£
          useOllama: true,
          useLlamaCpp: false,
          defaultModel: 'gemma3:1b',
          vectorDBConfig: {
            type: 'in-memory'
          }
        }
        
        const manager = new LLMManager(config)
        
        // ÂàùÊúüÂåñÊôÇ„Å´Ollama„ÇíÂÑ™ÂÖàÁöÑ„Å´‰ΩøÁî®„Åó„ÄÅgemma3:1b„ÇíËá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
        try {
          await manager.initialize()
          
          // Ollama„ÅåÂà©Áî®ÂèØËÉΩ„Å™Â†¥Âêà„ÅØ„ÄÅgemma3:1b„ÅåÂà©Áî®ÂèØËÉΩ„Åã„ÉÅ„Çß„ÉÉ„ÇØ
          if (manager.isUsingOllama()) {
            const models = await manager.listOllamaModels()
            const gemmaExists = models.some(m => m.name === 'gemma3:1b')
            
            if (!gemmaExists) {
              await manager.pullOllamaModelWithProgress(
                'gemma3:1b',
                (progress) => {
                  // „Éó„É≠„Ç∞„É¨„Çπ„É≠„Ç∞„ÇíÈùûË°®Á§∫
                }
              )
            }
          }
        } catch (error) {
          console.warn('‚ö†Ô∏è Ollama initialization failed, using fallback:', error)
        }
        
        setLlmManager(manager)
      } catch (error) {
        console.error('‚ùå Failed to initialize LLM Manager:', error)
        setLastError('Router Agent System„ÅÆÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü')
      }
    }

    initializeLLMManager()
  }, [])
  const [currentToolCalls, setCurrentToolCalls] = useState<any[]>([])
  const [isAgentMode, setIsAgentMode] = useState(false)
  const scrollAreaRef = useRef<HTMLDivElement>(null)

  // Auto-scroll
  useEffect(() => {
    if (scrollAreaRef.current) {
      scrollAreaRef.current.scrollTop = scrollAreaRef.current.scrollHeight
    }
  }, [messages, streamingResponse])

  // „Éá„Éê„ÉÉ„Ç∞Áî®Ôºö„É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÂ§âÊõ¥„ÇíÁõ£Ë¶ñ
  useEffect(() => {
    console.log('üìù Messages state changed:', {
      messageCount: messages.length,
      messages: messages.map(msg => ({
        id: msg.id,
        content: msg.content?.substring(0, 30) + (msg.content && msg.content.length > 30 ? '...' : ''),
        contentLength: msg.content?.length,
        role: msg.role
      }))
    })

    // „É°„ÉÉ„Çª„Éº„Ç∏„ÅåËøΩÂä†„Åï„Çå„ÅüÂæå„Å´isTyping„Çí„É™„Çª„ÉÉ„Éà
    if (messages.length > 0 && isTyping) {
      const lastMessage = messages[messages.length - 1]
      if (lastMessage.role === 'assistant' && lastMessage.content && lastMessage.content.trim() !== '') {
        console.log('üîÑ Resetting isTyping after assistant message added')
        setIsTyping(false)
        setLoadingState('idle')
      }
    }
  }, [messages, isTyping])

  // isTyping„ÅÆÁä∂ÊÖã„ÇíÁõ£Ë¶ñ„Åó„Å¶„ÄÅÈï∑ÊôÇÈñìtrue„ÅÆ„Åæ„Åæ„ÅÆÂ†¥Âêà„ÅØ„É™„Çª„ÉÉ„Éà
  useEffect(() => {
    if (isTyping) {
      const timeout = setTimeout(() => {
        console.log('‚ö†Ô∏è isTyping timeout - resetting state')
        setIsTyping(false)
        setLoadingState('idle')
      }, 30000) // 30ÁßíÂæå„Å´„É™„Çª„ÉÉ„Éà

      return () => clearTimeout(timeout)
    }
  }, [isTyping])

  // „Ç≠„Éº„Éú„Éº„Éâ„Ç∑„Éß„Éº„Éà„Ç´„ÉÉ„Éà
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      // Cmd+T (Mac) „Åæ„Åü„ÅØ Ctrl+T (Windows/Linux) „ÅßTTS„É¢„Éá„É´Âàá„ÇäÊõø„Åà
      if ((e.metaKey || e.ctrlKey) && e.key === 't') {
        e.preventDefault()
        // TTS„É¢„Éá„É´Âàá„ÇäÊõø„Åà„ÅÆ„É≠„Ç∏„ÉÉ„ÇØ„Çí„Åì„Åì„Å´ËøΩÂä†
        console.log('TTS model switch shortcut triggered')
      }
    }

    document.addEventListener('keydown', handleKeyDown)
    return () => document.removeEventListener('keydown', handleKeyDown)
  }, [])

  // Auto-configure provider on mount
  useEffect(() => {
    autoConfigureProvider()
  }, [])

  // „Éï„Ç°„Ç§„É´„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂá¶ÁêÜ
  const handleFileUpload = (files: FileList | File[]) => {
    const newFiles = Array.from(files)
    setSelectedFiles(prev => [...prev, ...newFiles])
  }

  const removeAttachment = (index: number) => {
    setSelectedFiles(prev => prev.filter((_, i) => i !== index))
  }

  // „Éâ„É©„ÉÉ„Ç∞&„Éâ„É≠„ÉÉ„ÉóÂá¶ÁêÜ
  const handleDragOver = (e: React.DragEvent) => {
    e.preventDefault()
    setIsDragging(true)
  }

  const handleDragLeave = (e: React.DragEvent) => {
    e.preventDefault()
    setIsDragging(false)
  }

  const handleDrop = (e: React.DragEvent) => {
    e.preventDefault()
    setIsDragging(false)
    const files = e.dataTransfer.files
    if (files.length > 0) {
      handleFileUpload(files)
    }
  }

  // Âà©Áî®ÂèØËÉΩ„Å™„É¢„Éá„É´„ÇíËá™ÂãïÈÅ∏Êäû„Åô„ÇãÈñ¢Êï∞
  const autoConfigureProvider = async () => {
    // ‰øùÂ≠ò„Åï„Çå„ÅüAPI„Ç≠„Éº„Åå„ÅÇ„Çã„Åã„ÉÅ„Çß„ÉÉ„ÇØ
    const savedApiKeys = Object.entries(providerApiKeys).filter(([_, apiKey]) => apiKey && apiKey.trim() !== '')

    if (savedApiKeys.length === 0) {
      console.log('No API keys available for auto-configuration')
      return
    }

    // ÊúâÂäπ„Å™„É¢„Éá„É´„ÇíÂÑ™ÂÖàÂ∫¶È†Ü„Å´„ÇΩ„Éº„Éà
    const enabledModels = modelSettings.enabledModels
      .filter(model => model.enabled)
      .sort((a, b) => (a.priority || 999) - (b.priority || 999))

    // Âà©Áî®ÂèØËÉΩ„Å™API„Ç≠„Éº„ÇíÊåÅ„Å§„É¢„Éá„É´„Çí„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
    const availableModels = enabledModels.filter(model => {
      const hasApiKey = savedApiKeys.some(([providerId, _]) => providerId === model.providerId)
      const provider = AVAILABLE_PROVIDERS.find((p: any) => p.id === model.providerId)
      const modelExists = provider?.models.some((m: any) => m.id === model.modelId)
      return hasApiKey && modelExists
    })

    if (availableModels.length === 0) {
      console.log('No available models with valid API keys')
      return
    }

    // ÊúÄÈ´òÂÑ™ÂÖàÂ∫¶„ÅÆ„É¢„Éá„É´„ÇíÈÅ∏Êäû
    const selectedModel = availableModels[0]
    const apiKey = savedApiKeys.find(([providerId, _]) => providerId === selectedModel.providerId)?.[1]

    if (!apiKey) {
      console.error('API key not found for selected model')
      return
    }

    const config: AIProviderConfig = {
      providerId: selectedModel.providerId,
      modelId: selectedModel.modelId,
      apiKey
    }

    try {
      await handleProviderSelect(config)
      console.log(`Auto-selected model: ${selectedModel.providerId}:${selectedModel.modelId} (priority: ${selectedModel.priority})`)
    } catch (error) {
      console.error('Failed to auto-configure provider:', error)
      
      // „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: Ê¨°„ÅÆÂÑ™ÂÖàÂ∫¶„ÅÆÈ´ò„ÅÑ„É¢„Éá„É´„ÇíË©¶„Åô
      if (availableModels.length > 1) {
        const fallbackModel = availableModels[1]
        const fallbackApiKey = savedApiKeys.find(([providerId, _]) => providerId === fallbackModel.providerId)?.[1]
        
        if (fallbackApiKey) {
          const fallbackConfig: AIProviderConfig = {
            providerId: fallbackModel.providerId,
            modelId: fallbackModel.modelId,
            apiKey: fallbackApiKey
          }
          
          try {
            await handleProviderSelect(fallbackConfig)
            console.log(`Fallback to model: ${fallbackModel.providerId}:${fallbackModel.modelId}`)
          } catch (fallbackError) {
            console.error('Failed to configure fallback provider:', fallbackError)
          }
        }
      }
    }
  }

  // „É°„ÉÉ„Çª„Éº„Ç∏Á∑®ÈõÜ„Éè„É≥„Éâ„É©„Éº
  const handleMessageEdit = (messageId: string, newContent: string) => {
    setMessages(prev => 
      prev.map(msg => 
        msg.id === messageId 
          ? { ...msg, content: newContent }
          : msg
      )
    )
    
    // Á∑®ÈõÜ„Åï„Çå„Åü„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂÜçÈÄÅ‰ø°
    handleSendMessage(newContent)
  }

  // „É°„ÉÉ„Çª„Éº„Ç∏Á∑®ÈõÜ„Ç≠„É£„É≥„Çª„É´„Éè„É≥„Éâ„É©„Éº
  const handleMessageEditCancel = (messageId: string) => {
    // Á∑®ÈõÜ„Ç≠„É£„É≥„Çª„É´ÊôÇ„ÅÆÂá¶ÁêÜÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶ÂÆüË£ÖÔºâ
    console.log('Message edit cancelled for:', messageId)
  }

  // ÂÅúÊ≠¢„Éè„É≥„Éâ„É©„Éº
  const handleStopGeneration = () => {
    console.log('üõë Stopping AI generation...')
    console.log('üîÑ Current isGenerating state before stop:', isGenerating)
    
    // AI SDK Service„ÅÆÂÅúÊ≠¢Âá¶ÁêÜ„ÇíÂÆüË°å
    aiSDKService.stopGeneration()
    
    // Áä∂ÊÖã„Çí„É™„Çª„ÉÉ„Éà
    setIsGenerating(false)
    setIsTyping(false)
    setLoadingState('idle')
    setStreamingResponse('')
    
    // ÊúÄÂæå„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅåÁ©∫„ÅÆÂ†¥Âêà„ÅØÂâäÈô§
    setMessages(prev => {
      const lastMessage = prev[prev.length - 1]
      if (lastMessage && lastMessage.role === 'assistant' && (!lastMessage.content || lastMessage.content.trim() === '')) {
        return prev.slice(0, -1)
      }
      return prev
    })
    
    console.log('‚úÖ AI generation stopped successfully')
    console.log('üîÑ isGenerating state after stop: false')
  }

  // WebSearchÂàá„ÇäÊõø„Åà„Éè„É≥„Éâ„É©„Éº
  const handleWebSearchToggle = (enabled: boolean) => {
    setWebSearchEnabled(enabled)
    console.log('WebSearch enabled:', enabled)
  }

  // TTS ModelÈÅ∏Êäû„Éè„É≥„Éâ„É©„Éº
  const handleTTSModelSelect = (modelId: string) => {
    setCurrentTTSModel(modelId)
    // „É≠„Éº„Ç´„É´„Çπ„Éà„É¨„Éº„Ç∏„Å´‰øùÂ≠ò
    try {
      localStorage.setItem('armis_tts_model', modelId)
    } catch (error) {
      console.error('Failed to save TTS model to localStorage:', error)
    }
    console.log('TTS Model selected:', modelId)
  }

  // Create ImageÂàá„ÇäÊõø„Åà„Éè„É≥„Éâ„É©„Éº
  const handleCreateImageToggle = (enabled: boolean) => {
    setCreateImageEnabled(enabled)
    console.log('Create Image enabled:', enabled)
    
    // GenerationË®≠ÂÆö„Å®ÈÄ£Êê∫
    if (enabled && !generationSettings.image.enabled) {
      setGenerationSettings((prev: any) => ({
        ...prev,
        image: {
          ...prev.image,
          enabled: true
        }
      }))
    }
  }

  // AudioÂàá„ÇäÊõø„Åà„Éè„É≥„Éâ„É©„Éº
  const handleAudioToggle = (enabled: boolean) => {
    setAudioEnabled(enabled)
    console.log('Audio enabled:', enabled)
    
    // GenerationË®≠ÂÆö„Å®ÈÄ£Êê∫
    if (enabled && !generationSettings.audio.enabled) {
      setGenerationSettings((prev: any) => ({
        ...prev,
        audio: {
          ...prev.audio,
          enabled: true
        }
      }))
    }
  }

  // VideoÂàá„ÇäÊõø„Åà„Éè„É≥„Éâ„É©„Éº
  const handleVideoToggle = (enabled: boolean) => {
    setVideoEnabled(enabled)
    console.log('Video enabled:', enabled)
    
    // GenerationË®≠ÂÆö„Å®ÈÄ£Êê∫
    if (enabled && !generationSettings.video.enabled) {
      setGenerationSettings((prev: any) => ({
        ...prev,
        video: {
          ...prev.video,
          enabled: true
        }
      }))
    }
  }

  // ÁèæÂú®„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂèñÂæó„Åô„ÇãÈñ¢Êï∞
  const getCurrentMessage = () => {
    const textarea = document.querySelector('textarea[placeholder*="Plan, search, build"]') as HTMLTextAreaElement
    return textarea ? textarea.value : ''
  }

  // ÂãïÁîªÁîüÊàêÈñãÂßã
  const startVideoGeneration = async (videoPrompt: string) => {
    setIsGeneratingVideo(true)
    setVideoProgress(0)
    
    // ÂãïÁîªÁîüÊàê‰∏≠„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
    const loadingMessageId = (Date.now() + 1).toString()
    const loadingMessage: ChatMessageProps = {
      id: loadingMessageId,
      content: 'Video generating...',
      role: 'assistant',
      isVideoLoading: true,
      videoProgress: 0
    }
    
    setMessages(prev => [...prev, loadingMessage])

    try {
      const veoService = new VeoService(providerApiKeys['google'] || '')
      
      // „Éó„É≠„Ç∞„É¨„ÇπÊõ¥Êñ∞„ÅÆ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
      const progressInterval = setInterval(() => {
        setVideoProgress(prev => {
          const newProgress = Math.min(prev + Math.random() * 15, 90)
          setMessages(prevMessages => 
            prevMessages.map(msg => 
              msg.id === loadingMessageId 
                ? { ...msg, videoProgress: newProgress }
                : msg
            )
          )
          return newProgress
        })
      }, 500)

      // ÂãïÁîªÁîüÊàê„ÅÆÂÆüË°å
      const result = await veoService.generateVideo({
        prompt: videoPrompt,
        duration: 8,
        aspectRatio: '16:9',
        quality: 'high'
      })
      
      let finalResult = result
      
      if (result.status === 'processing') {
        console.log('üîÑ Starting video polling for ID:', result.id)
        finalResult = await veoService.pollVideoStatus(result.id, (status) => {
          console.log('Video generation status:', status)
        })
        console.log('‚úÖ Video polling completed:', finalResult)
      }

      clearInterval(progressInterval)
      setVideoProgress(100)

      // ÁîüÊàêÂÆå‰∫Ü„É°„ÉÉ„Çª„Éº„Ç∏„Å´ÁΩÆ„ÅçÊèõ„Åà
      const isSimulation = finalResult.isSimulation || finalResult.id?.startsWith('veo_sim_')
      const completedMessage: ChatMessageProps = {
        id: loadingMessageId,
        content: isSimulation 
          ? 'Video generation completed! (Simulation mode - API quota exceeded)'
          : 'Video generation completed!',
        role: 'assistant',
        videoUrl: finalResult.videoUrl,
        videoDetails: {
          duration: finalResult.duration || 8,
          aspectRatio: '16:9',
          quality: 'high',
          provider: 'google',
          model: 'veo-3.0-generate-preview',
          isSimulation: isSimulation
        }
      }
      
      console.log('üé¨ Final video message:', {
        id: completedMessage.id,
        content: completedMessage.content,
        videoUrl: completedMessage.videoUrl,
        videoDetails: completedMessage.videoDetails
      })

      setMessages(prev => {
        console.log('üîÑ Updating messages with video:', {
          loadingMessageId,
          completedMessage,
          prevMessages: prev.map(m => ({ id: m.id, content: m.content?.substring(0, 50), videoUrl: m.videoUrl }))
        })
        
        const updated = prev.map(msg => 
          msg.id === loadingMessageId ? completedMessage : msg
        )
        
        console.log('‚úÖ Updated messages:', updated.map(m => ({ id: m.id, content: m.content?.substring(0, 50), videoUrl: m.videoUrl })))
        
        return updated
      })

    } catch (error) {
      console.error('Video generation error:', error)
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁîüÊàê
      let errorContent = 'Video generation failed: Unknown error'
      
      if (error instanceof Error) {
        if (error.message.includes('429') || error.message.includes('quota') || error.message.includes('RESOURCE_EXHAUSTED')) {
          errorContent = `Video generation failed: API quota exceeded. 

To resolve this issue:
1. Check your Google Cloud billing status
2. Verify your API quota limits at https://ai.google.dev/gemini-api/docs/rate-limits
3. Consider upgrading your billing plan
4. Wait for quota reset (usually daily)

Currently using simulation mode for demonstration.`
        } else if (error.message.includes('API quota exceeded')) {
          errorContent = `Video generation failed: ${error.message}`
        } else {
          errorContent = `Video generation failed: ${error.message}`
        }
      }
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´ÁΩÆ„ÅçÊèõ„Åà
      const errorMessage: ChatMessageProps = {
        id: loadingMessageId,
        content: errorContent,
        role: 'assistant'
      }

      setMessages(prev => 
        prev.map(msg => 
          msg.id === loadingMessageId ? errorMessage : msg
        )
      )
    } finally {
      setIsGeneratingVideo(false)
      setIsGenerating(false)
      setVideoProgress(0)
      // Video„Éú„Çø„É≥„ÅØÁÑ°ÂäπÂåñ„Åó„Å™„ÅÑÔºà„É¶„Éº„Ç∂„Éº„ÅåÊâãÂãï„ÅßÂàá„ÇäÊõø„Åà„ÇãÔºâ
    }
  }

  // TTSË¶ÅÊ±Ç„ÇíÊ§úÂá∫„Åô„ÇãÈñ¢Êï∞ÔºàÂü∫Êú¨ÁöÑ„Å™Ê§úÂá∫Ôºâ
  const detectTTSRequest = (text: string): boolean => {
    const ttsKeywords = [
      'Èü≥Â£∞„Çí‰ΩúÊàê', 'Èü≥Â£∞„Åß', 'Èü≥Â£∞Âåñ', 'TTS', 'Èü≥Â£∞ÂêàÊàê',
      'Èü≥Â£∞„ÇíÁîüÊàê', 'Èü≥Â£∞„Å´Â§âÊèõ', 'Èü≥Â£∞„ÅßË™≠„Åø‰∏ä„Åí',
      'audio', 'voice', 'speech', 'tts', 'Èü≥Â£∞'
    ]
    
    const lowerText = text.toLowerCase()
    return ttsKeywords.some(keyword => lowerText.includes(keyword.toLowerCase()))
  }

  // TTSÂá¶ÁêÜ„ÇíË°å„ÅÜÈñ¢Êï∞ÔºàÊñ∞„Åó„ÅÑÈ´òÂ∫¶„Å™Ëß£ÊûêÊ©üËÉΩ‰ªò„ÅçÔºâ
  const processTTS = async (userInput: string, aiResponse: string) => {
    console.log('üéµ TTS processing started:', { audioEnabled, generationSettingsAudioEnabled: generationSettings.audio.enabled, userInput: userInput.substring(0, 50) + '...', aiResponse: aiResponse.substring(0, 50) + '...' })
    
    if (!audioEnabled || !generationSettings.audio.enabled) {
      console.log('‚ùå TTS processing cancelled: Audio not enabled')
      return
    }

    // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØ„ÄÅRouter Agent„ÅÆÂà§Êñ≠„Å´Èñ¢‰øÇ„Å™„ÅèÂ∏∏„Å´TTSÂá¶ÁêÜ„ÇíÂÆüË°å
    const shouldProcessTTS = audioEnabled && generationSettings.audio.enabled
    console.log('‚úÖ TTS processing will proceed:', shouldProcessTTS)
    

    // TTSÂá¶ÁêÜÈñãÂßãÊôÇ„Å´„É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
    const loadingMessageId = (Date.now() + 1).toString()
    const loadingMessage: ChatMessageProps = {
      id: loadingMessageId,
      content: 'audio generating...',
      role: 'assistant',
      isTTSLoading: true, // „É≠„Éº„Éá„Ç£„É≥„Ç∞Áä∂ÊÖã„ÇíÁ§∫„Åô„Éï„É©„Ç∞
      ttsInfo: {
        provider: 'loading',
        model: 'loading',
        voice: 'loading',
        language: 'loading',
        text: 'audio generating...'
      }
    }
    
    setMessages(prev => [...prev, loadingMessage])

    try {
      // API„Ç≠„Éº„ÇíÂèñÂæóÔºàÂÑ™ÂÖàÈ†Ü‰Ωç: Settings API Keys > TTS Settings > Áí∞Â¢ÉÂ§âÊï∞Ôºâ
      const geminiApiKey = providerApiKeys['google'] || 
                           generationSettings.audio.tts?.apiKey || 
                           (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_GOOGLE_GENAI_API_KEY : undefined) ||
                           (typeof process !== 'undefined' ? process.env.GOOGLE_GENAI_API_KEY : undefined)

      // OpenAI API„Ç≠„Éº„ÇíÂèñÂæóÔºàTTSË¶ÅÊ±ÇËß£ÊûêÁî®Ôºâ
      const openaiApiKey = providerApiKeys['openai'] || 
                           (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_OPENAI_API_KEY : undefined) ||
                           (typeof process !== 'undefined' ? process.env.OPENAI_API_KEY : undefined)

      if (!geminiApiKey && !openaiApiKey) {
        console.warn('TTS: No API keys available. Please configure Google or OpenAI API key in Settings ‚Üí API Keys or set environment variables.')
        return
      }

      // Hugging Face API„Ç≠„Éº„ÇíÂèñÂæó
      const huggingfaceApiKey = providerApiKeys['huggingface'] || 
                                (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_HUGGINGFACE_API_KEY : undefined) ||
                                (typeof process !== 'undefined' ? process.env.HUGGINGFACE_API_KEY : undefined)

      // Ë®≠ÂÆö„Åã„ÇâÈÅ∏Êäû„Åï„Çå„ÅüTTS„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®„É¢„Éá„É´„ÇíÂèñÂæó
      const selectedTTSProvider = generationSettings.audio.provider || 'google'
      const selectedTTSModels = generationSettings.audio.models || {}
      
      console.log('üéµ TTS Provider Selection Debug:', {
        generationSettingsAudioProvider: generationSettings.audio.provider,
        selectedTTSProvider,
        generationSettingsAudio: generationSettings.audio,
        currentTTSModel,
        audioEnabled
      })
      
      // ÊúâÂäπ„Å™TTS„É¢„Éá„É´„ÇíÂÑ™ÂÖàÂ∫¶È†Ü„Å´„ÇΩ„Éº„Éà
      const enabledTTSModels = Object.entries(selectedTTSModels)
        .filter(([_, config]: [string, any]) => config.enabled)
        .sort(([_, a]: [string, any], [__, b]: [string, any]) => (a.priority || 999) - (b.priority || 999))
      
      // ÈÅ∏Êäû„Åï„Çå„ÅüTTS„É¢„Éá„É´„Åæ„Åü„ÅØÊúÄÈ´òÂÑ™ÂÖàÂ∫¶„ÅÆTTS„É¢„Éá„É´„ÇíÈÅ∏ÊäûÔºàË®≠ÂÆöÁîªÈù¢„Å®ÂÆåÂÖ®„Å´ÂêåÊúüÔºâ
      let primaryTTSModel = currentTTSModel !== 'auto' ? currentTTSModel : 
                           enabledTTSModels.length > 0 ? enabledTTSModels[0][0] : 'gemini-2.5-flash-preview-tts'
      
      // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„É¢„Éá„É´„ÇíÈÅ∏Êäû
      if (selectedTTSProvider === 'openai') {
        // OpenAI„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÅOpenAI„É¢„Éá„É´„ÇíÂÑ™ÂÖà
        const openaiModel = enabledTTSModels.find(([model, config]: [string, any]) => model === 'gpt-4o-mini-tts')
        if (openaiModel) {
          primaryTTSModel = 'gpt-4o-mini-tts'
        }
      } else if (selectedTTSProvider === 'google') {
        // Google„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÅGoogle„É¢„Éá„É´„ÇíÂÑ™ÂÖà
        const googleModel = enabledTTSModels.find(([model, config]: [string, any]) => 
          model === 'gemini-2.5-flash-preview-tts' || model === 'gemini-2.5-pro-preview-tts'
        )
        if (googleModel) {
          primaryTTSModel = googleModel[0]
        }
      }
      
      console.log('TTS Settings:', {
        provider: selectedTTSProvider,
        selectedModel: currentTTSModel,
        primaryModel: primaryTTSModel,
        enabledModels: enabledTTSModels.map(([model, config]: [string, any]) => ({ model, priority: config.priority }))
      })



      // Inworld AI API„Ç≠„Éº„ÇíÂèñÂæó
      const inworldApiKey = providerApiKeys?.['inworld'] || 
                           (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_INWORLD_API_KEY : undefined) ||
                           (typeof process !== 'undefined' ? process.env.INWORLD_API_KEY : undefined)

      console.log('üé§ Inworld API Key Debug:', {
        fromProviderApiKeys: !!providerApiKeys?.['inworld'],
        fromEnv: !!(typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_INWORLD_API_KEY : undefined),
        fromProcess: !!(typeof process !== 'undefined' ? process.env.INWORLD_API_KEY : undefined),
        finalApiKey: !!inworldApiKey,
        apiKeyLength: inworldApiKey?.length || 0
      })

      // „É≠„Éº„Ç´„É´InworldË®≠ÂÆö
      const localInworldConfig = {
        pythonPath: process.env.PYTHON_PATH || 'python3',
        modelsDir: './models/inworld-tts-local',
        autoSetup: true
      }

      // TTS„Éû„Éç„Éº„Ç∏„É£„Éº„Çí‰ΩúÊàêÔºàË®≠ÂÆö„Åã„ÇâÈÅ∏Êäû„Åï„Çå„Åü„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Çí‰ΩøÁî®Ôºâ
      const primaryService = (() => {
        switch (selectedTTSProvider) {
          case 'google':
            return 'gemini'
          case 'openai':
            return 'openai'
          case 'inworld':
            return 'inworld'
          case 'local-inworld':
            return 'local-inworld'
          default:
            return 'gemini'
        }
      })()

      console.log('üéµ TTS Manager Configuration:', {
        selectedTTSProvider,
        primaryService,
        hasGeminiApiKey: !!geminiApiKey,
        hasOpenaiApiKey: !!openaiApiKey,
        hasInworldApiKey: !!inworldApiKey,
        hasHuggingfaceApiKey: !!huggingfaceApiKey,
        inworldApiKeyLength: inworldApiKey?.length || 0,
        providerApiKeysKeys: Object.keys(providerApiKeys || {}),
        inworldInProviderApiKeys: !!providerApiKeys?.['inworld']
      })

      const ttsManager = createTTSManager({
        primaryService,
        enableFallback: true, // „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„ÇíÊúâÂäπÂåñ„Åó„Å¶Âà©Áî®ÂèØËÉΩ„Å™„Çµ„Éº„Éì„Çπ„Çí‰ΩøÁî®
        geminiApiKey: geminiApiKey,
        openaiApiKey: openaiApiKey,
        inworldApiKey: inworldApiKey,
        huggingfaceApiKey: huggingfaceApiKey,
        localInworldConfig: localInworldConfig,
        enableAdvancedAnalysis: true,
        enableTextExtraction: true // „ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Ê©üËÉΩ„ÇíÊúâÂäπÂåñ
      })

      // LLM„Éû„Éç„Éº„Ç∏„É£„Éº„ÇíTTS„Éû„Éç„Éº„Ç∏„É£„Éº„Å´Ë®≠ÂÆöÔºà„ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Áî®Ôºâ
      if (llmManager) {
        ttsManager.setLLMManager(llmManager)
      }

      if (!ttsManager.isAnyServiceAvailable()) {
        console.warn('No TTS services are available')
        
        // Local Inworld TTS„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„ÅåÂà©Áî®„Åß„Åç„Å™„ÅÑÂ†¥Âêà„ÅÆÁâπÂà•„Å™„É°„ÉÉ„Çª„Éº„Ç∏
        if (selectedTTSProvider === 'local-inworld') {
          console.warn('‚ö†Ô∏è  Local Inworld TTS requires Electron environment. Please use the Electron version of the application.')
          // „É¶„Éº„Ç∂„Éº„Å´ÈÄöÁü•Ôºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ
          if (typeof window !== 'undefined' && !window.electronAPI) {
            alert('Local Inworld TTS requires Electron environment. Please use the Electron version of the application for local TTS functionality.')
          }
        }
        return
      }

      // TTSÂá¶ÁêÜ„Ç™„Éó„Ç∑„Éß„É≥„ÇíË®≠ÂÆöÔºàË®≠ÂÆöÁîªÈù¢„Å®ÂÆåÂÖ®„Å´ÂêåÊúüÔºâ
      const ttsOptions = {
        speaker: {
          voiceName: (() => {
            // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éá„Éï„Ç©„É´„ÉàÈü≥Â£∞„ÇíÈÅ∏Êäû
            switch (selectedTTSProvider) {
              case 'openai':
                return generationSettings.audio.tts?.defaultVoice || 'alloy'
              case 'inworld':
                return generationSettings.audio.tts?.defaultVoice || 'Ashley'
              case 'local-inworld':
                return generationSettings.audio.tts?.defaultVoice || 'tts-1'
              case 'google':
              default:
                return generationSettings.audio.tts?.defaultVoice || 'Kore'
            }
          })(),
          language: (() => {
            // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éá„Éï„Ç©„É´„ÉàË®ÄË™û„ÇíÈÅ∏Êäû
            switch (selectedTTSProvider) {
              case 'openai':
                return generationSettings.audio.tts?.defaultLanguage || 'en-US'
              case 'inworld':
                return generationSettings.audio.tts?.defaultLanguage || 'en'
              case 'local-inworld':
                return generationSettings.audio.tts?.defaultLanguage || 'en-US'
              case 'google':
              default:
                return generationSettings.audio.tts?.defaultLanguage || 'ja-JP'
            }
          })(),
          style: generationSettings.audio.tts?.defaultStyle
        },
        model: primaryTTSModel // ÈÅ∏Êäû„Åï„Çå„Åü„É¢„Éá„É´„ÇíÊåáÂÆö
      }

      console.log('üéµ TTS Processing Options:', {
        provider: selectedTTSProvider,
        selectedModel: currentTTSModel,
        model: primaryTTSModel,
        voice: ttsOptions.speaker.voiceName,
        language: ttsOptions.speaker.language,
        style: ttsOptions.speaker.style,
        localInworldConfig: selectedTTSProvider === 'local-inworld' ? localInworldConfig : undefined,
        isElectron: typeof window !== 'undefined' && !!window.electronAPI,
        windowElectronAPI: typeof window !== 'undefined' ? !!window.electronAPI : 'window undefined'
      })

      console.log('üéµ TTS Voice Selection Debug (1st):', {
        selectedTTSProvider,
        defaultVoiceFromSettings: generationSettings.audio.tts?.defaultVoice,
        selectedVoiceName: ttsOptions.speaker.voiceName,
        inworldCase: selectedTTSProvider === 'inworld' ? 'Ashley' : 'not inworld'
      })

      // TTS„Çµ„Éº„Éì„Çπ„ÅÆÂà©Áî®ÂèØËÉΩÊÄß„ÇíË©≥Á¥∞„Å´„ÉÅ„Çß„ÉÉ„ÇØ
      console.log('üîç TTS Service Availability Check:', {
        selectedProvider: selectedTTSProvider,
        isLocalInworld: selectedTTSProvider === 'local-inworld',
        electronEnvironment: typeof window !== 'undefined' && !!window.electronAPI,
        ttsManagerAvailable: ttsManager.isAnyServiceAvailable()
      })

      // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØËá™ÂãïÁöÑ„Å´TTSÂá¶ÁêÜ„ÇíÂÆüË°å„ÄÅ„Åù„ÅÜ„Åß„Å™„ÅÑÂ†¥Âêà„ÅØTTSË¶ÅÊ±Ç„ÇíÊ§úÂá∫
      let result
      console.log('üéµ Starting TTS synthesis with options:', ttsOptions)
      
      if (shouldProcessTTS) {
        // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØ„ÄÅTTSË¶ÅÊ±Ç„ÅÆÊ§úÂá∫„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Å¶Áõ¥Êé•Èü≥Â£∞ÂêàÊàê„ÇíÂÆüË°å
        console.log('üéµ Direct TTS synthesis (Audio enabled)')
        result = await ttsManager.synthesize(aiResponse, ttsOptions)
        console.log('üéµ TTS synthesis completed:', result ? 'Success' : 'Failed')
      } else {
        // Audio„Åå„Ç™„Éï„ÅÆÂ†¥Âêà„ÅØ„ÄÅTTSË¶ÅÊ±Ç„ÇíÊ§úÂá∫„Åó„Å¶„Åã„ÇâÈü≥Â£∞ÂêàÊàê„ÇíÂÆüË°å
        console.log('üéµ TTS request analysis (Audio disabled)')
        result = await ttsManager.processTTSRequest(userInput, aiResponse, ttsOptions)

        // TTSË¶ÅÊ±Ç„Åß„Å™„ÅÑÂ†¥Âêà„ÅØÂá¶ÁêÜ„ÇíÁµÇ‰∫Ü
        if (!result) {
          console.log('No TTS request detected or processing cancelled')
          return
        }
      }

      // TTSResult„Åã„ÇâaudioUrl„Çí‰ΩøÁî®ÔºàÊó¢„Å´WAV„Éò„ÉÉ„ÉÄ„Éº„ÅåËøΩÂä†Ê∏à„ÅøÔºâ
      const audioUrl = result.audioUrl || (() => {
        // „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: WAV„Éò„ÉÉ„ÉÄ„Éº„ÇíËøΩÂä†„Åó„Å¶„Éñ„É©„Ç¶„Ç∂„ÅßÂÜçÁîüÂèØËÉΩ„Å™ÂΩ¢Âºè„Å´Â§âÊèõ
        const wavData = addWavHeader(result.audioData, 24000, 1, 16)
        const blob = new Blob([wavData], { type: 'audio/wav' })
        return URL.createObjectURL(blob)
      })()

      // „É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂÆüÈöõ„ÅÆTTSÁµêÊûú„Å´ÁΩÆ„ÅçÊèõ„Åà
      const ttsMessage: ChatMessageProps = {
        id: loadingMessageId, // Âêå„ÅòID„Çí‰ΩøÁî®„Åó„Å¶„É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁΩÆ„ÅçÊèõ„Åà
        content: `Audio has been generated using ${selectedTTSProvider} (${primaryTTSModel})!`,
        role: 'assistant',
        audioUrl: audioUrl,
        audioData: result.audioData,
        isTTSLoading: false, // „É≠„Éº„Éá„Ç£„É≥„Ç∞ÂÆå‰∫Ü
        ttsInfo: {
          provider: selectedTTSProvider,
          model: primaryTTSModel,
          selectedModel: currentTTSModel,
          voice: (() => {
            // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éá„Éï„Ç©„É´„ÉàÈü≥Â£∞„ÇíÈÅ∏Êäû
            switch (selectedTTSProvider) {
              case 'vibevoice':
                return generationSettings.audio.tts?.defaultVoice || 'vibevoice-japanese'
              case 'openai':
                return generationSettings.audio.tts?.defaultVoice || 'alloy'
              case 'google':
              default:
                return generationSettings.audio.tts?.defaultVoice || 'Kore'
            }
          })(),
          language: (() => {
            // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éá„Éï„Ç©„É´„ÉàË®ÄË™û„ÇíÈÅ∏Êäû
            switch (selectedTTSProvider) {
              case 'vibevoice':
                return generationSettings.audio.tts?.defaultLanguage || 'ja-JP'
              case 'openai':
                return generationSettings.audio.tts?.defaultLanguage || 'en-US'
              case 'google':
              default:
                return generationSettings.audio.tts?.defaultLanguage || 'ja-JP'
            }
          })(),
          style: generationSettings.audio.tts?.defaultStyle,
          text: aiResponse.substring(0, 100) + (aiResponse.length > 100 ? '...' : '')
        }
      }
      
      setMessages(prev => prev.map(msg => msg.id === loadingMessageId ? ttsMessage : msg))
      
      console.log('TTS processing completed for:', aiResponse.substring(0, 50) + '...')
    } catch (error) {
      console.error('TTS processing failed:', error)
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Çí„É¶„Éº„Ç∂„Éº„Å´Ë°®Á§∫
      const errorMessage = error instanceof Error ? error.message : 'Unknown TTS error'
      
      // „É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„Çí„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´ÁΩÆ„ÅçÊèõ„Åà
      const errorMsg: ChatMessageProps = {
        id: loadingMessageId, // Âêå„ÅòID„Çí‰ΩøÁî®„Åó„Å¶„É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁΩÆ„ÅçÊèõ„Åà
        content: errorMessage.includes('quota exceeded') || errorMessage.includes('429') 
          ? `‚ö†Ô∏è **TTS Quota Exceeded**\n\nGemini TTS„ÅÆ1Êó•„ÅÆÂà©Áî®Âà∂ÈôêÔºà15ÂõûÔºâ„Å´ÈÅî„Åó„Åæ„Åó„Åü„ÄÇ\n\n**Ëß£Ê±∫ÊñπÊ≥ï:**\n‚Ä¢ 24ÊôÇÈñìÂæå„Å´ÂÜçË©¶Ë°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n‚Ä¢ Ë®≠ÂÆö„ÅßWeb Speech API„Å´Âàá„ÇäÊõø„Åà„Å¶„Åè„Å†„Åï„ÅÑ\n‚Ä¢ ÊúâÊñô„Éó„É©„É≥„Å´„Ç¢„ÉÉ„Éó„Ç∞„É¨„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ`
          : `‚ùå **TTS Error**\n\n${errorMessage}\n\n**Ëß£Ê±∫ÊñπÊ≥ï:**\n‚Ä¢ API„Ç≠„Éº„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n‚Ä¢ Ë®≠ÂÆö„ÅßTTS„Çµ„Éº„Éì„Çπ„ÇíÂ§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ`,
        role: 'assistant',
        isError: true,
        isTTSLoading: false // „É≠„Éº„Éá„Ç£„É≥„Ç∞ÂÆå‰∫Ü
      }
      
      setMessages(prev => prev.map(msg => msg.id === loadingMessageId ? errorMsg : msg))
    } finally {
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  // „ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Ê©üËÉΩ‰ªò„ÅçTTSÂá¶ÁêÜ„ÇíË°å„ÅÜÈñ¢Êï∞
  const processTTSWithTextExtraction = async (userInput: string) => {
    console.log('üéµ TTS Text Extraction processing started:', { audioEnabled, generationSettingsAudioEnabled: generationSettings.audio.enabled, userInput: userInput.substring(0, 50) + '...' })
    
    if (!audioEnabled || !generationSettings.audio.enabled) {
      console.log('‚ùå TTS Text Extraction processing cancelled: Audio not enabled')
      return
    }

    // TTSÂá¶ÁêÜÈñãÂßãÊôÇ„Å´„É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
    const loadingMessageId = (Date.now() + 1).toString()
    const loadingMessage: ChatMessageProps = {
      id: loadingMessageId,
      content: 'audio generating...',
      role: 'assistant',
      isTTSLoading: true, // „É≠„Éº„Éá„Ç£„É≥„Ç∞Áä∂ÊÖã„ÇíÁ§∫„Åô„Éï„É©„Ç∞
      ttsInfo: {
        provider: 'loading',
        model: 'loading',
        voice: 'loading',
        language: 'loading',
        text: 'audio generating...'
      }
    }
    
    setMessages(prev => [...prev, loadingMessage])

    try {
      // API„Ç≠„Éº„ÇíÂèñÂæóÔºàÂÑ™ÂÖàÈ†Ü‰Ωç: Settings API Keys > TTS Settings > Áí∞Â¢ÉÂ§âÊï∞Ôºâ
      const geminiApiKey = providerApiKeys['google'] || 
                           generationSettings.audio.tts?.apiKey || 
                           (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_GOOGLE_GENAI_API_KEY : undefined) ||
                           (typeof process !== 'undefined' ? process.env.GOOGLE_GENAI_API_KEY : undefined)

      // OpenAI API„Ç≠„Éº„ÇíÂèñÂæóÔºàTTSË¶ÅÊ±ÇËß£ÊûêÁî®Ôºâ
      const openaiApiKey = providerApiKeys['openai'] || 
                           (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_OPENAI_API_KEY : undefined) ||
                           (typeof process !== 'undefined' ? process.env.OPENAI_API_KEY : undefined)

      if (!geminiApiKey && !openaiApiKey) {
        console.warn('TTS: No API keys available. Please configure Google or OpenAI API key in Settings ‚Üí API Keys or set environment variables.')
        return
      }

      // Hugging Face API„Ç≠„Éº„ÇíÂèñÂæó
      const huggingfaceApiKey = providerApiKeys['huggingface'] || 
                                (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_HUGGINGFACE_API_KEY : undefined) ||
                                (typeof process !== 'undefined' ? process.env.HUGGINGFACE_API_KEY : undefined)

      // Ë®≠ÂÆö„Åã„ÇâÈÅ∏Êäû„Åï„Çå„ÅüTTS„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Å®„É¢„Éá„É´„ÇíÂèñÂæó
      const selectedTTSProvider = generationSettings.audio.provider || 'google'
      const selectedTTSModels = generationSettings.audio.models || {}
      
      // ÊúâÂäπ„Å™TTS„É¢„Éá„É´„ÇíÂÑ™ÂÖàÂ∫¶È†Ü„Å´„ÇΩ„Éº„Éà
      const enabledTTSModels = Object.entries(selectedTTSModels)
        .filter(([_, config]: [string, any]) => config.enabled)
        .sort(([_, a]: [string, any], [__, b]: [string, any]) => (a.priority || 999) - (b.priority || 999))
      
      // ÈÅ∏Êäû„Åï„Çå„ÅüTTS„É¢„Éá„É´„Åæ„Åü„ÅØÊúÄÈ´òÂÑ™ÂÖàÂ∫¶„ÅÆTTS„É¢„Éá„É´„ÇíÈÅ∏ÊäûÔºàË®≠ÂÆöÁîªÈù¢„Å®ÂÆåÂÖ®„Å´ÂêåÊúüÔºâ
      let primaryTTSModel = currentTTSModel !== 'auto' ? currentTTSModel : 
                           enabledTTSModels.length > 0 ? enabledTTSModels[0][0] : 'gemini-2.5-flash-preview-tts'
      
      // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„É¢„Éá„É´„ÇíÈÅ∏Êäû
      if (selectedTTSProvider === 'openai') {
        // OpenAI„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÅOpenAI„É¢„Éá„É´„ÇíÂÑ™ÂÖà
        const openaiModel = enabledTTSModels.find(([model, config]: [string, any]) => model === 'gpt-4o-mini-tts')
        if (openaiModel) {
          primaryTTSModel = 'gpt-4o-mini-tts'
        }
      } else if (selectedTTSProvider === 'google') {
        // Google„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÅGoogle„É¢„Éá„É´„ÇíÂÑ™ÂÖà
        const googleModel = enabledTTSModels.find(([model, config]: [string, any]) => 
          model === 'gemini-2.5-flash-preview-tts' || model === 'gemini-2.5-pro-preview-tts'
        )
        if (googleModel) {
          primaryTTSModel = googleModel[0]
        }
      }

      // Inworld AI API„Ç≠„Éº„ÇíÂèñÂæó
      const inworldApiKey = providerApiKeys['inworld'] || 
                           (typeof import.meta !== 'undefined' ? (import.meta as any).env?.VITE_INWORLD_API_KEY : undefined) ||
                           (typeof process !== 'undefined' ? process.env.INWORLD_API_KEY : undefined)

      // „É≠„Éº„Ç´„É´InworldË®≠ÂÆö
      const localInworldConfig = {
        pythonPath: process.env.PYTHON_PATH || 'python3',
        modelsDir: './models/inworld-tts-local',
        autoSetup: true
      }

      // TTS„Éû„Éç„Éº„Ç∏„É£„Éº„Çí‰ΩúÊàêÔºàË®≠ÂÆö„Åã„ÇâÈÅ∏Êäû„Åï„Çå„Åü„Éó„É≠„Éê„Ç§„ÉÄ„Éº„Çí‰ΩøÁî®Ôºâ
      const primaryService = (() => {
        switch (selectedTTSProvider) {
          case 'google':
            return 'gemini'
          case 'openai':
            return 'openai'
          case 'inworld':
            return 'inworld'
          case 'local-inworld':
            return 'local-inworld'
          default:
            return 'gemini'
        }
      })()

      const ttsManager = createTTSManager({
        primaryService,
        enableFallback: true, // „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„ÇíÊúâÂäπÂåñ„Åó„Å¶Âà©Áî®ÂèØËÉΩ„Å™„Çµ„Éº„Éì„Çπ„Çí‰ΩøÁî®
        geminiApiKey: geminiApiKey,
        openaiApiKey: openaiApiKey,
        inworldApiKey: inworldApiKey,
        huggingfaceApiKey: huggingfaceApiKey,
        localInworldConfig: localInworldConfig,
        enableAdvancedAnalysis: true,
        enableTextExtraction: true // „ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Ê©üËÉΩ„ÇíÊúâÂäπÂåñ
      })

      // LLM„Éû„Éç„Éº„Ç∏„É£„Éº„ÇíTTS„Éû„Éç„Éº„Ç∏„É£„Éº„Å´Ë®≠ÂÆöÔºà„ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Áî®Ôºâ
      if (llmManager) {
        ttsManager.setLLMManager(llmManager)
      }

      if (!ttsManager.isAnyServiceAvailable()) {
        console.warn('No TTS services are available')
        return
      }

      // TTSÂá¶ÁêÜ„Ç™„Éó„Ç∑„Éß„É≥„ÇíË®≠ÂÆöÔºàË®≠ÂÆöÁîªÈù¢„Å®ÂÆåÂÖ®„Å´ÂêåÊúüÔºâ
      const ttsOptions = {
        speaker: {
          voiceName: (() => {
            // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éá„Éï„Ç©„É´„ÉàÈü≥Â£∞„ÇíÈÅ∏Êäû
            switch (selectedTTSProvider) {
              case 'openai':
                return generationSettings.audio.tts?.defaultVoice || 'alloy'
              case 'inworld':
                return generationSettings.audio.tts?.defaultVoice || 'Ashley'
              case 'local-inworld':
                return generationSettings.audio.tts?.defaultVoice || 'tts-1'
              case 'google':
              default:
                return generationSettings.audio.tts?.defaultVoice || 'Kore'
            }
          })(),
          language: (() => {
            // Ë®≠ÂÆöÁîªÈù¢„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éá„Éï„Ç©„É´„ÉàË®ÄË™û„ÇíÈÅ∏Êäû
            switch (selectedTTSProvider) {
              case 'openai':
                return generationSettings.audio.tts?.defaultLanguage || 'en-US'
              case 'inworld':
                return generationSettings.audio.tts?.defaultLanguage || 'en'
              case 'local-inworld':
                return generationSettings.audio.tts?.defaultLanguage || 'en-US'
              case 'google':
              default:
                return generationSettings.audio.tts?.defaultLanguage || 'ja-JP'
            }
          })(),
          style: generationSettings.audio.tts?.defaultStyle
        },
        model: primaryTTSModel // ÈÅ∏Êäû„Åï„Çå„Åü„É¢„Éá„É´„ÇíÊåáÂÆö
      }

      console.log('üéµ TTS Text Extraction: Starting synthesis with options:', ttsOptions)
      
      console.log('üéµ TTS Voice Selection Debug (2nd):', {
        selectedTTSProvider,
        defaultVoiceFromSettings: generationSettings.audio.tts?.defaultVoice,
        selectedVoiceName: ttsOptions.speaker.voiceName,
        inworldCase: selectedTTSProvider === 'inworld' ? 'Ashley' : 'not inworld'
      })
      
      // „ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Ê©üËÉΩ‰ªò„ÅçTTSÂá¶ÁêÜ„ÇíÂÆüË°å
      const result = await ttsManager.processTTSWithTextExtraction(userInput, ttsOptions)
      
      if (!result) {
        console.log('üéµ TTS Text Extraction: No result returned, skipping audio generation')
        // „É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂâäÈô§
        setMessages(prev => prev.filter(msg => msg.id !== loadingMessageId))
        return
      }

      // TTSResult„Åã„ÇâaudioUrl„Çí‰ΩøÁî®ÔºàÊó¢„Å´WAV„Éò„ÉÉ„ÉÄ„Éº„ÅåËøΩÂä†Ê∏à„ÅøÔºâ
      const audioUrl = result.audioUrl || (() => {
        // „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ: WAV„Éò„ÉÉ„ÉÄ„Éº„ÇíËøΩÂä†„Åó„Å¶„Éñ„É©„Ç¶„Ç∂„ÅßÂÜçÁîüÂèØËÉΩ„Å™ÂΩ¢Âºè„Å´Â§âÊèõ
        const wavData = addWavHeader(result.audioData, 24000, 1, 16)
        const audioBlob = new Blob([wavData], { type: 'audio/wav' })
        return URL.createObjectURL(audioBlob)
      })()

      // TTSÊÉÖÂ†±„ÇíË®≠ÂÆö
      const ttsInfo = {
        provider: selectedTTSProvider,
        model: primaryTTSModel,
        voice: ttsOptions.speaker.voiceName,
        language: ttsOptions.speaker.language,
        style: ttsOptions.speaker.style,
        text: userInput
      }

      // „É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíTTSÁµêÊûú„É°„ÉÉ„Çª„Éº„Ç∏„Å´ÁΩÆ„ÅçÊèõ„Åà
      const ttsMessage: ChatMessageProps = {
        id: loadingMessageId, // Âêå„ÅòID„Çí‰ΩøÁî®„Åó„Å¶„É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁΩÆ„ÅçÊèõ„Åà
        content: `Audio has been generated using ${selectedTTSProvider} (${primaryTTSModel})!`,
        role: 'assistant',
        audioUrl: audioUrl,
        audioData: result.audioData,
        ttsInfo: ttsInfo,
        isTTSLoading: false // „É≠„Éº„Éá„Ç£„É≥„Ç∞ÂÆå‰∫Ü
      }
      
      setMessages(prev => prev.map(msg => msg.id === loadingMessageId ? ttsMessage : msg))
      
      console.log('üéµ TTS Text Extraction processing completed for:', userInput.substring(0, 50) + '...')
    } catch (error) {
      console.error('üéµ TTS Text Extraction processing failed:', error)
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Çí„É¶„Éº„Ç∂„Éº„Å´Ë°®Á§∫
      const errorMessage = error instanceof Error ? error.message : 'Unknown TTS error'
      
      // „É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„Çí„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´ÁΩÆ„ÅçÊèõ„Åà
      const errorMsg: ChatMessageProps = {
        id: loadingMessageId, // Âêå„ÅòID„Çí‰ΩøÁî®„Åó„Å¶„É≠„Éº„Éá„Ç£„É≥„Ç∞„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁΩÆ„ÅçÊèõ„Åà
        content: errorMessage.includes('quota exceeded') || errorMessage.includes('429') 
          ? `‚ö†Ô∏è **TTS Quota Exceeded**\n\nGemini TTS„ÅÆ1Êó•„ÅÆÂà©Áî®Âà∂ÈôêÔºà15ÂõûÔºâ„Å´ÈÅî„Åó„Åæ„Åó„Åü„ÄÇ\n\n**Ëß£Ê±∫ÊñπÊ≥ï:**\n‚Ä¢ 24ÊôÇÈñìÂæå„Å´ÂÜçË©¶Ë°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n‚Ä¢ Ë®≠ÂÆö„ÅßWeb Speech API„Å´Âàá„ÇäÊõø„Åà„Å¶„Åè„Å†„Åï„ÅÑ\n‚Ä¢ ÊúâÊñô„Éó„É©„É≥„Å´„Ç¢„ÉÉ„Éó„Ç∞„É¨„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ`
          : `‚ùå **TTS Error**\n\n${errorMessage}\n\n**Ëß£Ê±∫ÊñπÊ≥ï:**\n‚Ä¢ API„Ç≠„Éº„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n‚Ä¢ Ë®≠ÂÆö„ÅßTTS„Çµ„Éº„Éì„Çπ„ÇíÂ§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ`,
        role: 'assistant',
        isError: true,
        isTTSLoading: false // „É≠„Éº„Éá„Ç£„É≥„Ç∞ÂÆå‰∫Ü
      }
      
      setMessages(prev => prev.map(msg => msg.id === loadingMessageId ? errorMsg : msg))
    } finally {
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  // WAV„Éò„ÉÉ„ÉÄ„Éº„ÇíËøΩÂä†„Åô„Çã„Éò„É´„Éë„ÉºÈñ¢Êï∞
  function addWavHeader(pcmData: ArrayBuffer, sampleRate: number, channels: number, bitsPerSample: number): ArrayBuffer {
    const dataLength = pcmData.byteLength
    const headerLength = 44
    const totalLength = headerLength + dataLength
    
    const buffer = new ArrayBuffer(totalLength)
    const view = new DataView(buffer)
    
    // WAV„Éò„ÉÉ„ÉÄ„Éº„ÇíÊõ∏„ÅçËæº„Åø
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i))
      }
    }
    
    // RIFF„Éò„ÉÉ„ÉÄ„Éº
    writeString(0, 'RIFF')
    view.setUint32(4, totalLength - 8, true) // „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫ - 8
    writeString(8, 'WAVE')
    
    // fmt „ÉÅ„É£„É≥„ÇØ
    writeString(12, 'fmt ')
    view.setUint32(16, 16, true) // fmt„ÉÅ„É£„É≥„ÇØ„Çµ„Ç§„Ç∫
    view.setUint16(20, 1, true) // PCMÂΩ¢Âºè
    view.setUint16(22, channels, true) // „ÉÅ„É£„É≥„Éç„É´Êï∞
    view.setUint32(24, sampleRate, true) // „Çµ„É≥„Éó„É´„É¨„Éº„Éà
    view.setUint32(28, sampleRate * channels * bitsPerSample / 8, true) // „Éê„Ç§„Éà„É¨„Éº„Éà
    view.setUint16(32, channels * bitsPerSample / 8, true) // „Éñ„É≠„ÉÉ„ÇØ„Ç¢„É©„Ç§„É°„É≥„Éà
    view.setUint16(34, bitsPerSample, true) // „Éì„ÉÉ„ÉàÊ∑±Â∫¶
    
    // data „ÉÅ„É£„É≥„ÇØ
    writeString(36, 'data')
    view.setUint32(40, dataLength, true) // „Éá„Éº„Çø„Çµ„Ç§„Ç∫
    
    // PCM„Éá„Éº„Çø„Çí„Ç≥„Éî„Éº
    const pcmView = new Uint8Array(pcmData)
    const bufferView = new Uint8Array(buffer)
    bufferView.set(pcmView, headerLength)
    
    return buffer
  }

  // ÁîªÂÉèÁîüÊàê„É™„ÇØ„Ç®„Çπ„Éà„ÇíÂá¶ÁêÜ„Åô„ÇãÈñ¢Êï∞
  const handleImageGenerationRequest = async (content: string) => {
    let taskId: string | undefined
    try {
      // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØ„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê„Çí„Çπ„Ç≠„ÉÉ„Éó
      if (audioEnabled && generationSettings.audio.enabled) {
        const audioMessage: ChatMessageProps = {
          id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
          content: '',
          role: 'assistant',
          metadata: {
            title: 'Audio Mode Active'
          }
        }
        setMessages(prev => [...prev, audioMessage])
        return
      }

      console.log('üé® Starting image generation process...')
      
      // „Éó„É≠„É≥„Éó„Éà„Åã„ÇâÁîªÂÉèÁîüÊàêÁî®„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäΩÂá∫
      const imagePrompt = content
        .replace(/ÁîªÂÉè„ÇíÁîüÊàê|create image|generate image|draw|paint|ÁîªÂÉè„Çí‰ΩúÊàê|Áµµ„ÇíÊèè„ÅÑ„Å¶/gi, '')
        .trim()
      
      if (!imagePrompt) {
        const errorMessage = 'ÁîªÂÉèÁîüÊàê„ÅÆ„Éó„É≠„É≥„Éó„Éà„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã: "Áæé„Åó„ÅÑÂ§ïÊó•„ÇíÁîªÂÉè„ÅßÁîüÊàê"'
        setMessages(prev => [...prev, {
          id: (Date.now() + 1).toString(),
          content: errorMessage,
          role: 'assistant'
        }])
        return
      }

      // „Çø„Çπ„ÇØÂÆüË°å„ÇíÈñãÂßã
      taskId = await startTask({
        taskType: 'generation',
        title: 'Image Generation',
        description: `ÁîªÂÉèÁîüÊàê‰∏≠: ${imagePrompt.substring(0, 50)}${imagePrompt.length > 50 ? '...' : ''}`,
        estimatedDuration: 15000,
        metadata: {
          complexity: 'medium',
          priority: 'medium',
          resources: ['AI Image Model']
        }
      })

      // Áí∞Â¢ÉÂ§âÊï∞„ÅÆË®≠ÂÆöÁä∂Ê≥Å„ÇíÁ¢∫Ë™ç
      const config = await checkGoogleAIConfig()
      
      if (!config.isConfigured) {
        // Áí∞Â¢ÉÂ§âÊï∞„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÅÆ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂá¶ÁêÜ
        const setupMessage = `## üé® ÁîªÂÉèÁîüÊàê„ÅÆË®≠ÂÆö„ÅåÂøÖË¶Å„Åß„Åô

ÁîªÂÉèÁîüÊàêÊ©üËÉΩ„Çí‰ΩøÁî®„Åô„Çã„Å´„ÅØ„ÄÅGoogle AI API„ÅÆË®≠ÂÆö„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ

### üìã Ë®≠ÂÆöÊâãÈ†Ü:

1. **Google Cloud Console**„Åß„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê
2. **Vertex AI API**„ÇíÊúâÂäπÂåñ
3. **API Key**„Çí‰ΩúÊàê
4. **Project ID**„ÇíÂèñÂæó

### üîß Áí∞Â¢ÉÂ§âÊï∞„ÅÆË®≠ÂÆö:

„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅÆ„É´„Éº„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´\`.env\`„Éï„Ç°„Ç§„É´„Çí‰ΩúÊàê„Åó„ÄÅ‰ª•‰∏ã„ÇíËøΩÂä†„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö

\`\`\`bash
# Google AI API Key for Gemini File Upload and Image Generation
VITE_GOOGLE_API_KEY=your_google_api_key_here

# Google Cloud Project ID for Vertex AI Image Generation
VITE_GOOGLE_PROJECT_ID=your_google_cloud_project_id_here

# Google Cloud Location for Vertex AI (default: us-central1)
VITE_GOOGLE_LOCATION=us-central1
\`\`\`

### üìñ Ë©≥Á¥∞„Å™Ë®≠ÂÆöÊñπÊ≥ï:

Ë©≥Á¥∞„Å™Ë®≠ÂÆöÊñπÊ≥ï„Å´„Å§„ÅÑ„Å¶„ÅØ„ÄÅ[README.md](./README.md)„ÅÆ„ÄåGemini Image Generation Integration„Äç„Çª„ÇØ„Ç∑„Éß„É≥„ÇíÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

### üîÑ Ë®≠ÂÆöÂæå„ÅÆÂÜçËµ∑Âãï:

Áí∞Â¢ÉÂ§âÊï∞„ÇíË®≠ÂÆö„Åó„ÅüÂæå„ÄÅ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÂÜçËµ∑Âãï„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

---
**ÁèæÂú®„ÅÆ„Éó„É≠„É≥„Éó„Éà:** ${imagePrompt}
**Áä∂ÊÖã:** Ë®≠ÂÆöÂæÖ„Å°`

        setMessages(prev => [...prev, {
          id: (Date.now() + 1).toString(),
          content: setupMessage,
          role: 'assistant'
        }])
        
        // „Çø„Çπ„ÇØÂÆå‰∫Ü
        if (taskId) {
          completeTask(taskId, false)
        }
        return
      }

      // Gemini Image Service„Çí‰ΩøÁî®„Åó„Å¶ÁîªÂÉèÁîüÊàê
      const geminiImageService = new GeminiImageService()

      // LLM„Çµ„Éº„Éì„Çπ„ÇíÂèñÂæóÔºà„Éó„É≠„É≥„Éó„ÉàË£úÂÆå„Ç®„Éº„Ç∏„Çß„É≥„ÉàÁî®Ôºâ
      let llmService = null
      try {
        if (llmManager) {
          // ÁèæÂú®„ÅÆLLM„Çµ„Éº„Éì„Çπ„ÇíÂèñÂæó
          llmService = llmManager.getLLMService()
        }
      } catch (error) {
        console.warn('LLM„Çµ„Éº„Éì„Çπ„ÅåÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì„ÄÇ„Éó„É≠„É≥„Éó„ÉàË£úÂÆåÊ©üËÉΩ„ÅØÁÑ°Âäπ„Å´„Å™„Çä„Åæ„Åô:', error)
      }

      // Gemini Image Service„ÇíË®≠ÂÆöÔºà„Éó„É≠„É≥„Éó„ÉàË£úÂÆå„Ç®„Éº„Ç∏„Çß„É≥„Éà‰ªò„ÅçÔºâ
      await geminiImageService.configure(
        config.googleApiKey!, 
        config.googleProjectId!, 
        config.googleLocation,
        llmService || undefined,
        true, // „Éó„É≠„É≥„Éó„ÉàË£úÂÆåÊ©üËÉΩ„ÇíÊúâÂäπÂåñ
        true  // API„Ç≠„ÉºÊ§úË®º„Çí„Çπ„Ç≠„ÉÉ„ÉóÔºàÁîªÂÉèÁîüÊàêÊôÇ„Å´ÂÆüÈöõ„ÅÆ„ÉÜ„Çπ„Éà„ÇíË°å„ÅÜÔºâ
      )

      // ÁîªÂÉèÁîüÊàê„É™„ÇØ„Ç®„Çπ„Éà„Çí‰ΩúÊàê
      const imageRequest = {
        prompt: imagePrompt,
        model: 'gemini-2.0-flash-preview-image-generation',
        aspectRatio: '1:1' as const,
        quality: 'standard' as const,
        style: 'photorealistic' as const,
        safetyFilter: 'block_some' as const,
        personGeneration: 'dont_allow' as const
      }

      console.log('üîÑ Generating image with prompt:', imagePrompt)
      
      // ÁîªÂÉèÁîüÊàê„ÇíÂÆüË°å
      const imageResponse = await geminiImageService.generateImage(imageRequest)
      
      console.log('‚úÖ Image generation completed:', imageResponse)

      // ÁîüÊàê„Åï„Çå„ÅüÁîªÂÉè„Çí„É°„ÉÉ„Çª„Éº„Ç∏„Å®„Åó„Å¶ËøΩÂä†
      const assistantMessage: ChatMessageProps = {
        id: (Date.now() + 1).toString(),
        content: `image generated!`,
        role: 'assistant',
        images: imageResponse.images // ÁîüÊàê„Åï„Çå„ÅüÁîªÂÉè„Éá„Éº„Çø„ÇíËøΩÂä†
      }
      
      setMessages(prev => [...prev, assistantMessage])
      
      // „Çø„Çπ„ÇØÂÆå‰∫Ü
      if (taskId) {
        completeTask(taskId, true)
      }

    } catch (error) {
      console.error('‚ùå Image generation failed:', error)
      
      const errorMessage = `ÁîªÂÉèÁîüÊàê‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: ${error instanceof Error ? error.message : 'Unknown error'}`
      
      setMessages(prev => [...prev, {
        id: (Date.now() + 1).toString(),
        content: errorMessage,
        role: 'assistant'
      }])
      
      // „Çø„Çπ„ÇØ„Ç®„É©„Éº
      if (taskId) {
        completeTask(taskId, false)
      }
    } finally {
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  // „Ç¶„Çß„ÉñÊ§úÁ¥¢„ÇíÂÆüË°å„Åô„ÇãÈñ¢Êï∞
  const performWebSearch = async (query: string): Promise<string | null> => {
    if (!webSearchEnabled) {
      return null
    }

    try {
      console.log('Performing web search for:', query)
      const searchResult = await webSearchManager.performWebSearch(query, 'google', 'auto')
      
      // Ê§úÁ¥¢ÁµêÊûú„ÇíMarkdownÂΩ¢Âºè„Åß„Éï„Ç©„Éº„Éû„ÉÉ„Éà
      const searchContext = webSearchManager.formatSearchResultAsMarkdown(searchResult)
      
      return searchContext
    } catch (error) {
      console.error('Web search failed:', error)
      return `**„Ç¶„Çß„ÉñÊ§úÁ¥¢„Ç®„É©„Éº:** ${error instanceof Error ? error.message : 'Ê§úÁ¥¢„Å´Â§±Êïó„Åó„Åæ„Åó„Åü'}\n`
    }
  }

  const handleSendMessage = async (content: string, contexts?: Array<{id: string, type: string, name: string, value?: string}>) => {
    if (!content.trim() && selectedFiles.length === 0) return

    setIsTyping(true)
    console.log('üîÑ Setting isGenerating to true in handleSendMessage')
    setIsGenerating(true)
    setLoadingState('text')

    // „Ç¶„Çß„ÉñÊ§úÁ¥¢„ÇíÂÆüË°åÔºàÊúâÂäπ„Å™Â†¥ÂêàÔºâ
    let searchContext = ''
    if (webSearchEnabled) {
      try {
        const searchResult = await performWebSearch(content.trim())
        if (searchResult) {
          searchContext = searchResult + '\n\n'
        }
      } catch (error) {
        console.error('Web search error during message send:', error)
      }
    }

    // YouTube URL„ÇíÊ§úÂá∫
    const youtubeRegex = /^(https?:\/\/)?(www\.)?(youtube\.com|youtu\.be)\/.+/
    const isYouTubeUrl = youtubeRegex.test(content.trim())

    // „É¶„Éº„Ç∂„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†Ôºà„Éï„Ç°„Ç§„É´‰ªò„ÅçÔºâ
    const userMessage: ChatMessageProps = {
      id: Date.now().toString(),
      content: content.trim(),
      role: 'user',
      files: selectedFiles.length > 0 ? selectedFiles : undefined
    }
    console.log('‚ûï Adding user message:', userMessage)
    setMessages(prev => [...prev, userMessage])

    // „Éï„Ç°„Ç§„É´„Çí‰∏ÄÊôÇ‰øùÂ≠òÔºàAPIÂëº„Å≥Âá∫„ÅóÂæå„Å´„ÇØ„É™„Ç¢Ôºâ
    const filesToSend = [...selectedFiles]
    setSelectedFiles([])

    try {
      // Video„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØÂãïÁîªÁîüÊàê„ÇíÂÆüË°å
      if (videoEnabled) {
        await startVideoGeneration(content.trim())
        return
      }

      // ÁèæÂú®„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ
      const currentConfig = aiSDKService.getCurrentConfig()
      
      // Ollama„Åæ„Åü„ÅØLlamaCpp„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÄÅ„É¢„Éá„É´Â≠òÂú®„ÉÅ„Çß„ÉÉ„ÇØ„Å®Ëá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
      if (currentConfig && (currentConfig.providerId === 'ollama' || currentConfig.providerId === 'llama-cpp') && llmManager) {
        try {
          setIsDownloading(true)
          setDownloadProgress({ status: 'checking', message: 'Checking model availability...' })

          // „É¢„Éá„É´„ÅåÂà©Áî®ÂèØËÉΩ„Åã„ÉÅ„Çß„ÉÉ„ÇØ„Åó„ÄÅÂøÖË¶Å„Å´Âøú„Åò„Å¶„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
          await llmManager.ensureModelAvailable(currentConfig.modelId, (progress) => {
            // „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÅåÈñãÂßã„Åï„Çå„Åü„Çâ„ÄåChecking model availability...„Äç„ÇíÈùûË°®Á§∫„Å´„Åô„Çã
            if (progress && progress.status === 'downloading') {
              setDownloadProgress(null)
            }
            // ÈÄ≤Ë°åÁä∂Ê≥Å„ÅåÂ≠òÂú®„Åô„ÇãÂ†¥Âêà„ÅÆ„ÅøÊõ¥Êñ∞ÔºàcheckingÁä∂ÊÖã„ÅÆÈáçË§á„ÇíÈò≤„ÅêÔºâ
            if (progress && (progress.status === 'starting' || progress.status === 'downloading' || progress.status === 'verifying' || progress.status === 'completed' || progress.status === 'error')) {
              setDownloadProgress(progress)
            }
            console.log('Model availability check progress:', progress)
            console.log('Progress status:', progress?.status)
            console.log('Progress message:', progress?.message)
          })

          setDownloadProgress({ status: 'completed', message: 'Model ready!' })
        } catch (error) {
          console.error('Failed to ensure model availability:', error)
          setLastError(`Model not available: ${error}`)
          setIsTyping(false)
          setIsGenerating(false)
          setLoadingState('idle')
          return
        } finally {
          setIsDownloading(false)
          setDownloadProgress(null)
        }
      }

      if (content.toLowerCase().includes('sequential') || content.toLowerCase().includes('step by step') || content.toLowerCase().includes('plan')) {
        await handleSequentialThinkingRequest(content, contexts)
      } else if (isYouTubeUrl && selectedFiles.length === 0) {
        // YouTube URL„ÅÆÂ†¥Âêà„ÅØÂãïÁîªÂàÜÊûê„ÇíÂÆüË°å
        await handleYouTubeVideoRequest(content, contexts)
      } else {
        await handleRegularChatRequest(content, contexts, filesToSend, searchContext)
      }
    } catch (error) {
      console.error('Error handling message:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred'
      setLastError(errorMessage)
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  // „Çø„Çπ„ÇØÂÆüË°å„Éò„É´„Éë„ÉºÈñ¢Êï∞
  const startTask = async (taskInfo: {
    taskType: 'analysis' | 'generation' | 'processing' | 'search' | 'computation' | 'optimization' | 'learning' | 'custom'
    title: string
    description: string
    estimatedDuration?: number
    metadata?: {
      model?: string
      complexity?: string
      priority?: 'low' | 'medium' | 'high'
      resources?: string[]
    }
  }) => {
    // Chat Response Generation„Çø„Çπ„ÇØ„ÇíÈô§Â§ñ
    if (taskInfo.title && taskInfo.title.includes('Chat Response Generation')) {
      return `excluded_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    }

    const taskId = await addTask({
      ...taskInfo,
      status: 'pending',
      progress: 0
    })

    // „Åô„Åê„Å´ÂÆüË°å‰∏≠„Å´Â§âÊõ¥
    setTimeout(() => {
      updateTask(taskId, { status: 'running', progress: 10 })
    }, 100)

    return taskId
  }

  const updateTaskProgress = (taskId: string, progress: number, step?: string, stepIndex?: number) => {
    updateTask(taskId, { 
      progress, 
      currentStep: step,
      currentStepIndex: stepIndex
    })
  }

  const completeTask = (taskId: string, success: boolean = true) => {
    updateTask(taskId, { 
      status: success ? 'completed' : 'error',
      progress: 100
    })
  }

  // „Éï„Ç°„Ç§„É´‰ΩúÊàê„Éò„É´„Éë„ÉºÈñ¢Êï∞
  const startFileCreation = (fileInfo: {
    fileName: string
    fileType: 'text' | 'image' | 'video' | 'audio' | 'code' | 'archive' | 'document' | 'other'
    estimatedDuration?: number
    metadata?: {
      size?: number
      format?: string
      quality?: string
      compression?: string
    }
  }) => {
    const fileCreationId = addFileCreation({
      ...fileInfo,
      status: 'creating',
      progress: 0
    })

    // „Åô„Åê„Å´Âá¶ÁêÜ‰∏≠„Å´Â§âÊõ¥
    setTimeout(() => {
      updateFileCreation(fileCreationId, { status: 'processing', progress: 10 })
    }, 100)

    return fileCreationId
  }

  const updateFileCreationProgress = (fileCreationId: string, progress: number, step?: string, stepIndex?: number) => {
    updateFileCreation(fileCreationId, { 
      progress, 
      currentStep: step,
      currentStepIndex: stepIndex
    })
  }

  const completeFileCreation = (fileCreationId: string, success: boolean = true) => {
    updateFileCreation(fileCreationId, { 
      status: success ? 'completed' : 'error',
      progress: 100
    })
  }

  const handleSequentialThinkingRequest = async (content: string, contexts?: Array<{id: string, type: string, name: string, value?: string}>) => {
    let taskId: string | undefined
    try {
      // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØ„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê„Çí„Çπ„Ç≠„ÉÉ„Éó
      if (audioEnabled && generationSettings.audio.enabled) {
        // Á©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅØËøΩÂä†„Åó„Å™„ÅÑ
        return
      }

      setIsAgentMode(true)
      setShowSequentialThinking(true)

      // „Çø„Çπ„ÇØÂÆüË°å„ÇíÈñãÂßã
      taskId = await startTask({
        taskType: 'analysis',
        title: 'Sequential Thinking Analysis',
        description: `Ë§áÈõë„Å™„Çø„Çπ„ÇØ„Äå${content}„Äç„ÅÆÊÆµÈöéÁöÑÊÄùËÄÉÂàÜÊûê„ÇíÂÆüË°å‰∏≠`,
        estimatedDuration: 30000, // 30Áßí
        metadata: {
          complexity: 'high',
          priority: 'high',
          resources: ['AI Model', 'Planning Tools']
        }
      })

      if (aiSDKService.isProviderConfigured()) {
        // ÁèæÂú®„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„ÇíÂèñÂæó
        const currentConfig = aiSDKService.getCurrentConfig()
        if (!currentConfig) {
          throw new Error('No provider configured')
        }

        // „Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅÆAPI Key„ÇíÂèñÂæó
        const apiKey = providerApiKeys[currentConfig.providerId]
        if (!apiKey) {
          throw new Error(`API Key not found for provider: ${currentConfig.providerId}`)
        }

        // API Key„Åß„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíÂÜçË®≠ÂÆö
        await aiSDKService.configureProvider({
          ...currentConfig,
          apiKey: apiKey
        })

        // „Çø„Çπ„ÇØÈÄ≤Êçó„ÇíÊõ¥Êñ∞
        if (taskId) {
          updateTaskProgress(taskId, 30, 'AI„É¢„Éá„É´Ë®≠ÂÆöÂÆå‰∫Ü', 1)
        }

        // Use AI SDK with tools for Sequential Thinking
        let fullResponse = ''
        const toolCalls: any[] = []
        
        if (taskId) {
          updateTaskProgress(taskId, 50, 'AIÂàÜÊûêÂÆüË°å‰∏≠', 2)
        }
        
        setIsTyping(true) // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÈñãÂßãÊôÇ„Å´isTyping„Çítrue„Å´Ë®≠ÂÆö
        let lastFullResponse = '' // ÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØÁî®
        await aiSDKService.streamResponse(
          `You are an AI assistant specialized in video production and media editing. The user wants to: ${content}. 
           Use the available tools to accomplish this task step by step. Think through the process and use tools when needed.
           ${contexts ? `Context: ${contexts.map(ctx => `@${ctx.name}`).join(', ')}` : ''}`,
          (chunk: string) => {
            fullResponse += chunk
            // ÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØ
            if (fullResponse !== lastFullResponse) {
              setStreamingResponse(fullResponse)
              lastFullResponse = fullResponse
            }
          }
        )

        if (taskId) {
          updateTaskProgress(taskId, 80, 'ÁµêÊûúÁîüÊàê‰∏≠', 3)
        }

        // Create Sequential Thinking plan
        const plan: SequentialThinkingPlan = {
          id: Date.now().toString(),
          steps: [
            {
              id: '1',
              type: 'thinking',
              content: `Analyzing user request: "${content}". This appears to be a request for ${content.toLowerCase().includes('video') ? 'video creation' : 'content processing'}.`,
              timestamp: new Date()
            },
            ...toolCalls.map((toolCall, index) => ({
              id: (index + 2).toString(),
              type: 'tool_call' as const,
              content: '',
              toolCall: {
                name: toolCall.name,
                arguments: toolCall.arguments
              },
              timestamp: new Date()
            }))
          ],
          status: 'completed',
          createdAt: new Date(),
          updatedAt: new Date()
        }

        setCurrentPlan(plan)

        // Add assistant message
        const assistantMessage: ChatMessageProps = {
          id: (Date.now() + 1).toString(),
          content: fullResponse,
          role: 'assistant',
        }
        setMessages(prev => [...prev, assistantMessage])
        setStreamingResponse('')
        setIsTyping(false) // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„Å´isTyping„Çífalse„Å´Ë®≠ÂÆö
        setIsGenerating(false)
      } else {
        // Fallback to mock Sequential Thinking
        const mockPlan: SequentialThinkingPlan = {
          id: Date.now().toString(),
          steps: [
            {
              id: '1',
              type: 'thinking',
              content: `Analyzing user request: "${content}". This appears to be a request for ${content.toLowerCase().includes('video') ? 'video creation' : 'content processing'}.`,
              timestamp: new Date()
            },
            {
              id: '2',
              type: 'tool_call',
              content: '',
              toolCall: {
                name: content.toLowerCase().includes('url') ? 'web_scraper' : 'file_processor',
                arguments: content.toLowerCase().includes('url') ? { url: 'https://example.com' } : { filePath: 'input.txt', type: 'text' }
              },
              timestamp: new Date()
            },
            {
              id: '3',
              type: 'result',
              content: '',
              result: { success: true, processedData: 'Sample processed data' },
              timestamp: new Date()
            }
          ],
          status: 'completed',
          createdAt: new Date(),
          updatedAt: new Date()
        }

        setCurrentPlan(mockPlan)

        // „Çø„Çπ„ÇØÂÆå‰∫Ü
        if (taskId) {
          completeTask(taskId, true)
        }

        setTimeout(() => {
          const assistantMessage: ChatMessageProps = {
            id: (Date.now() + 1).toString(),
            content: `I've processed your request using Sequential Thinking! Here's what I did:\n\n1. Analyzed your request\n2. Used appropriate tools to process the content\n3. Generated the results\n\n${content.toLowerCase().includes('video') ? 'Your video is ready!' : 'Your content has been processed successfully!'}`,
            role: 'assistant',
          }
          setMessages(prev => [...prev, assistantMessage])
          setIsTyping(false)
          setIsGenerating(false)
        }, 3000)
      }
    } catch (error) {
      console.error('Error in Sequential Thinking:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error'
      setLastError(errorMessage)
      
      // „Çø„Çπ„ÇØ„Ç®„É©„Éº
      if (taskId) {
        completeTask(taskId, false)
      }
      
      const assistantMessage: ChatMessageProps = {
        id: (Date.now() + 1).toString(),
        content: `‚ùå Sequential Thinking failed: ${errorMessage}`,
        role: 'assistant',
      }
      setMessages(prev => [...prev, assistantMessage])
      setIsGenerating(false)
    } finally {
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
      setIsAgentMode(false)
    }
  }

  const handleRegularChatRequest = async (content: string, contexts?: Array<{id: string, type: string, name: string, value?: string}>, files?: File[], searchContext?: string) => {
    let taskId: string | undefined
    try {

      // ÁîªÂÉèÁîüÊàê„É™„ÇØ„Ç®„Çπ„Éà„ÅÆÊ§úÂá∫Ôºà„Çà„ÇäÊüîËªü„Å™Ê§úÂá∫Ôºâ
      const isImageGenerationRequest = createImageEnabled && (
        content.toLowerCase().includes('ÁîªÂÉè„ÇíÁîüÊàê') || 
        content.toLowerCase().includes('create image') ||
        content.toLowerCase().includes('generate image') ||
        content.toLowerCase().includes('draw') ||
        content.toLowerCase().includes('paint') ||
        content.toLowerCase().includes('ÁîªÂÉè„Çí‰ΩúÊàê') ||
        content.toLowerCase().includes('Áµµ„ÇíÊèè„ÅÑ„Å¶') ||
        content.toLowerCase().includes('ÁîªÂÉè') && content.toLowerCase().includes('‰Ωú„Å£„Å¶') ||
        content.toLowerCase().includes('picture') && content.toLowerCase().includes('create') ||
        content.toLowerCase().includes('image') && content.toLowerCase().includes('generate')
      )

      if (isImageGenerationRequest) {
        console.log('üñºÔ∏è Image generation request detected')
        console.log('üìä Image generation settings:', {
          createImageEnabled,
          generationSettings: generationSettings.image,
          content: content.substring(0, 100) + '...'
        })
        await handleImageGenerationRequest(content)
        return
      }

      // Ê§úÁ¥¢„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„ÇíÂê´„ÇÅ„Å¶content„ÇíÊã°Âºµ
      let enhancedContent = content
      if (searchContext) {
        enhancedContent = `${searchContext}**„É¶„Éº„Ç∂„Éº„Åã„Çâ„ÅÆË≥™Âïè:**\n${content}`
      }
      
      // ÂÖ•ÂäõÂàÜÊûê„ÇíÂÆüË°åÔºàAudio„ÅÆÁä∂ÊÖã„ÇíÂê´„ÇÅ„ÇãÔºâ
      const analysis = inputAnalyzer.analyzeInput(enhancedContent, { 
        files,
        audioEnabled: audioEnabled && generationSettings.audio.enabled
      })
      setCurrentAnalysis(analysis)
      
      console.log('Input Analysis:', analysis)

      // „Çø„Çπ„ÇØÂÆüË°å„ÇíÈñãÂßã
      taskId = await startTask({
        taskType: analysis.complexity === 'complex' ? 'analysis' : 'generation',
        title: analysis.suggestedAgent && analysis.suggestedAgent !== 'file_processor' ? `${analysis.suggestedAgent} Agent Execution` : 'Chat Response Generation',
        description: `„É¶„Éº„Ç∂„Éº„ÅÆ„É™„ÇØ„Ç®„Çπ„Éà„Äå${content.substring(0, 50)}${content.length > 50 ? '...' : ''}„Äç„ÇíÂá¶ÁêÜ‰∏≠`,
        estimatedDuration: analysis.complexity === 'complex' ? 15000 : 8000,
        metadata: {
          complexity: analysis.complexity,
          priority: analysis.complexity === 'complex' ? 'high' : 'medium',
          resources: files && files.length > 0 ? ['File Processing', 'AI Model'] : ['AI Model']
        }
      })
      
      // Router Agent System„ÅåÂà©Áî®ÂèØËÉΩ„Åß„ÄÅRouter Agent„ÅåÂøÖË¶Å„Å™Â†¥Âêà
      if (llmManager && analysis.needsRouterAgent) {
        // „Ç®„Éº„Ç∏„Çß„É≥„ÉàÊÉÖÂ†±„ÇíË®≠ÂÆöÔºàreasoning„ÅØÈùûË°®Á§∫Ôºâ
        setAgentInfo({
          type: analysis.suggestedAgent || null,
          confidence: analysis.confidence,
          reasoning: ''
        })
        
        // Router Agent System„ÅßÂá¶ÁêÜ
        const response = await llmManager.routeAndExecute(enhancedContent, {
          files,
          contexts,
          analysis
        })
        
        // Audio„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØ„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„É¨„Çπ„Éù„É≥„Çπ„ÇíÈùûË°®Á§∫„Å´„Åó„Å¶TTSÂá¶ÁêÜ„ÅÆ„Åø„ÇíÂÆüË°å
        const shouldHideInAudioMode = audioEnabled && generationSettings.audio.enabled
        
        // Á©∫„ÅÆ„É¨„Çπ„Éù„É≥„Çπ„ÇÑÁÑ°Âäπ„Å™„É¨„Çπ„Éù„É≥„Çπ„ÅÆÂ†¥Âêà„ÅØ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†„Åó„Å™„ÅÑ
        if (response.content && 
            response.content.trim() !== '' && 
            response.content !== '{}' && 
            response.content !== '[]' && 
            response.content !== 'null' && 
            response.content !== 'undefined' &&
            response.content !== '[object Object]' &&
            response.content !== '[object Array]' &&
            !/^\s*\{\s*\}\s*$/.test(response.content) &&
            !/^\s*\[\s*\]\s*$/.test(response.content) &&
            !response.content.includes('[object Object]') &&
            !response.content.includes('[object Array]') &&
            !response.content.includes('{}') &&
            !response.content.includes('[]') &&
            !shouldHideInAudioMode) {
          
          // „Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
          const assistantMessage: ChatMessageProps = {
            id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
            content: response.content,
            role: 'assistant',
            images: response.images, // ÁîüÊàê„Åï„Çå„ÅüÁîªÂÉè„Éá„Éº„Çø„ÇíËøΩÂä†
            metadata: response.agentType && response.agentType !== 'file_processor' ? {
              agentType: response.agentType,
              confidence: response.confidence || analysis.confidence,
              executionTime: response.executionTime,
              complexity: analysis.complexity,
              title: `${response.agentType} Agent Execution`
            } : {
              title: 'Chat Response Generation'
            }
          }
          
          console.log('‚úÖ Adding Router Agent message:', assistantMessage)
          setMessages(prev => [...prev, assistantMessage])
        } else {
          if (shouldHideInAudioMode) {
            console.log('üéµ Audio mode active - hiding text response for TTS processing')
          } else {
            console.log('‚ùå Skipping empty Router Agent response:', response.content)
          }
        }
        
        // Audio„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØ„ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Ê©üËÉΩ‰ªò„ÅçTTSÂá¶ÁêÜ„ÇíÂÆüË°å
        if (audioEnabled && generationSettings.audio.enabled) {
          console.log('üéµ Audio enabled, performing TTS processing with text extraction')
          await processTTSWithTextExtraction(content)
        }
        
        return
      }
      
      // ÈÄöÂ∏∏„ÅÆLLMÂá¶ÁêÜÔºàRouter Agent„Åå‰∏çË¶Å„Å™Â†¥ÂêàÔºâ
      setAgentInfo(null)
      
      // ÁèæÂú®ÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´„ÇíÁ¢∫Ë™ç„Åó„ÄÅÈÅ©Âàá„Å™„Çµ„Éº„Éì„Çπ„ÇíÈÅ∏Êäû
      if (currentSelectedModel && currentSelectedModel !== 'auto') {
        const [selectedProviderId, selectedModelId] = currentSelectedModel.split(':')
        
        // Ollama„Åæ„Åü„ÅØLlamaCpp„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÄÅLLM Manager„Çí‰ΩøÁî®
        if (selectedProviderId === 'ollama' || selectedProviderId === 'llama-cpp') {
          if (llmManager) {
            // LLM Manager„Çí‰ΩøÁî®„Åó„Å¶„ÉÅ„É£„ÉÉ„ÉàÂá¶ÁêÜ
            const response = await llmManager.processUserRequestLegacy(enhancedContent, {
              files,
              contexts,
              analysis
            })
            
            // „É¨„Çπ„Éù„É≥„Çπ„ÅÆÂÜÖÂÆπ„ÇíÂèñÂæó
            let responseContent = ''
            if (typeof response === 'string') {
              responseContent = response
            } else if (response && typeof response === 'object') {
              // ÂÑ™ÂÖàÈ†Ü‰Ωç: content > response > text
              responseContent = response.content || response.response || response.text || ''
              
              // „Éá„Éê„ÉÉ„Ç∞Áî®Ôºö„É¨„Çπ„Éù„É≥„Çπ„ÅåÁ©∫„ÅÆÂ†¥Âêà„ÅÆ„É≠„Ç∞
              if (!responseContent || responseContent.trim() === '') {
                console.warn('Empty response content detected:', {
                  content: response.content,
                  response: response.response,
                  text: response.text,
                  fullResponse: response
                })
              }
            } else {
              responseContent = 'Error: Invalid response format'
            }
            
            // „Éá„Éê„ÉÉ„Ç∞Áî®Ôºö„É¨„Çπ„Éù„É≥„ÇπÂÜÖÂÆπ„Çí„É≠„Ç∞Âá∫Âäõ
            console.log('üîç Response content check:', {
              responseContent: responseContent?.substring(0, 50) + (responseContent && responseContent.length > 50 ? '...' : ''),
              isEmpty: !responseContent || responseContent.trim() === '',
              isObject: responseContent === '{}',
              isArray: responseContent === '[]',
              isNull: responseContent === 'null',
              isUndefined: responseContent === 'undefined',
              hasWhitespaceOnly: /^\s*$/.test(responseContent),
              hasWhitespaceObject: /^\s*\{\s*\}\s*$/.test(responseContent),
              hasWhitespaceArray: /^\s*\[\s*\]\s*$/.test(responseContent)
            })
            
            // Audio„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØ„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„É¨„Çπ„Éù„É≥„Çπ„ÇíÈùûË°®Á§∫„Å´„Åó„Å¶TTSÂá¶ÁêÜ„ÅÆ„Åø„ÇíÂÆüË°å
            const shouldHideInAudioMode = audioEnabled && generationSettings.audio.enabled
            
            // Á©∫„ÅÆ„É¨„Çπ„Éù„É≥„Çπ„ÇÑÁÑ°Âäπ„Å™„É¨„Çπ„Éù„É≥„Çπ„ÅÆÂ†¥Âêà„ÅØ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†„Åó„Å™„ÅÑ
            if (responseContent && 
                responseContent.trim() !== '' && 
                responseContent !== '{}' && 
                responseContent !== '[]' && 
                responseContent !== 'null' && 
                responseContent !== 'undefined' &&
                responseContent !== '[object Object]' &&
                responseContent !== '[object Array]' &&
                !/^\s*\{\s*\}\s*$/.test(responseContent) &&
                !/^\s*\[\s*\]\s*$/.test(responseContent) &&
                !responseContent.includes('[object Object]') &&
                !responseContent.includes('[object Array]') &&
                !responseContent.includes('{}') &&
                !responseContent.includes('[]') &&
                !shouldHideInAudioMode) {
              const assistantMessage: ChatMessageProps = {
                id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
                content: responseContent,
                role: 'assistant',
                metadata: {
                  title: analysis.suggestedAgent && analysis.suggestedAgent !== 'file_processor' ? `${analysis.suggestedAgent} Agent Execution` : 'Chat Response Generation'
                }
              }
              
              console.log('‚úÖ Adding assistant message:', assistantMessage)
              setMessages(prev => [...prev, assistantMessage])
            } else {
              if (shouldHideInAudioMode) {
                console.log('üéµ Audio mode active - hiding text response for TTS processing')
              } else {
                console.log('‚ùå Skipping empty/invalid response:', responseContent)
              }
            }
            
            // Audio„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØTTSÂá¶ÁêÜ„ÇíÂÆüË°åÔºà„É¶„Éº„Ç∂„Éº„ÅÆÂÖ•Âäõ„ÉÜ„Ç≠„Çπ„Éà„ÇíÂá¶ÁêÜÔºâ
            if (audioEnabled && generationSettings.audio.enabled) {
              console.log('üéµ Audio enabled, performing TTS processing for user input')
              await processTTS(content, content)
            }
            
            return
          }
        } else {
          // ÈÄöÂ∏∏„ÅÆAPI„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅÆÂ†¥Âêà„ÄÅAI SDK Service„Çí‰ΩøÁî®
          const apiKey = providerApiKeys[selectedProviderId]
          if (apiKey) {
            await aiSDKService.configureProvider({
              providerId: selectedProviderId,
              modelId: selectedModelId,
              apiKey
            })
          }
        }
      }
      
      // ÁèæÂú®ÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´„ÅåOllama„Åæ„Åü„ÅØLlamaCpp„Åß„Å™„ÅÑÂ†¥Âêà„ÅÆ„Åø„ÄÅAI SDK Service„Çí‰ΩøÁî®
      const shouldUseAISDK = !currentSelectedModel || 
        (!currentSelectedModel.startsWith('ollama:') && !currentSelectedModel.startsWith('llama-cpp:'))
      
      if (shouldUseAISDK && aiSDKService.isProviderConfigured()) {
        // ÁèæÂú®„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„ÇíÂèñÂæó
        const currentConfig = aiSDKService.getCurrentConfig()
        if (!currentConfig) {
          throw new Error('No provider configured')
        }

        // „Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅÆAPI Key„ÇíÂèñÂæó
        const apiKey = providerApiKeys[currentConfig.providerId]
        if (!apiKey) {
          throw new Error(`API Key not found for provider: ${currentConfig.providerId}`)
        }

        // API Key„Åß„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíÂÜçË®≠ÂÆö
        await aiSDKService.configureProvider({
          ...currentConfig,
          apiKey: apiKey
        })

        // „Éï„Ç°„Ç§„É´„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØGemini API„Çí‰ΩøÁî®
        if (files && files.length > 0 && currentConfig.providerId === 'google') {
          await handleFileChatRequest(enhancedContent, contexts, files, apiKey)
          return
        }

        // ÈÄöÂ∏∏„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÉÅ„É£„ÉÉ„ÉàÔºà„Éï„Ç°„Ç§„É´„Å™„ÅóÔºâ
        const chatHistory = messages.map(msg => ({
          role: msg.role as 'user' | 'assistant' | 'system',
          content: msg.content
        }))

        // Êñ∞„Åó„ÅÑ„É¶„Éº„Ç∂„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
        const updatedHistory = [
          ...chatHistory,
          { role: 'user' as const, content: enhancedContent }
        ]

        // „Ç∑„Çπ„ÉÜ„É†„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†Ôºà„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„Åå„ÅÇ„ÇãÂ†¥ÂêàÔºâ
        if (contexts && contexts.length > 0) {
          const systemMessage = {
            role: 'system' as const,
            content: `Context: ${contexts.map(ctx => `@${ctx.name}`).join(', ')}`
          }
          updatedHistory.unshift(systemMessage)
        }

        // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„É¨„Çπ„Éù„É≥„ÇπÁî®„ÅÆ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„ÉÉ„Çª„Éº„Ç∏„Çí‰ΩúÊàê
        const assistantMessageId = (Date.now() + 1).toString()
        const assistantMessage: ChatMessageProps = {
          id: assistantMessageId,
          content: '', // Á©∫ÊñáÂ≠óÂàó„Å´Ë®≠ÂÆö
          role: 'assistant',
          metadata: {
            title: analysis.suggestedAgent && analysis.suggestedAgent !== 'file_processor' ? `${analysis.suggestedAgent} Agent Execution` : 'Chat Response Generation'
          }
        }
        
        setStreamingResponse('')

                // „Çø„Çπ„ÇØÈÄ≤Êçó„ÇíÊõ¥Êñ∞
        if (taskId) {
          updateTaskProgress(taskId, 50, 'AI„É¢„Éá„É´Ë®≠ÂÆöÂÆå‰∫Ü', 1)
        }

        // AI SDK UI„ÅÆreadUIMessageStream„Çí‰ΩøÁî®„Åó„ÅüÊñ∞„Åó„ÅÑ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞Ê©üËÉΩ
        console.log('üöÄ Starting AI streaming...')
        setIsTyping(true) // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÈñãÂßãÊôÇ„Å´isTyping„Çítrue„Å´Ë®≠ÂÆö
        
        // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÈñãÂßãÊôÇ„Å´„ÅØ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†„Åó„Å™„ÅÑÔºàÁ©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÈÅø„Åë„Çã„Åü„ÇÅÔºâ
        // ‰ª£„Çè„Çä„Å´„ÄÅÊúÄÂàù„ÅÆÊúâÂäπ„Å™„ÉÅ„É£„É≥„ÇØ„ÅåÂà∞ÁùÄ„Åó„ÅüÊôÇ„Å´„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†„Åô„Çã
        
        let lastFullResponse = '' // ÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØÁî®
        let hasAddedMessage = false // „É°„ÉÉ„Çª„Éº„Ç∏ËøΩÂä†„Éï„É©„Ç∞
        let chunkCount = 0 // „ÉÅ„É£„É≥„ÇØ„Ç´„Ç¶„É≥„Çø„Éº
        
        console.log('üöÄ Gemini 2.5 Flash Lite „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÈñãÂßã')
        
        await aiSDKService.streamUIMessageResponse(
          updatedHistory,
          (chunk: string) => {
            chunkCount++
            
            // Á©∫„ÅÆ„ÉÅ„É£„É≥„ÇØ„ÇÑÁÑ°Âäπ„Å™„ÉÅ„É£„É≥„ÇØ„Çí„Çπ„Ç≠„ÉÉ„Éó
            if (!chunk || chunk.trim() === '' || chunk === '{}' || chunk === '[]' || chunk === 'null' || chunk === 'undefined') {
              console.log(`üîÑ ÁÑ°Âäπ„Å™„ÉÅ„É£„É≥„ÇØ„Çí„Çπ„Ç≠„ÉÉ„Éó („ÉÅ„É£„É≥„ÇØ ${chunkCount}):`, chunk)
              return
            }
            
            // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÉÅ„É£„É≥„ÇØ„ÇíÂá¶ÁêÜ
            setStreamingResponse(prev => {
              const newResponse = prev + chunk
              
              // ÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØÔºöÂâçÂõû„Å®Âêå„Åò„É¨„Çπ„Éù„É≥„Çπ„ÅÆÂ†¥Âêà„ÅØ„Çπ„Ç≠„ÉÉ„Éó
              if (newResponse === lastFullResponse) {
                console.log(`üîÑ ÈáçË§á„É¨„Çπ„Éù„É≥„Çπ„Çí„Çπ„Ç≠„ÉÉ„Éó („ÉÅ„É£„É≥„ÇØ ${chunkCount})`)
                return prev
              }
              lastFullResponse = newResponse
              
              console.log(`üìù „ÉÅ„É£„É≥„ÇØ ${chunkCount} Âá¶ÁêÜ:`, {
                chunkLength: chunk.length,
                totalLength: newResponse.length,
                chunkPreview: chunk.substring(0, 30) + (chunk.length > 30 ? '...' : '')
              })
              
              // „Éá„Éê„ÉÉ„Ç∞Áî®Ôºö„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÉÅ„É£„É≥„ÇØ„ÅÆÂÜÖÂÆπ„Çí„É≠„Ç∞Âá∫Âäõ
              console.log('üîç Streaming chunk check:', {
                chunk: chunk?.substring(0, 30) + (chunk && chunk.length > 30 ? '...' : ''),
                newResponse: newResponse?.substring(0, 50) + (newResponse && newResponse.length > 50 ? '...' : ''),
                isEmpty: !newResponse || newResponse.trim() === '',
                isObject: newResponse === '{}',
                isArray: newResponse === '[]',
                isNull: newResponse === 'null',
                isUndefined: newResponse === 'undefined',
                hasWhitespaceOnly: /^\s*$/.test(newResponse),
                hasWhitespaceObject: /^\s*\{\s*\}\s*$/.test(newResponse),
                hasWhitespaceArray: /^\s*\[\s*\]\s*$/.test(newResponse)
              })
              
              // Audio„ÅåÊúâÂäπ„Åßgeneral„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅßmoderateË§áÈõëÂ∫¶„ÅÆÂ†¥Âêà„ÅØ„ÄÅTTSÂá¶ÁêÜ‰∏≠„ÅØUI„Å´Ë°®Á§∫„Åó„Å™„ÅÑ
              const shouldHideInAudioMode = audioEnabled && generationSettings.audio.enabled
              
              // Á©∫„Åß„Å™„ÅÑ„É¨„Çπ„Éù„É≥„Çπ„ÅÆÂ†¥Âêà„ÅÆ„Åø„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÊõ¥Êñ∞„Åæ„Åü„ÅØËøΩÂä†Ôºà‰∏ÄÂ∫¶„Å†„ÅëÔºâ
              if (newResponse && 
                  newResponse.trim() !== '' && 
                  newResponse !== '{}' && 
                  newResponse !== '[]' && 
                  newResponse !== 'null' && 
                  newResponse !== 'undefined' &&
                  newResponse !== '[object Object]' &&
                  newResponse !== '[object Array]' &&
                  !/^\s*\{\s*\}\s*$/.test(newResponse) &&
                  !/^\s*\[\s*\]\s*$/.test(newResponse) &&
                  !newResponse.includes('[object Object]') &&
                  !newResponse.includes('[object Array]') &&
                  !newResponse.includes('{}') &&
                  !newResponse.includes('[]') &&
                  !hasAddedMessage &&
                  !shouldHideInAudioMode &&
                  chunk.length > 0) { // „ÉÅ„É£„É≥„ÇØ„ÅåÁ©∫„Åß„Å™„ÅÑ„Åì„Å®„ÇíÁ¢∫Ë™ç
                
                hasAddedMessage = true
                
                // „É°„ÉÉ„Çª„Éº„Ç∏ËøΩÂä†„ÇíÈùûÂêåÊúü„ÅßÂÆüË°åÔºàÁÑ°Èôê„É´„Éº„Éó„ÇíÈò≤„Åê„Åü„ÇÅÔºâ
                setTimeout(() => {
                  setMessages(prevMessages => {
                    // Êó¢Â≠ò„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„Åå„ÅÇ„Çã„Åã„ÉÅ„Çß„ÉÉ„ÇØ
                    const existingMessage = prevMessages.find(msg => msg.id === assistantMessageId)
                    
                    if (existingMessage) {
                      // Êó¢Â≠ò„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÊõ¥Êñ∞
                      return prevMessages.map(msg => 
                        msg.id === assistantMessageId 
                          ? { ...msg, content: newResponse }
                          : msg
                      )
                    } else {
                      // Êñ∞„Åó„ÅÑ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
                      return [...prevMessages, { ...assistantMessage, content: newResponse }]
                    }
                  })
                }, 0)
              }
              
              return newResponse
            })
          },
          (fullResponse: string) => {
            // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„ÅÆÂá¶ÁêÜ
            console.log('‚úÖ AI streaming completed')
            
            // „Éá„Éê„ÉÉ„Ç∞Áî®Ôºö„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„ÅÆ„É¨„Çπ„Éù„É≥„ÇπÂÜÖÂÆπ„Çí„É≠„Ç∞Âá∫Âäõ
            console.log('üîç Streaming completion check:', {
              fullResponse: fullResponse?.substring(0, 50) + (fullResponse && fullResponse.length > 50 ? '...' : ''),
              isEmpty: !fullResponse || fullResponse.trim() === '',
              isObject: fullResponse === '{}',
              isArray: fullResponse === '[]',
              isNull: fullResponse === 'null',
              isUndefined: fullResponse === 'undefined',
              hasWhitespaceOnly: /^\s*$/.test(fullResponse),
              hasWhitespaceObject: /^\s*\{\s*\}\s*$/.test(fullResponse),
              hasWhitespaceArray: /^\s*\[\s*\]\s*$/.test(fullResponse)
            })
            
            // Audio„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØ„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„É¨„Çπ„Éù„É≥„Çπ„ÇíÈùûË°®Á§∫„Å´„Åó„Å¶TTSÂá¶ÁêÜ„ÅÆ„Åø„ÇíÂÆüË°å
            const shouldHideInAudioMode = audioEnabled && generationSettings.audio.enabled
            
            // Á©∫„ÅÆ„É¨„Çπ„Éù„É≥„Çπ„ÇÑÁÑ°Âäπ„Å™„É¨„Çπ„Éù„É≥„Çπ„ÅÆÂ†¥Âêà„ÅØ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂâäÈô§
            if (!fullResponse || 
                fullResponse.trim() === '' || 
                fullResponse.length === 0 ||
                fullResponse === '{}' ||
                fullResponse === '[]' ||
                fullResponse === 'null' ||
                fullResponse === 'undefined' ||
                fullResponse === '[object Object]' ||
                fullResponse === '[object Array]' ||
                fullResponse.replace(/\s/g, '').length === 0 ||
                /^\s*\{\s*\}\s*$/.test(fullResponse) ||
                /^\s*\[\s*\]\s*$/.test(fullResponse) ||
                fullResponse.includes('[object Object]') ||
                fullResponse.includes('[object Array]') ||
                fullResponse.includes('{}') ||
                fullResponse.includes('[]') ||
                shouldHideInAudioMode) {
              if (shouldHideInAudioMode) {
                console.log('üéµ Audio mode active - removing text response for TTS processing')
              } else {
                console.log('üóëÔ∏è Removing empty/invalid response message')
              }
              setMessages(prev => prev.filter(msg => msg.id !== assistantMessageId))
            } else {
              // Á©∫„Åß„Å™„ÅÑ„É¨„Çπ„Éù„É≥„Çπ„ÅÆÂ†¥Âêà„ÅÆ„Åø„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÊõ¥Êñ∞
              console.log('‚úÖ Updating message with response:', fullResponse.substring(0, 50) + '...')
              setMessages(prev => 
                prev.map(msg => 
                  msg.id === assistantMessageId 
                    ? { ...msg, content: fullResponse }
                    : msg
                )
              )
            }
            setStreamingResponse('')
            setIsTyping(false) // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„Å´isTyping„Çífalse„Å´Ë®≠ÂÆö
            console.log('üîÑ Streaming completed: setting isGenerating to false')
            setIsGenerating(false)
            
            // Á©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁ¢∫ÂÆü„Å´ÂâäÈô§
            setMessages(prev => prev.filter(msg => 
              msg.content && 
              msg.content.trim() !== '' && 
              msg.content.length > 0 &&
              msg.content !== ' ' &&
              msg.content !== '\n' &&
              msg.content !== '\t' &&
              msg.content !== 'Chat Response Generation' &&
              msg.content !== 'Audio Mode Active' &&
              msg.content !== '{}' &&
              msg.content !== '[]' &&
              msg.content !== 'null' &&
              msg.content !== 'undefined' &&
              msg.content !== '[object Object]' &&
              msg.content !== '[object Array]' &&
              !/^\s*$/.test(msg.content) &&
              msg.content.replace(/\s/g, '').length > 0 &&
              !/^\s*\{\s*\}\s*$/.test(msg.content) &&
              !/^\s*\[\s*\]\s*$/.test(msg.content) &&
              !msg.content.includes('[object Object]') &&
              !msg.content.includes('[object Array]') &&
              !msg.content.includes('{}') &&
              !msg.content.includes('[]')
            ))
            
            // „Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØÂá¶ÁêÜ„ÇíÂÆüË°å
            if (factCheckingSettings.enabled && factCheckingSettings.autoCheck && fullResponse) {
              // ÈùûÂêåÊúü„Åß„Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØ„ÇíÂÆüË°å
              performFactCheck(fullResponse).then(factCheckResult => {
                if (factCheckResult && !factCheckResult.isFactual) {
                  // „Éï„Ç°„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØ„ÅßÂïèÈ°å„ÅåË¶ã„Å§„Åã„Å£„ÅüÂ†¥Âêà„ÄÅË≠¶Âëä„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
                  const warningMessage: ChatMessageProps = {
                    id: `fact-check-${Date.now()}`,
                    content: `**Fact Check Warning**: This response may contain inaccuracies.\n\n**Issues Found**:\n${factCheckResult.issues.map(issue => `‚Ä¢ ${issue}`).join('\n')}\n\n**Confidence**: ${factCheckResult.confidence}%\n\n**Explanation**: ${factCheckResult.explanation}`,
                    role: 'assistant',
                    metadata: {
                      title: 'Fact Check Warning'
                    }
                  }
                  setMessages(prev => [...prev, warningMessage])
                }
              }).catch(error => {
                console.error('Fact check failed:', error)
              })
            }
            
            // TTSÂá¶ÁêÜ„ÇíÂÆüË°åÔºà„ÉÜ„Ç≠„Çπ„ÉàÊäΩÂá∫Ê©üËÉΩ‰ªò„ÅçÔºâ
            if (audioEnabled && generationSettings.audio.enabled) {
              processTTSWithTextExtraction(content)
            }
            
            // „Çø„Çπ„ÇØÂÆå‰∫Ü
            if (taskId) {
              completeTask(taskId, true)
            }
          },
          (error: Error) => {
            // „Ç®„É©„ÉºÂá¶ÁêÜ
            console.error('‚ùå Streaming error:', error)
            
            // Audio„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØ„ÄÅ„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇÇË°®Á§∫„Åó„Å™„ÅÑ
            const shouldHideInAudioMode = audioEnabled && generationSettings.audio.enabled
            
            if (!shouldHideInAudioMode) {
              setMessages(prev => 
                prev.map(msg => 
                  msg.id === assistantMessageId 
                    ? { ...msg, content: `‚ùå „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: ${error.message}` }
                    : msg
                )
              )
            } else {
              console.log('üéµ Audio mode active - hiding error message for TTS processing')
              // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂâäÈô§
              setMessages(prev => prev.filter(msg => msg.id !== assistantMessageId))
            }
            
            setStreamingResponse('')
            setLastError(error.message)
            setIsTyping(false) // „Ç®„É©„ÉºÊôÇ„ÇÇisTyping„Çífalse„Å´Ë®≠ÂÆö
            console.log('üîÑ Streaming error: setting isGenerating to false')
            setIsGenerating(false)
            
            // Á©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÁ¢∫ÂÆü„Å´ÂâäÈô§
            setMessages(prev => prev.filter(msg => 
              msg.content && 
              msg.content.trim() !== '' && 
              msg.content.length > 0 &&
              msg.content !== ' ' &&
              msg.content !== '\n' &&
              msg.content !== '\t' &&
              msg.content !== 'Chat Response Generation' &&
              msg.content !== 'Audio Mode Active' &&
              msg.content !== '{}' &&
              msg.content !== '[]' &&
              msg.content !== 'null' &&
              msg.content !== 'undefined' &&
              msg.content !== '[object Object]' &&
              msg.content !== '[object Array]' &&
              !/^\s*$/.test(msg.content) &&
              msg.content.replace(/\s/g, '').length > 0 &&
              !/^\s*\{\s*\}\s*$/.test(msg.content) &&
              !/^\s*\[\s*\]\s*$/.test(msg.content) &&
              !msg.content.includes('[object Object]') &&
              !msg.content.includes('[object Array]') &&
              !msg.content.includes('{}') &&
              !msg.content.includes('[]')
            ))
            
            // „Çø„Çπ„ÇØ„Ç®„É©„Éº
            if (taskId) {
              completeTask(taskId, false)
            }
          }
        )
      } else {
        // Fallback to mock response
        const mockResponse = `I understand you're asking about: "${content}". However, I need to be configured with an AI provider to provide meaningful responses. Please configure an AI provider in the settings.`
        
        const assistantMessage: ChatMessageProps = {
          id: (Date.now() + 1).toString(),
          content: mockResponse,
          role: 'assistant',
          metadata: {
            title: 'Chat Response Generation'
          }
        }
        setMessages(prev => [...prev, assistantMessage])
        setLastError('No AI provider configured')
        setIsGenerating(false)
      }
    } catch (error) {
      console.error('Error in handleRegularChatRequest:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred'
      setLastError(errorMessage)
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
      const errorResponse: ChatMessageProps = {
        id: (Date.now() + 1).toString(),
        content: `‚ùå „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: ${errorMessage}`,
        role: 'assistant',
        metadata: {
          title: 'Chat Response Generation'
        }
      }
      setMessages(prev => [...prev, errorResponse])
      setIsGenerating(false)
    } finally {
      console.log('üîÑ Finally block: setting isTyping to false, isGenerating to false and loadingState to idle')
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  // YouTubeÂãïÁîª„É™„ÇØ„Ç®„Çπ„ÉàÂá¶ÁêÜ
  const handleYouTubeVideoRequest = async (content: string, contexts?: Array<{id: string, type: string, name: string, value?: string}>) => {
    try {
      // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØ„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê„Çí„Çπ„Ç≠„ÉÉ„Éó
      if (audioEnabled && generationSettings.audio.enabled) {
        // Á©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅØËøΩÂä†„Åó„Å™„ÅÑ
        return
      }

      if (aiSDKService.isProviderConfigured()) {
        // ÁèæÂú®„ÅÆ„Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„ÇíÂèñÂæó
        const currentConfig = aiSDKService.getCurrentConfig()
        if (!currentConfig) {
          throw new Error('No provider configured')
        }

        // „Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅÆAPI Key„ÇíÂèñÂæó
        const apiKey = providerApiKeys[currentConfig.providerId]
        if (!apiKey) {
          throw new Error(`API Key not found for provider: ${currentConfig.providerId}`)
        }

        // API Key„Åß„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíÂÜçË®≠ÂÆö
        await aiSDKService.configureProvider({
          ...currentConfig,
          apiKey: apiKey
        })

        // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„É¨„Çπ„Éù„É≥„ÇπÁî®„ÅÆ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„ÉÉ„Çª„Éº„Ç∏„Çí‰ΩúÊàê
        const assistantMessageId = (Date.now() + 1).toString()
        const assistantMessage: ChatMessageProps = {
          id: assistantMessageId,
          content: '',
          role: 'assistant',
        }
        
        // „Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂç≥Â∫ß„Å´ËøΩÂä†Ôºà„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞Ë°®Á§∫Áî®Ôºâ
        setMessages(prev => [...prev, assistantMessage])

        // GeminiFileService„ÇíÂàùÊúüÂåñ
        const geminiFileService = new GeminiFileService()
        await geminiFileService.configure(apiKey, 'gemini-1.5-flash')

        // YouTubeÂãïÁîª„Å´„Å§„ÅÑ„Å¶„ÉÅ„É£„ÉÉ„Éà
        const question = content.trim() || '„Åì„ÅÆÂãïÁîª„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ'
        const chatResponse = await geminiFileService.chatAboutVideo(content.trim(), question)

        // „É¨„Çπ„Éù„É≥„Çπ„ÇíË°®Á§∫
        const fullResponse = chatResponse.text
        setMessages(prev => 
          prev.map(msg => 
            msg.id === assistantMessageId 
              ? { ...msg, content: fullResponse }
              : msg
          )
        )
        setStreamingResponse('')
        setIsGenerating(false)
        
        // TTSÂá¶ÁêÜ„ÅØÊúÄÂæå„ÅÆ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„Å´ÂÆüË°å„Åï„Çå„Çã„Åü„ÇÅ„ÄÅ„Åì„Åì„Åß„ÅØÂÆüË°å„Åó„Å™„ÅÑ

      } else {
        // Fallback to mock response
        const mockResponse = `I understand you want to analyze a YouTube video: "${content}". However, I need to be configured with an AI provider to provide meaningful responses. Please configure an AI provider in the settings.`
        
        const assistantMessage: ChatMessageProps = {
          id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
          content: mockResponse,
          role: 'assistant',
        }
        setMessages(prev => [...prev, assistantMessage])
        
        // TTSÂá¶ÁêÜ„ÅØÊúÄÂæå„ÅÆ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„Å´ÂÆüË°å„Åï„Çå„Çã„Åü„ÇÅ„ÄÅ„Åì„Åì„Åß„ÅØÂÆüË°å„Åó„Å™„ÅÑ
        
        setLastError('No AI provider configured')
        setIsGenerating(false)
      }
    } catch (error) {
      console.error('Error in handleYouTubeVideoRequest:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred'
      setLastError(errorMessage)
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
      const errorResponse: ChatMessageProps = {
        id: (Date.now() + 1).toString(),
        content: `‚ùå YouTubeÂãïÁîªÂàÜÊûê„Ç®„É©„Éº: ${errorMessage}`,
        role: 'assistant',
      }
      setMessages(prev => [...prev, errorResponse])
      setStreamingResponse('')
      setIsGenerating(false)
    } finally {
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  // „Éï„Ç°„Ç§„É´„ÉÅ„É£„ÉÉ„Éà„É™„ÇØ„Ç®„Çπ„ÉàÂá¶ÁêÜ
  const handleFileChatRequest = async (content: string, contexts?: Array<{id: string, type: string, name: string, value?: string}>, files?: File[], apiKey?: string) => {
    if (!files || files.length === 0 || !apiKey) {
      throw new Error('Files and API key are required for file chat')
    }

    // Audio„Åå„Ç™„É≥„ÅÆÂ†¥Âêà„ÅØ„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê„Çí„Çπ„Ç≠„ÉÉ„Éó
    if (audioEnabled && generationSettings.audio.enabled) {
      // Á©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅØËøΩÂä†„Åó„Å™„ÅÑ
      return
    }

    try {
      // GeminiFileService„ÇíÂàùÊúüÂåñ
      const geminiFileService = new GeminiFileService()
      await geminiFileService.configure(apiKey, 'gemini-1.5-flash')

      // „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„É¨„Çπ„Éù„É≥„ÇπÁî®„ÅÆ„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„ÉÉ„Çª„Éº„Ç∏„Çí‰ΩúÊàê
      const assistantMessageId = (Date.now() + 1).toString()
      const assistantMessage: ChatMessageProps = {
        id: assistantMessageId,
        content: '',
        role: 'assistant',
      }
      
      // „Ç¢„Ç∑„Çπ„Çø„É≥„Éà„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂç≥Â∫ß„Å´ËøΩÂä†Ôºà„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞Ë°®Á§∫Áî®Ôºâ
      setMessages(prev => [...prev, assistantMessage])

      // „Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ
      const uploadPromises = files.map(async (file, index) => {
        try {
          const fileType = file.type.startsWith('video/') ? 'üé•' : 
                          file.type.startsWith('image/') ? 'üñºÔ∏è' : 
                          file.type.startsWith('audio/') ? 'üéµ' : 'üìÑ'
          
          // ÂãïÁîª„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà„ÅØËøΩÂä†ÊÉÖÂ†±„ÇíË°®Á§∫
          if (file.type.startsWith('video/')) {
            const fileSizeMB = file.size / 1024 / 1024
            if (fileSizeMB > 15) {
            }
          }
          
          // Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà„ÅØËøΩÂä†ÊÉÖÂ†±„ÇíË°®Á§∫
          if (file.type.startsWith('audio/')) {
            const fileSizeMB = file.size / 1024 / 1024
            if (fileSizeMB > 15) {
            }
          }
          
          // File„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÇíÁõ¥Êé•„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ
          const uploadResponse = await geminiFileService.uploadFileObject(file, file.name)
          
          console.log(`File uploaded successfully: ${file.name}`)
          return uploadResponse.file.uri
        } catch (error) {
          console.error(`Failed to upload file ${file.name}:`, error)
          
          // ÂãïÁîª„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà„ÅØ„Çà„ÇäË©≥Á¥∞„Å™„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏
          if (file.type.startsWith('video/')) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error'
            if (errorMessage.includes('ÂãïÁîª„ÅåÈï∑„Åô„Åé„Åæ„Åô')) {
              throw new Error(`ÂãïÁîª„Éï„Ç°„Ç§„É´ "${file.name}" „ÅåÈï∑„Åô„Åé„Åæ„Åô„ÄÇÊúÄÂ§ß60Áßí„Åæ„ÅßÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ`)
            } else if (errorMessage.includes('ÂãïÁîª„Éï„Ç°„Ç§„É´„ÅåÂ§ß„Åç„Åô„Åé„Åæ„Åô')) {
              throw new Error(`ÂãïÁîª„Éï„Ç°„Ç§„É´ "${file.name}" „ÅåÂ§ß„Åç„Åô„Åé„Åæ„Åô„ÄÇÊúÄÂ§ß50MB„Åæ„ÅßÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ`)
            } else if (errorMessage.includes('ÂãïÁîª„Éï„Ç°„Ç§„É´„ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü')) {
              throw new Error(`ÂãïÁîª„Éï„Ç°„Ç§„É´ "${file.name}" „ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„Éï„Ç°„Ç§„É´„ÅåÁ†¥Êêç„Åó„Å¶„ÅÑ„Çã„Åã„ÄÅ„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂΩ¢Âºè„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ`)
            }
          }
          
          // Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà„ÅØ„Çà„ÇäË©≥Á¥∞„Å™„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏
          if (file.type.startsWith('audio/')) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error'
            if (errorMessage.includes('Èü≥Â£∞„ÅåÈï∑„Åô„Åé„Åæ„Åô')) {
              throw new Error(`Èü≥Â£∞„Éï„Ç°„Ç§„É´ "${file.name}" „ÅåÈï∑„Åô„Åé„Åæ„Åô„ÄÇÊúÄÂ§ß30ÂàÜ„Åæ„ÅßÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ`)
            } else if (errorMessage.includes('Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåÂ§ß„Åç„Åô„Åé„Åæ„Åô')) {
              throw new Error(`Èü≥Â£∞„Éï„Ç°„Ç§„É´ "${file.name}" „ÅåÂ§ß„Åç„Åô„Åé„Åæ„Åô„ÄÇÊúÄÂ§ß50MB„Åæ„ÅßÂØæÂøú„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ`)
            } else if (errorMessage.includes('Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü')) {
              throw new Error(`Èü≥Â£∞„Éï„Ç°„Ç§„É´ "${file.name}" „ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„Éï„Ç°„Ç§„É´„ÅåÁ†¥Êêç„Åó„Å¶„ÅÑ„Çã„Åã„ÄÅ„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂΩ¢Âºè„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ`)
            }
          }
          
          throw new Error(`Failed to upload file ${file.name}: ${error instanceof Error ? error.message : 'Unknown error'}`)
        }
      })

      const fileUris = await Promise.all(uploadPromises)
      
      const question = content.trim() || '„Åì„ÅÆ„Éï„Ç°„Ç§„É´„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ'
      
      let chatResponse
      if (files.length === 1) {
        // Âçò‰∏Ä„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà
        const file = files[0]
        
        if (file.type.startsWith('video/')) {
          // ÂãïÁîª„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà„ÅØÂ∞ÇÁî®„É°„ÇΩ„ÉÉ„Éâ„Çí‰ΩøÁî®
          chatResponse = await geminiFileService.chatAboutVideo(fileUris[0], question)
        } else if (file.type.startsWith('audio/')) {
          // Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÂ†¥Âêà„ÅØÂ∞ÇÁî®„É°„ÇΩ„ÉÉ„Éâ„Çí‰ΩøÁî®
          chatResponse = await geminiFileService.chatAboutAudio(fileUris[0], question)
        } else {
          // „Åù„ÅÆ‰ªñ„ÅÆ„Éï„Ç°„Ç§„É´
          chatResponse = await geminiFileService.chatAboutFile(fileUris[0], question)
        }
      } else {
        // Ë§áÊï∞„Éï„Ç°„Ç§„É´„ÅÆÂ†¥ÂêàÔºàÁèæÂú®„ÅØÊúÄÂàù„ÅÆ„Éï„Ç°„Ç§„É´„ÅÆ„ÅøÂá¶ÁêÜÔºâ
        console.log(`Multiple files detected (${files.length}), processing first file: ${files[0].name}`)
        const firstFile = files[0]
        
        if (firstFile.type.startsWith('video/')) {
          chatResponse = await geminiFileService.chatAboutVideo(fileUris[0], question)
        } else if (firstFile.type.startsWith('audio/')) {
          chatResponse = await geminiFileService.chatAboutAudio(fileUris[0], question)
        } else {
          chatResponse = await geminiFileService.chatAboutFile(fileUris[0], question)
        }
      }

      // „É¨„Çπ„Éù„É≥„Çπ„ÇíË°®Á§∫
      const fullResponse = chatResponse.text
      setMessages(prev => 
        prev.map(msg => 
          msg.id === assistantMessageId 
            ? { ...msg, content: fullResponse }
            : msg
        )
      )
      setStreamingResponse('')
      setIsGenerating(false)
      
      // TTSÂá¶ÁêÜ„ÅØÊúÄÂæå„ÅÆ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂÆå‰∫ÜÊôÇ„Å´ÂÆüË°å„Åï„Çå„Çã„Åü„ÇÅ„ÄÅ„Åì„Åì„Åß„ÅØÂÆüË°å„Åó„Å™„ÅÑ

    } catch (error) {
      console.error('Error in handleFileChatRequest:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred'
      setLastError(errorMessage)
      
      // „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËøΩÂä†
      const errorResponse: ChatMessageProps = {
        id: (Date.now() + 1).toString(),
        content: `‚ùå „Éï„Ç°„Ç§„É´Âá¶ÁêÜ„Ç®„É©„Éº: ${errorMessage}`,
        role: 'assistant',
      }
      setMessages(prev => [...prev, errorResponse])
      setStreamingResponse('')
      setIsGenerating(false)
    } finally {
      setIsTyping(false)
      setIsGenerating(false)
      setLoadingState('idle')
    }
  }

  const handleFilesAdded = (files: File[]) => {
    setSelectedFiles(prev => [...prev, ...files])
  }

  const handleTranscriptionComplete = (text: string) => {
    // ÊñáÂ≠óËµ∑„Åì„ÅóÁµêÊûú„Çí„ÉÅ„É£„ÉÉ„Éà„Å´ÈÄÅ‰ø°
    handleSendMessage(`Èü≥Â£∞„ÅÆÊñáÂ≠óËµ∑„Åì„ÅóÁµêÊûú:\n\n${text}`)
  }

  const handleAttachFiles = () => {
    // This function is no longer needed as we use direct file selection
  }

  const handleCancelSequentialThinking = () => {
    setShowSequentialThinking(false)
    setCurrentPlan(null)
    setIsTyping(false)
    setIsAgentMode(false)
  }

  const handleProviderSelect = async (config: AIProviderConfig) => {
    try {
      setLastError(null)
      
      await aiSDKService.configureProvider(config)
      setCurrentProviderConfig(config)
      
      console.log(`Provider configured: ${config.providerId} with model: ${config.modelId}`)
    } catch (error) {
      console.error('Failed to configure provider:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error'
      setLastError(errorMessage)
    }
  }

  // ÁèæÂú®ÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´„ÇíËøΩË∑°
  const [currentSelectedModel, setCurrentSelectedModel] = useState<string | null>(null)

  // „É¢„Éá„É´„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÈÄ≤ÊçóÂá¶ÁêÜÈñ¢Êï∞
  const handleModelDownloadProgress = (progress: any, modelId?: string) => {
    if (progress && typeof progress === 'object') {
      console.log('üìä Received progress:', progress)
      console.log('üìä Progress keys:', Object.keys(progress))
      console.log('üìä actualModelId:', progress.actualModelId)
      console.log('üìä originalModelId:', progress.originalModelId)
      console.log('üìä modelId:', progress.modelId)
      console.log('üìä message:', progress.message)
      console.log('üìä Input modelId parameter:', modelId)
      
      // ÈÄ≤ÊçóÊÉÖÂ†±„ÅÆÊßãÈÄ†„ÇíÁµ±‰∏ÄÔºàollama-service.ts„Åã„Çâ„ÅÆÊñ∞„Åó„ÅÑÂΩ¢Âºè„Å´ÂØæÂøúÔºâ
      const status = progress.status || (progress.message?.includes('completed') ? 'completed' : 'downloading')
      const progressValue = progress.progress || progress.percentage || 0
      const downloaded = progress.downloaded || 0
      const total = progress.total || 0
      
      console.log(`üìä Parsed progress: status=${status}, progress=${progressValue}, downloaded=${downloaded}, total=${total}`)
      
      // „É¢„Éá„É´Âêç„ÇíÊäΩÂá∫ÔºàproviderId:modelId „ÅÆÂΩ¢Âºè„Åã„Çâ modelId „ÅÆ„Åø„ÇíÂèñÂæóÔºâ
      let modelName = 'Unknown Model'
      const targetModelId = modelId || currentSelectedModel
      if (targetModelId) {
        const parts = targetModelId.split(':')
        const modelIdPart = parts.length > 1 ? parts[1] : targetModelId
        
        // ÂÆüÈöõ„Å´„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´Âêç„ÇíÂèñÂæó
        // progress.modelId „Åæ„Åü„ÅØ progress.message „Åã„ÇâÂÆüÈöõ„ÅÆ„É¢„Éá„É´Âêç„ÇíÊäΩÂá∫
        let actualModelName = modelIdPart
        
        // „Éó„É≠„Ç∞„É¨„ÇπÊÉÖÂ†±„Åã„ÇâÂÆüÈöõ„ÅÆ„É¢„Éá„É´Âêç„ÇíÊäΩÂá∫
        if (progress.actualModelId) {
          // LLM Manager„Åã„ÇâÊèê‰æõ„Åï„Çå„ÅüÂÆüÈöõ„ÅÆ„É¢„Éá„É´ID„Çí‰ΩøÁî®
          const actualModelId = progress.actualModelId
          
          // ÂÆüÈöõ„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„É¢„Éá„É´ID„Åã„ÇâË°®Á§∫Áî®„É¢„Éá„É´Âêç„Å∏„ÅÆ„Éû„ÉÉ„Éî„É≥„Ç∞
          const actualModelMapping: { [key: string]: string } = {
            'unsloth/Qwen3-0.6B-GGUF': 'qwen3:0.6b',
            'unsloth/Qwen3-1.7B-GGUF': 'qwen3:1.7b',
            'unsloth/Qwen3-4B-Instruct-2507-GGUF': 'qwen3:4b',
            'unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF': 'qwen3:8b',
            'unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF': 'qwen3:30b',
            'unsloth/gpt-oss-20b-GGUF': 'gpt-oss-20b',
            'TheBloke/Llama-2-7B-Chat-GGUF': 'llama-2-7b-chat',
            'TheBloke/Llama-2-13B-Chat-GGUF': 'llama-2-13b-chat',
            'TheBloke/Mistral-7B-Instruct-v0.2-GGUF': 'mistral-7b-instruct',
            'TheBloke/Qwen2-7B-Instruct-GGUF': 'qwen2-7b-instruct',
            'TheBloke/CodeLlama-7B-Instruct-GGUF': 'codellama-7b-instruct',
            'TheBloke/Gemma-2-9B-IT-GGUF': 'gemma-2-9b-it'
          }
          
          actualModelName = actualModelMapping[actualModelId] || actualModelId
        } else if (progress.modelId) {
          // Ollama„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÄÅmodelId„ÅåÂÆüÈöõ„ÅÆ„É¢„Éá„É´Âêç
          actualModelName = progress.modelId
        } else if (progress.message) {
          // „É°„ÉÉ„Çª„Éº„Ç∏„Åã„Çâ„É¢„Éá„É´Âêç„ÇíÊäΩÂá∫
          const message = progress.message
          
          // „É°„ÉÉ„Çª„Éº„Ç∏ÂÜÖ„ÅÆÂÆüÈöõ„ÅÆ„É¢„Éá„É´ID„Åã„ÇâË°®Á§∫Áî®„É¢„Éá„É´Âêç„Å∏„ÅÆ„Éû„ÉÉ„Éî„É≥„Ç∞
          const messageModelMapping: { [key: string]: string } = {
            'unsloth/Qwen3-0.6B-GGUF': 'qwen3:0.6b',
            'unsloth/Qwen3-1.7B-GGUF': 'qwen3:1.7b',
            'unsloth/Qwen3-4B-Instruct-2507-GGUF': 'qwen3:4b',
            'unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF': 'qwen3:8b',
            'unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF': 'qwen3:30b',
            'unsloth/gpt-oss-20b-GGUF': 'gpt-oss-20b',
            'TheBloke/Llama-2-7B-Chat-GGUF': 'llama-2-7b-chat',
            'TheBloke/Llama-2-13B-Chat-GGUF': 'llama-2-13b-chat',
            'TheBloke/Mistral-7B-Instruct-v0.2-GGUF': 'mistral-7b-instruct',
            'TheBloke/Qwen2-7B-Instruct-GGUF': 'qwen2-7b-instruct',
            'TheBloke/CodeLlama-7B-Instruct-GGUF': 'codellama-7b-instruct',
            'TheBloke/Gemma-2-9B-IT-GGUF': 'gemma-2-9b-it'
          }
          
          // „É°„ÉÉ„Çª„Éº„Ç∏ÂÜÖ„Åß„Éû„ÉÉ„ÉÅ„Åô„Çã„É¢„Éá„É´ID„ÇíÊ§úÁ¥¢
          for (const [modelId, displayName] of Object.entries(messageModelMapping)) {
            if (message.includes(modelId)) {
              actualModelName = displayName
              break
            }
          }
          
          // „Éû„ÉÉ„ÉÅ„Åó„Å™„ÅÑÂ†¥Âêà„ÅØÂÖÉ„ÅÆ„É¢„Éá„É´Âêç„Çí‰ΩøÁî®
          if (!actualModelName) {
            actualModelName = modelIdPart
          }
        }
        
        // „Éá„Éê„ÉÉ„Ç∞Áî®ÔºöÂÆüÈöõ„ÅÆ„É¢„Éá„É´Âêç„Çí„É≠„Ç∞Âá∫Âäõ
        console.log(`üìä Debug - actualModelName: ${actualModelName}, modelIdPart: ${modelIdPart}, progress.modelId: ${progress.modelId}, progress.message: ${progress.message}`)
        
        // „É¢„Éá„É´Âêç„Çí„Çà„ÇäË©≥Á¥∞„Å´Ë°®Á§∫
        const modelNameMapping: { [key: string]: string } = {
          'qwen3': 'Qwen3 4B Instruct',
          'qwen3:0.6b': 'Qwen3 0.6B',
          'qwen3-0.6b': 'Qwen3 0.6B',
          'qwen3:1.7b': 'Qwen3 1.7B',
          'qwen3-1.7b': 'Qwen3 1.7B',
          'qwen3-4b': 'Qwen3 4B Instruct',
          'qwen3-8b': 'Qwen3 8B',
          'qwen3-30b': 'Qwen3 30B Instruct',
          'gpt-oss-20b': 'GPT-OSS-20B',
          'gpt-oss-20b-GGUF': 'GPT-OSS-20B',
          'gemma3:1b': 'Gemma3 1B',
          'gemma-2-9b-it': 'Gemma 2 9B IT',
          'llama-2-7b-chat': 'Llama 2 7B Chat',
          'llama-2-13b-chat': 'Llama 2 13B Chat',
          'mistral-7b-instruct': 'Mistral 7B Instruct',
          'qwen2-7b-instruct': 'Qwen2 7B Instruct',
          'codellama-7b-instruct': 'CodeLlama 7B Instruct'
        }
        
        modelName = modelNameMapping[actualModelName] || actualModelName
      }
      
      console.log(`üìä Setting model download state: ${modelName}, progress: ${progressValue}%, downloaded: ${downloaded}, total: ${total}`)
      
      const newState = {
        isDownloading: status === 'starting' || status === 'downloading' || status === 'verifying',
        modelName: modelName,
        progress: progressValue,
        status: status,
        downloadedBytes: downloaded,
        totalBytes: total
      }
      
      console.log(`üìä New model download state:`, newState)
      setModelDownloadState(newState)
      
      // modelDownloadState„Åå‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„ÄÅdownloadProgress„Çí„ÇØ„É™„Ç¢
      if (newState.isDownloading) {
        setDownloadProgress(null)
      }
      
      // „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÂÆå‰∫Ü„Åæ„Åü„ÅØ„Ç®„É©„Éº„ÅÆÂ†¥Âêà„ÄÅÂ∞ë„ÅóÈÅÖÂª∂„Åó„Å¶„Åã„ÇâÁä∂ÊÖã„Çí„É™„Çª„ÉÉ„Éà
      if (status === 'completed' || status === 'error') {
        setTimeout(() => {
          setModelDownloadState({
            isDownloading: false,
            modelName: '',
            progress: 0,
            status: 'starting',
            downloadedBytes: undefined,
            totalBytes: undefined
          })
        }, 3000) // 3ÁßíÂæå„Å´„É™„Çª„ÉÉ„Éà
      }
    }
  }

  // „É¢„Éá„É´ÈÅ∏Êäû„Éè„É≥„Éâ„É©„Éº
  const handleModelSelect = async (modelId: string) => {
    try {
      setLastError(null)
      
      if (modelId === 'auto') {
        // Auto mode: Âà©Áî®ÂèØËÉΩ„Å™„É¢„Éá„É´„ÇíËá™ÂãïÈÅ∏Êäû
        console.log('Auto mode selected - finding best available model...')
        await autoConfigureProvider()
        return
      }

      // TTS„É¢„Éá„É´„ÅÆÂ†¥Âêà
      if (modelId.startsWith('tts:')) {
        const ttsModelId = modelId.replace('tts:', '')
        console.log(`TTS model selected: ${ttsModelId}`)
        
        // TTS„É¢„Éá„É´„Å´Âøú„Åò„Å¶ÈÅ©Âàá„Å™„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíÊ±∫ÂÆö
        let provider = 'google' // „Éá„Éï„Ç©„É´„Éà
        if (ttsModelId.startsWith('inworld-tts')) {
          provider = 'inworld'
        } else if (ttsModelId.startsWith('gpt-')) {
          provider = 'openai'
        } else if (ttsModelId.startsWith('gemini-')) {
          provider = 'google'
        }
        
        // TTS„É¢„Éá„É´„Å®„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíË®≠ÂÆöÁîªÈù¢„ÅßÊúâÂäπ„Å´„Åô„Çã
        setGenerationSettings((prev: any) => {
          const newSettings = {
            ...prev,
            audio: {
              ...prev.audio,
              provider: provider, // „Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíÊõ¥Êñ∞
              models: {
                ...prev.audio.models,
                [ttsModelId]: {
                  ...prev.audio.models[ttsModelId],
                  enabled: true
                }
              }
            }
          }
          
          // ‰ªñ„ÅÆTTS„É¢„Éá„É´„ÇíÁÑ°Âäπ„Å´„Åô„Çã
          Object.keys(newSettings.audio.models).forEach(key => {
            if (key !== ttsModelId) {
              newSettings.audio.models[key].enabled = false
            }
          })
          
          return newSettings
        })
        
        // ÁèæÂú®„ÅÆTTS„É¢„Éá„É´„ÇíÊõ¥Êñ∞
        setCurrentTTSModel(ttsModelId)
        localStorage.setItem('armis_tts_model', ttsModelId)
        
        console.log(`TTS model activated: ${ttsModelId} with provider: ${provider}`)
        return
      }

      // STT„É¢„Éá„É´„ÅÆÂ†¥Âêà
      if (modelId.startsWith('stt:')) {
        const sttModelId = modelId.replace('stt:', '')
        console.log(`STT model selected: ${sttModelId}`)
        
        // STTË®≠ÂÆö„Çµ„Éº„Éì„Çπ„ÇíÂèñÂæó
        const sttService = STTSettingsService.getInstance()
        
        // ÈÅ∏Êäû„Åï„Çå„Åü„É¢„Éá„É´„ÇíÊúâÂäπ„Å´„Åô„Çã
        sttService.toggleModel(sttModelId)
        
        // ‰ªñ„ÅÆ„É¢„Éá„É´„ÇíÁÑ°Âäπ„Å´„Åô„Çã
        const settings = sttService.getSettings()
        Object.keys(settings.models).forEach(key => {
          if (key !== sttModelId) {
            settings.models[key].enabled = false
          }
        })
        
        // Ë®≠ÂÆö„Çí‰øùÂ≠ò
        sttService.updateSettings({ models: settings.models })
        
        // ÁèæÂú®„ÅÆSTT„É¢„Éá„É´„ÇíÊõ¥Êñ∞
        setCurrentSTTModel(sttModelId)
        localStorage.setItem('armis_stt_model', sttModelId)
        
        console.log(`STT model activated: ${sttModelId}`)
        return
      }

      // modelId„ÅÆÂΩ¢Âºè: "providerId:modelId" (modelId„Å´:„ÅåÂê´„Åæ„Çå„ÇãÂ†¥Âêà„Åå„ÅÇ„Çã)
      const firstColonIndex = modelId.indexOf(':')
      if (firstColonIndex === -1) {
        console.error('Invalid model ID format:', modelId)
        return
      }
      
      const providerId = modelId.substring(0, firstColonIndex)
      const selectedModelId = modelId.substring(firstColonIndex + 1)
      
      if (!providerId || !selectedModelId) {
        console.error('Invalid model ID format:', modelId)
        return
      }

      // ÁèæÂú®ÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„É¢„Éá„É´„ÇíÊõ¥Êñ∞
      setCurrentSelectedModel(modelId)

      // Ollama„Åæ„Åü„ÅØLlamaCpp„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÄÅËá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊ©üËÉΩ„Çí‰ΩøÁî®
      if (providerId === 'ollama' || providerId === 'llama-cpp') {
        if (!llmManager) {
          setLastError('LLM Manager not available')
          return
        }

        try {
          setIsDownloading(true)
          setDownloadProgress({ status: 'checking', message: 'Checking model availability...' })

          // „É¢„Éá„É´Âàá„ÇäÊõø„Åà„Å®Ëá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
          await llmManager.switchToModel(selectedModelId, (progress) => {
            console.log('üîÑ LLM Manager progress callback received:', progress)
            
            // „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÅåÈñãÂßã„Åï„Çå„Åü„Çâ„ÄåChecking model availability...„Äç„ÇíÈùûË°®Á§∫„Å´„Åô„Çã
            if (progress && progress.status === 'downloading') {
              setDownloadProgress(null)
            }
            // ÈÄ≤Ë°åÁä∂Ê≥Å„ÅåÂ≠òÂú®„Åô„ÇãÂ†¥Âêà„ÅÆ„ÅøÊõ¥Êñ∞ÔºàcheckingÁä∂ÊÖã„ÅÆÈáçË§á„ÇíÈò≤„ÅêÔºâ
            if (progress && (progress.status === 'starting' || progress.status === 'downloading' || progress.status === 'verifying' || progress.status === 'completed' || progress.status === 'error')) {
              console.log('üìä Calling handleModelDownloadProgress with:', progress)
              handleModelDownloadProgress(progress, modelId)
            }
            console.log('Download progress:', progress)
            console.log('Progress status:', progress?.status)
            console.log('Progress message:', progress?.message)
          })

          setDownloadProgress({ status: 'completed', message: 'Model ready!' })
          console.log(`Model selected and ready: ${providerId}:${selectedModelId}`)
        } catch (error) {
          console.error('Failed to switch to model:', error)
          setLastError(`Failed to switch to model: ${error}`)
        } finally {
          setIsDownloading(false)
          setDownloadProgress(null)
        }
        return
      }

      // ÈÄöÂ∏∏„ÅÆAPI„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÅÆÂ†¥Âêà
      const apiKey = providerApiKeys[providerId]
      if (!apiKey) {
        setLastError(`API Key not found for provider: ${providerId}`)
        return
      }

      // „Éó„É≠„Éê„Ç§„ÉÄ„ÉºË®≠ÂÆö„Çí‰ΩúÊàê
      const config: AIProviderConfig = {
        providerId,
        modelId: selectedModelId,
        apiKey
      }

      // „Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíË®≠ÂÆö
      await aiSDKService.configureProvider(config)
      setCurrentProviderConfig(config)
      
      console.log(`Model selected: ${providerId}:${selectedModelId}`)
    } catch (error) {
      console.error('Failed to select model:', error)
      const errorMessage = error instanceof Error ? error.message : 'Unknown error'
      setLastError(errorMessage)
    }
  }

  return (
    <div 
      className={cn("h-full flex flex-col bg-background", className)}
      onDragOver={handleDragOver}
      onDragLeave={handleDragLeave}
      onDrop={handleDrop}
    >
      {/* Header with Settings and CLI Buttons */}
      <div className="flex items-center justify-between p-4 border-b border-border">
        <div className="flex items-center gap-3">
          {isAgentMode && (
            <div className="flex items-center gap-1 text-blue-500">
              <Brain className="w-4 h-4" />
              <span className="text-sm">Agent Mode</span>
            </div>
          )}
        </div>
        <div className="flex items-center gap-2">
          <Button
            onClick={() => setShowCLI(!showCLI)}
            variant={showCLI ? "default" : "ghost"}
            size="sm"
            className="flex items-center justify-center w-8 h-8 p-0"
            title={showCLI ? 'Hide CLI' : 'Show CLI'}
          >
            <TerminalIcon className="w-4 h-4" />
          </Button>
          <Button
            onClick={() => setShowSettings(true)}
            variant="outline"
            size="sm"
            className="flex items-center gap-2"
          >
            <Settings className="w-4 h-4" />
            Settings
          </Button>
        </div>
      </div>

      {/* Error Display */}
      {lastError && (
        <div className="p-3 bg-red-50 border-b border-red-200">
          <div className="flex items-center gap-2 text-red-700 text-sm">
            <AlertCircle className="w-4 h-4" />
            <span>{lastError}</span>
            <Button
              variant="ghost"
              size="sm"
              onClick={() => setLastError(null)}
              className="ml-auto h-6 px-2 text-xs"
            >
              Dismiss
            </Button>
          </div>
        </div>
      )}

      {/* Download Progress Display - Only show when modelDownloadState is not active */}
      {isDownloading && downloadProgress && !modelDownloadState.isDownloading && (
        <div className="p-3">
          <div className="flex items-center gap-2 text-white text-sm">
            <ShimmerText className="text-white">
              {downloadProgress.message}
            </ShimmerText>
            {downloadProgress.status === 'downloading' && downloadProgress.progress && (
              <span className="text-xs text-white">
                {downloadProgress.progress.percentage ? `${downloadProgress.progress.percentage.toFixed(1)}%` : ''}
              </span>
            )}
          </div>
        </div>
      )}

      {/* Tool Calls Display */}
      {currentToolCalls.length > 0 && (
        <div className="p-3 bg-blue-50 border-b border-blue-200">
          <div className="flex items-center gap-2 text-blue-700 text-sm">
            <Wrench className="w-4 h-4" />
            <span>Using tools: {currentToolCalls.map(tc => tc.name).join(', ')}</span>
          </div>
        </div>
      )}

      {/* Sequential Thinking Panel */}
      {showSequentialThinking && (
        <div className="p-4 border-b border-border">
          <SequentialThinkingPanel
            plan={currentPlan}
            onCancel={handleCancelSequentialThinking}
          />
        </div>
      )}

      {/* Message display area */}
      <ScrollArea className="flex-1 p-4" ref={scrollAreaRef}>
        <div className="space-y-2">
          {messages
            .filter((message) => {
              // „Éá„Éê„ÉÉ„Ç∞Áî®Ôºö„É°„ÉÉ„Çª„Éº„Ç∏ÂÜÖÂÆπ„Çí„É≠„Ç∞Âá∫Âäõ
              console.log('üîç Message filter check:', {
                id: message.id,
                content: message.content?.substring(0, 30) + (message.content && message.content.length > 30 ? '...' : ''),
                contentLength: message.content?.length,
                isEmpty: !message.content || message.content.trim() === '',
                isObject: message.content === '{}',
                isArray: message.content === '[]',
                isNull: message.content === 'null',
                isUndefined: message.content === 'undefined',
                hasWhitespaceOnly: /^\s*$/.test(message.content),
                hasWhitespaceObject: /^\s*\{\s*\}\s*$/.test(message.content),
                hasWhitespaceArray: /^\s*\[\s*\]\s*$/.test(message.content)
              })
              
              // Á©∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇÑÁÑ°Âäπ„Å™„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÈùûË°®Á§∫„Å´„Åô„ÇãÔºàÂãïÁîª„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØÈô§Â§ñÔºâ
              if ((!message || 
                  !message.content || 
                  message.content.trim() === '' || 
                  message.content.length === 0 ||
                  message.content === undefined ||
                  message.content === null ||
                  typeof message.content !== 'string' ||
                  message.content === 'Chat Response Generation' ||
                  message.content === ' ' ||
                  message.content === '\n' ||
                  message.content === '\t' ||
                  message.content === '{}' ||
                  message.content === '[]' ||
                  message.content === 'null' ||
                  message.content === 'undefined' ||
                  message.content === '[object Object]' ||
                  message.content === '[object Array]' ||
                  message.id === 'streaming' ||
                  /^\s*$/.test(message.content) ||
                  message.content.replace(/\s/g, '').length === 0 ||
                  message.content === 'Audio Mode Active' ||
                  // Á©∫„ÅÆ„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÇÑÈÖçÂàó„ÅÆÊñáÂ≠óÂàóË°®Áèæ„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                  /^\s*\{\s*\}\s*$/.test(message.content) ||
                  /^\s*\[\s*\]\s*$/.test(message.content) ||
                  // „Çà„ÇäÂé≥ÂØÜ„Å™Á©∫„ÅÆ„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÉÅ„Çß„ÉÉ„ÇØ
                  message.content.includes('[object Object]') ||
                  message.content.includes('[object Array]') ||
                  message.content.includes('{}') ||
                  message.content.includes('[]')) && 
                  !message.videoUrl) {
                console.log('‚ùå Filtering out message:', message.id, message.content)
                return false
              }
              
              console.log('‚úÖ Keeping message:', message.id, message.content)
              return true
            })
            .map((message) => (
              <ChatMessage 
                key={message.id} 
                {...message} 
                useEnhancedPreview={useEnhancedPreview}
                onEdit={handleMessageEdit}
                onCancelEdit={handleMessageEditCancel}
                audioEnabled={audioEnabled}
              />
            ))}
          
          {/* Agent Info Display - Hidden for Router Agents */}
          {/* {agentInfo && agentInfo.type && currentAnalysis && !isTTSProcessing && (
            <AgentInfoDisplay
              agentType={agentInfo.type}
              confidence={agentInfo.confidence}
              reasoning={agentInfo.reasoning}
              complexity={currentAnalysis.complexity}
            />
          )} */}
          {isTyping && !streamingResponse && (
                          <>
                {console.log('üîç isTyping state:', { isTyping, loadingState, streamingResponse })}
                {loadingState === 'text' ? (
                  <JumpingDots className="text-blue-500" />
                ) : (
                  <div className="flex items-center gap-3 p-4 rounded-lg border-[0.5px] border-[#2B2B2B]">
                    <div className="flex items-center gap-2">
                      {loadingState === 'media' ? (
                        <>
                          <CircleSpinner size="sm" className="text-blue-500" />
                          <span className="text-sm text-muted-foreground">Generating...</span>
                        </>
                      ) : (
                        <>
                          <CircleSpinner size="sm" className="text-blue-500" />
                          <span className="text-sm text-muted-foreground">Thinking...</span>
                        </>
                      )}
                    </div>
                  </div>
                )}
              </>
          )}
          {streamingResponse && 
           streamingResponse.trim() !== '' && 
           streamingResponse.length > 0 && 
           streamingResponse !== '{}' && 
           streamingResponse !== '[]' && 
           streamingResponse !== 'null' && 
           streamingResponse !== 'undefined' &&
           !/^\s*\{\s*\}\s*$/.test(streamingResponse) &&
           !/^\s*\[\s*\]\s*$/.test(streamingResponse) && (
            <ChatMessage
              id="streaming"
              content={streamingResponse}
              role="assistant"
              isStreaming={isTyping}
              audioEnabled={audioEnabled}
            />
          )}

          {/* „É¢„Éá„É´„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâË°®Á§∫ÔºàShimmer EffectÔºâ */}
          {modelDownloadState.isDownloading && (
            <ModelDownloadShimmer
              modelName={modelDownloadState.modelName}
              progress={modelDownloadState.progress}
              status={modelDownloadState.status}
              downloadedBytes={modelDownloadState.downloadedBytes}
              totalBytes={modelDownloadState.totalBytes}
              className="animate-in slide-in-from-bottom-2 duration-300"
            />
          )}

          {/* STTÂÆüË°å‰∏≠Ë°®Á§∫ÔºàShimmer EffectÔºâ */}
          {isSTTTranscribing && (
            <div className="flex items-center p-3 animate-in slide-in-from-bottom-2 duration-300">
              <ShimmerText className="text-sm font-medium text-blue-600 dark:text-blue-400">
                Transcribing audio file...
              </ShimmerText>
              {sttFileName && (
                <span className="text-xs text-muted-foreground ml-2">
                  {sttFileName}
                </span>
              )}
            </div>
          )}

          {/* „Çø„Çπ„ÇØÂÆüË°åË°®Á§∫ÔºàShimmer EffectÔºâ */}
          {activeTasks
            .filter(task => !task.title.includes('Chat Response Generation'))
            .filter(task => task.status === 'running' || task.status === 'pending')
            .map((task) => (
            <TaskShimmerDisplay
              key={task.id}
              task={task}
              className="animate-in slide-in-from-bottom-2 duration-300"
            />
          ))}

          {/* „Éï„Ç°„Ç§„É´‰ΩúÊàêË°®Á§∫ */}
          {activeFileCreations.length > 0 && (
            <div className="space-y-3 mt-4">
              <div className="flex items-center justify-between">
                <h3 className="text-sm font-medium text-muted-foreground">
                  „Éï„Ç°„Ç§„É´‰ΩúÊàê‰∏≠ ({activeFileCreations.length})
                </h3>
                <Button
                  variant="ghost"
                  size="sm"
                  onClick={clearCompletedFileCreations}
                  className="text-xs"
                >
                  ÂÆå‰∫ÜÊ∏à„Åø„Çí„ÇØ„É™„Ç¢
                </Button>
              </div>
              {activeFileCreations.map((fileCreation) => (
                <FileCreationLoader
                  key={fileCreation.id}
                  fileInfo={fileCreation}
                  className="animate-in slide-in-from-bottom-2 duration-300"
                />
              ))}
            </div>
          )}
        </div>
      </ScrollArea>

      {/* Input area */}
      <div className="border-t p-4">
        {/* Ê∑ª‰ªò„Éï„Ç°„Ç§„É´Ë°®Á§∫ */}
        {selectedFiles.length > 0 && (
          <div className="mb-3 flex flex-wrap gap-2">
            {selectedFiles.map((file, index) => (
              <div key={index} className="flex items-center space-x-2 bg-muted rounded-lg p-2">
                {useEnhancedPreview ? (
                  <EnhancedFilePreview 
                    file={file} 
                    onRemove={() => removeAttachment(index)}
                    showPreview={true}
                    googleService={geminiFileService}
                    onTranscriptionComplete={handleTranscriptionComplete}
                  />
                ) : (
                  <EnhancedFilePreview 
                    file={file}
                    googleService={geminiFileService}
                    onTranscriptionComplete={handleTranscriptionComplete}
                  />
                )}
                {!useEnhancedPreview && (
                  <Button
                    type="button"
                    variant="ghost"
                    size="sm"
                    onClick={() => removeAttachment(index)}
                    className="h-6 w-6 p-0"
                  >
                    <X className="h-3 w-3" />
                  </Button>
                )}
              </div>
            ))}
          </div>
        )}

        {/* Embedded CLI */}
        {showCLI && (
          <div className="mb-3">
            <EmbeddedCLI
              onClose={() => setShowCLI(false)}
              isMinimized={isCLIMinimized}
              onToggleMinimize={() => setIsCLIMinimized(!isCLIMinimized)}
              fontSettings={cliFontSettings}
            />
          </div>
        )}

        <PromptInputBox
          onSend={handleSendMessage}
          onAttachFiles={handleFilesAdded}
          onStop={handleStopGeneration}
          disabled={isTyping}
          placeholder=""
          modelSettings={modelSettings}
          onModelSettingsChange={handleModelSettingsChange}
          onModelSelect={handleModelSelect}
          providerApiKeys={providerApiKeys}
          loadingState={loadingState}
          selectedFiles={selectedFiles}
          currentProviderConfig={currentProviderConfig}
          isGenerating={isGenerating}
          webSearchEnabled={webSearchEnabled}
          onWebSearchToggle={handleWebSearchToggle}
          createImageEnabled={createImageEnabled}
          onCreateImageToggle={handleCreateImageToggle}
          audioEnabled={audioEnabled}
          onAudioToggle={handleAudioToggle}
          videoEnabled={videoEnabled}
          onVideoToggle={handleVideoToggle}
          onGetCurrentMessage={getCurrentMessage}
          generationSettings={generationSettings}
          onSTTStatusChange={(isTranscribing, fileName) => {
            setIsSTTTranscribing(isTranscribing)
            setSttFileName(fileName || '')
          }}
        />
      </div>

      {/* „Éâ„É©„ÉÉ„Ç∞„Ç™„Éº„Éê„Éº„É¨„Ç§ */}
      <AnimatePresence>
        {isDragging && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            className="absolute inset-0 bg-primary/10 border-2 border-dashed border-primary rounded-lg flex items-center justify-center z-50"
          >
            <div className="text-center">
              <Paperclip className="h-8 w-8 mx-auto mb-2" />
              <p className="text-sm font-medium">„Éï„Ç°„Ç§„É´„Çí„Éâ„É≠„ÉÉ„Éó„Åó„Å¶„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ</p>
            </div>
          </motion.div>
        )}
      </AnimatePresence>



      {/* Settings Modal */}
      {showSettings && (
        <ArmisSettings
          onClose={() => setShowSettings(false)}
          onProviderSelect={handleProviderSelect}
                  currentModelSettings={modelSettings}
        onModelSettingsChange={handleModelSettingsChange}
          providerApiKeys={providerApiKeys}
          onProviderApiKeysChange={setProviderApiKeys}
          llmManager={llmManager}
          generationSettings={generationSettings}
          onGenerationSettingsChange={setGenerationSettings}
          onCliFontSettingsChange={handleCliFontSettingsChange}
          currentCliFontSettings={cliFontSettings}
          currentTheme={theme}
          onThemeChange={setTheme}
          factCheckingSettings={factCheckingSettings}
          onFactCheckingSettingsChange={handleFactCheckingSettingsChange}
        />
      )}


    </div>
  )
}
