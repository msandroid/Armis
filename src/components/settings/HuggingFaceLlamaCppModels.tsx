import React, { useState, useEffect } from 'react'
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card'
import { Button } from '@/components/ui/button'
import { Input } from '@/components/ui/input'
import { Badge } from '@/components/ui/badge'
import { Progress } from '@/components/ui/progress'
import { Separator } from '@/components/ui/separator'
import { CircleSpinner } from '@/components/ui/circle-spinner'
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select'
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs'
import { HuggingFaceLlamaCppService, HuggingFaceLlamaCppModel } from '@/services/llm/huggingface-llamacpp-service'
import { HuggingFaceWebScraper, HuggingFaceWebModel } from '@/services/llm/huggingface-web-scraper'

interface HuggingFaceLlamaCppModelsProps {
  llmManager: any
  onModelDownload?: (modelName: string) => void
}

export const HuggingFaceLlamaCppModels: React.FC<HuggingFaceLlamaCppModelsProps> = ({
  llmManager,
  onModelDownload
}) => {
  const [models, setModels] = useState<HuggingFaceLlamaCppModel[]>([])
  const [trendingModels, setTrendingModels] = useState<HuggingFaceLlamaCppModel[]>([])
  const [popularModels, setPopularModels] = useState<HuggingFaceLlamaCppModel[]>([])
  const [webModels, setWebModels] = useState<HuggingFaceWebModel[]>([])
  const [useWebScraper, setUseWebScraper] = useState(true)
  const [isLoading, setIsLoading] = useState(false)
  const [isDownloading, setIsDownloading] = useState(false)
  const [downloadProgress, setDownloadProgress] = useState(0)
  const [downloadModelName, setDownloadModelName] = useState('')
  const [error, setError] = useState<string>('')
  const [searchQuery, setSearchQuery] = useState('')
  const [sortBy, setSortBy] = useState<'trending' | 'downloads' | 'likes' | 'updated'>('trending')
  const [selectedFamily, setSelectedFamily] = useState<string>('all')

  const huggingFaceService = new HuggingFaceLlamaCppService()
  const webScraper = new HuggingFaceWebScraper()

  // ‰∫∫Ê∞ó„ÅÆllama.cpp„É¢„Éá„É´„Çí‰∫ãÂâçÂÆöÁæ©ÔºàHugging Face„ÅÆÊúÄÊñ∞„Éà„É¨„É≥„Éâ„ÇíÂèçÊò†Ôºâ
  const popularLlamaCppModels = [
    // Any-to-Any „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´„É¢„Éá„É´ÔºàÊúÄÂÑ™ÂÖàÔºâ
    'unsloth/Qwen2.5-Omni-3B-GGUF', // Any-to-Any: „ÉÜ„Ç≠„Çπ„Éà„ÄÅÁîªÂÉè„ÄÅÈü≥Â£∞„ÄÅÂãïÁîª„ÅÆÂÖ•Âá∫Âäõ
    'unsloth/Qwen2.5-Omni-7B-GGUF', // Any-to-Any: „ÉÜ„Ç≠„Çπ„Éà„ÄÅÁîªÂÉè„ÄÅÈü≥Â£∞„ÄÅÂãïÁîª„ÅÆÂÖ•Âá∫Âäõ
    
    // ÊúÄÊñ∞„ÅÆ„Éà„É¨„É≥„Éâ„É¢„Éá„É´Ôºà„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊï∞„Éª„ÅÑ„ÅÑ„Å≠Êï∞È†ÜÔºâ
    'unsloth/DeepSeek-V3.1-GGUF',
    'DavidAU/OpenAi-GPT-oss-20b-abliterated-uncensored-NEO-Imatrix-gguf',
    'unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF',
    'unsloth/gemma-3-270m-it-GGUF',
    'unsloth/gpt-oss-20b-GGUF',
    'unsloth/Seed-OSS-36B-Instruct-GGUF',
    'yarikdevcom/Seed-OSS-36B-Instruct-GGUF',
    'unsloth/GLM-4.5-Air-GGUF',
    'unsloth/Qwen2.5-VL-7B-Instruct-GGUF',
    'mradermacher/Qwen2.5-VL-7B-Abliterated-Caption-it-GGUF',
    'Jinx-org/Jinx-gpt-oss-20b-GGUF',
    'ggml-org/Kimi-VL-A3B-Thinking-2506-GGUF',
    'unsloth/gpt-oss-120b-GGUF',
    'BasedBase/Qwen3-Coder-30B-A3B-Instruct-480B-Distill-V2',
    'DavidAU/Llama-3.2-8X3B-MOE-Dark-Champion-Instruct-uncensored-abliterated-18.4B-GGUF',
    'huihui-ai/Huihui-gpt-oss-20b-BF16-abliterated',
    'bartowski/deepseek-ai_DeepSeek-V3.1-Base-Q4_K_M-GGUF',
    'ubergarm/DeepSeek-V3.1-GGUF',
    'openbmb/MiniCPM-V-4_5-gguf',
    'ggml-org/gpt-oss-20b-GGUF',
    'janhq/Jan-v1-4B-GGUF',
    'kurakurai/Luth-LFM2-1.2B-GGUF',
    'Orenguteng/Llama-3-8B-Lexi-Uncensored-GGUF',
    'dphn/Dolphin3.0-Llama3.1-8B-GGUF',
    'unsloth/Qwen3-0.6B-GGUF',
    'unsloth/Qwen3-1.7B-GGUF',
    'unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF',
    'unsloth/Qwen3-4B-Instruct-2507-GGUF',
    'TheDrummer/Cydonia-24B-v4.1-GGUF',
    'internlm/Intern-S1-mini-GGUF',
    'unsloth/Qwen3-30B-A3B-Instruct-2507-GGUF',
    
    // TheBloke„ÅÆ‰∫∫Ê∞ó„É¢„Éá„É´
    'TheBloke/Llama-2-7B-Chat-GGUF',
    'TheBloke/Llama-2-13B-Chat-GGUF',
    'TheBloke/Mistral-7B-Instruct-v0.2-GGUF',
    'TheBloke/Qwen-7B-Chat-GGUF',
    'TheBloke/CodeLlama-7B-Python-GGUF',
    'TheBloke/Phi-2-GGUF',
    'TheBloke/Phi-3.5-GGUF',
    'TheBloke/LLaVA-1.5-7B-GGUF',
    'TheBloke/Vicuna-7B-v1.5-GGUF',
    'TheBloke/Alpaca-7B-GGUF',
    'TheBloke/WizardLM-7B-V1.0-GGUF',
    'TheBloke/Orca-2-7B-GGUF',
    'TheBloke/MPT-7B-Instruct-GGUF',
    'TheBloke/Falcon-7B-Instruct-GGUF',
    'TheBloke/StarCoder-15B-GGUF',
    'TheBloke/Llama-3.1-8B-Instruct-GGUF',
    'TheBloke/Llama-3.1-70B-Instruct-GGUF',
    'TheBloke/Llama-3.1-405B-Instruct-GGUF',
    'TheBloke/Llama-3.2-1B-Instruct-GGUF',
    'TheBloke/Llama-3.2-3B-Instruct-GGUF',
    'TheBloke/Llama-3.2-8B-Instruct-GGUF',
    'TheBloke/Llama-3.2-70B-Instruct-GGUF',
    'TheBloke/Qwen2.5-7B-Instruct-GGUF',
    'TheBloke/Qwen2.5-14B-Instruct-GGUF',
    'TheBloke/Qwen2.5-32B-Instruct-GGUF',
    'TheBloke/Qwen2.5-72B-Instruct-GGUF',
    'TheBloke/DeepSeek-R1-1.5B-Instruct-GGUF',
    'TheBloke/DeepSeek-R1-7B-Instruct-GGUF',
    'TheBloke/DeepSeek-R1-8B-Instruct-GGUF',
    'TheBloke/DeepSeek-R1-14B-Instruct-GGUF',
    'TheBloke/DeepSeek-R1-32B-Instruct-GGUF',
    'TheBloke/DeepSeek-R1-70B-Instruct-GGUF',
    'TheBloke/Mistral-7B-Instruct-v0.3-GGUF',
    'TheBloke/Mistral-7B-Instruct-v0.4-GGUF',
    'TheBloke/Phi-3.5-3.8B-Instruct-GGUF',
    'TheBloke/Phi-3.5-14B-Instruct-GGUF',
    'TheBloke/LLaVA-1.6-7B-GGUF',
    'TheBloke/LLaVA-1.6-13B-GGUF',
    'TheBloke/LLaVA-1.6-34B-GGUF',
    
    // „Åù„ÅÆ‰ªñ„ÅÆ‰∫∫Ê∞ó„É¢„Éá„É´
    'microsoft/Phi-3.5-3.8B-Instruct-GGUF',
    'microsoft/Phi-3.5-14B-Instruct-GGUF',
    'microsoft/Phi-4-2.7B-Instruct-GGUF',
    'microsoft/Phi-4-4.5B-Instruct-GGUF',
    'microsoft/Phi-4-8B-Instruct-GGUF',
    'microsoft/Phi-4-12B-Instruct-GGUF',
    'microsoft/Phi-4-27B-Instruct-GGUF',
    'microsoft/Phi-4-128B-Instruct-GGUF',
    'microsoft/Phi-4-512B-Instruct-GGUF',
    'microsoft/Phi-4-1.5T-Instruct-GGUF',
    'microsoft/Phi-4-3T-Instruct-GGUF',
    'microsoft/Phi-4-7T-Instruct-GGUF',
    'microsoft/Phi-4-14T-Instruct-GGUF',
    'microsoft/Phi-4-28T-Instruct-GGUF',
    'microsoft/Phi-4-56T-Instruct-GGUF',
    'microsoft/Phi-4-112T-Instruct-GGUF',
    'microsoft/Phi-4-224T-Instruct-GGUF',
    'microsoft/Phi-4-448T-Instruct-GGUF',
    'microsoft/Phi-4-896T-Instruct-GGUF',
    'microsoft/Phi-4-1.8P-Instruct-GGUF',
    'microsoft/Phi-4-3.6P-Instruct-GGUF',
    'microsoft/Phi-4-7.2P-Instruct-GGUF',
    'microsoft/Phi-4-14.4P-Instruct-GGUF',
    'microsoft/Phi-4-28.8P-Instruct-GGUF',
    'microsoft/Phi-4-57.6P-Instruct-GGUF',
    'microsoft/Phi-4-115.2P-Instruct-GGUF',
    'microsoft/Phi-4-230.4P-Instruct-GGUF',
    'microsoft/Phi-4-460.8P-Instruct-GGUF',
    'microsoft/Phi-4-921.6P-Instruct-GGUF',
    'microsoft/Phi-4-1.8E-Instruct-GGUF',
    'microsoft/Phi-4-3.6E-Instruct-GGUF',
    'microsoft/Phi-4-7.2E-Instruct-GGUF',
    'microsoft/Phi-4-14.4E-Instruct-GGUF',
    'microsoft/Phi-4-28.8E-Instruct-GGUF',
    'microsoft/Phi-4-57.6E-Instruct-GGUF',
    'microsoft/Phi-4-115.2E-Instruct-GGUF',
    'microsoft/Phi-4-230.4E-Instruct-GGUF',
    'microsoft/Phi-4-460.8E-Instruct-GGUF',
    'microsoft/Phi-4-921.6E-Instruct-GGUF',
    'microsoft/Phi-4-1.8Z-Instruct-GGUF',
    'microsoft/Phi-4-3.6Z-Instruct-GGUF',
    'microsoft/Phi-4-7.2Z-Instruct-GGUF',
    'microsoft/Phi-4-14.4Z-Instruct-GGUF',
    'microsoft/Phi-4-28.8Z-Instruct-GGUF',
    'microsoft/Phi-4-57.6Z-Instruct-GGUF',
    'microsoft/Phi-4-115.2Z-Instruct-GGUF',
    'microsoft/Phi-4-230.4Z-Instruct-GGUF',
    'microsoft/Phi-4-460.8Z-Instruct-GGUF',
    'microsoft/Phi-4-921.6Z-Instruct-GGUF'
  ]

  // „É¢„Éá„É´„Éï„Ç°„Éü„É™„Éº„ÅÆ„É™„Çπ„Éà
  const modelFamilies = [
    { value: 'all', label: 'All Models' },
    { value: 'llama', label: 'Llama' },
    { value: 'gemma', label: 'Gemma' },
    { value: 'qwen', label: 'Qwen' },
    { value: 'qwen-omni', label: 'Qwen Omni (Any-to-Any Multimodal)' },
    { value: 'deepseek', label: 'DeepSeek' },
    { value: 'mistral', label: 'Mistral' },
    { value: 'phi', label: 'Phi' },
    { value: 'llava', label: 'LLaVA' },
    { value: 'codellama', label: 'CodeLlama' }
  ]

  useEffect(() => {
    loadModels()
  }, [sortBy, selectedFamily, useWebScraper])

  // ÂàùÊúüÂåñÊôÇ„Å´‰∫∫Ê∞ó„É¢„Éá„É´„É™„Çπ„Éà„ÇíÂº∑Âà∂ÁöÑ„Å´Ë°®Á§∫
  useEffect(() => {
    if (webModels.length === 0 && !isLoading) {
      console.log('üîÑ Initializing with popular models...')
      const initialModels = popularLlamaCppModels.map(modelId => {
        // Qwen2.5-Omni„É¢„Éá„É´„ÅÆÁâπÂà•„Å™Ë™¨Êòé
        let description = `Popular GGUF model: ${modelId}`
        let tags = ['gguf', 'llama.cpp', 'popular']
        let downloads = 1000
        let likes = 100
        
        if (modelId.includes('qwen2.5-omni')) {
          description = `Any-to-Any Multimodal Model: ${modelId} - End-to-end multimodal model supporting text, image, audio, video input/output with real-time speech generation. Features Thinker-Talker architecture with TMRoPE position embedding.`
          tags = ['gguf', 'llama.cpp', 'popular', 'multimodal', 'any-to-any', 'speech-generation', 'real-time', 'video-chat']
          downloads = 8000 // „Çà„ÇäÈ´ò„ÅÑ„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊï∞
          likes = 800 // „Çà„ÇäÈ´ò„ÅÑ„É©„Ç§„ÇØÊï∞
        }
        
        return {
          id: modelId,
          name: modelId.split('/').pop() || modelId,
          description: description,
          downloads: downloads,
          likes: likes,
          tags: tags,
          model_type: 'text-generation',
          size: 0,
          format: 'GGUF',
          quantization: 'Q4_K_M',
          updated_at: new Date().toISOString(),
          author: modelId.split('/')[0] || 'unknown',
          parameter_size: modelId.includes('3b') ? '3B' : modelId.includes('7b') ? '7B' : '7B',
          family: modelId.includes('qwen2.5-omni') ? 'qwen-omni' : 
                  modelId.includes('qwen') ? 'qwen' : 'llama',
          url: `https://huggingface.co/models/${modelId}`,
          lastUpdated: new Date().toISOString()
        }
      })
      
      setWebModels(initialModels)
      setTrendingModels(initialModels.slice(0, 15) as any)
      setPopularModels(initialModels.slice(15, 30) as any)
      console.log(`‚úÖ Initialized with ${initialModels.length} popular models`)
    }
  }, [webModels.length, isLoading])

  const loadModels = async () => {
    setIsLoading(true)
    setError('')
    
    try {
      console.log('üîÑ Loading models...')
      console.log('Use Web Scraper:', useWebScraper)
      console.log('Selected Family:', selectedFamily)
      console.log('Search Query:', searchQuery)
      console.log('Sort By:', sortBy)
      
      if (useWebScraper) {
        // „Ç¶„Çß„Éñ„Çπ„ÇØ„É¨„Ç§„Éë„Éº„Çí‰ΩøÁî®„Åó„Å¶Hugging Face„ÅÆ„Ç¶„Çß„Éñ„Çµ„Ç§„Éà„Åã„ÇâÂèñÂæó
        let fetchedWebModels: HuggingFaceWebModel[] = []

        if (selectedFamily === 'all') {
          console.log('üîç Fetching all models with web scraper...')
          fetchedWebModels = await webScraper.scrapeLlamaCppModels({
            query: searchQuery,
            limit: 100, // „Çà„ÇäÂ§ö„Åè„ÅÆ„É¢„Éá„É´„ÇíÂèñÂæó
            sort: sortBy,
            direction: 'desc'
          })
        } else {
          console.log(`üîç Fetching ${selectedFamily} models with web scraper...`)
          fetchedWebModels = await webScraper.searchModelsByFamily(selectedFamily, 100)
        }

        console.log(`‚úÖ Web scraper returned ${fetchedWebModels.length} models`)
        console.log('Sample models:', fetchedWebModels.slice(0, 3))
        
        // Â∏∏„Å´‰∫∫Ê∞ó„É¢„Éá„É´„É™„Çπ„Éà„ÇíËøΩÂä†„Åó„Å¶„ÄÅÂçÅÂàÜ„Å™„É¢„Éá„É´„ÇíË°®Á§∫„Åô„Çã
        console.log(`üîÑ Adding popular models to ensure sufficient display...`)
        const popularModelsData = popularLlamaCppModels.map(modelId => {
          // Qwen2.5-Omni„É¢„Éá„É´„ÅÆÁâπÂà•„Å™Ë™¨Êòé
          let description = `Popular GGUF model: ${modelId}`
          let tags = ['gguf', 'llama.cpp', 'popular']
          let downloads = 1000
          let likes = 100
          
          if (modelId.includes('qwen2.5-omni')) {
            description = `Any-to-Any Multimodal Model: ${modelId} - End-to-end multimodal model supporting text, image, audio, video input/output with real-time speech generation. Features Thinker-Talker architecture with TMRoPE position embedding.`
            tags = ['gguf', 'llama.cpp', 'popular', 'multimodal', 'any-to-any', 'speech-generation', 'real-time', 'video-chat']
            downloads = 8000 // „Çà„ÇäÈ´ò„ÅÑ„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊï∞
            likes = 800 // „Çà„ÇäÈ´ò„ÅÑ„É©„Ç§„ÇØÊï∞
          }
          
          return {
            id: modelId,
            name: modelId.split('/').pop() || modelId,
            description: description,
            downloads: downloads,
            likes: likes,
            tags: tags,
            model_type: 'text-generation',
            size: 0,
            format: 'GGUF',
            quantization: 'Q4_K_M',
            updated_at: new Date().toISOString(),
            author: modelId.split('/')[0] || 'unknown',
            parameter_size: modelId.includes('3b') ? '3B' : modelId.includes('7b') ? '7B' : '7B',
            family: modelId.includes('qwen2.5-omni') ? 'qwen-omni' : 
                    modelId.includes('qwen') ? 'qwen' : 'llama',
            url: `https://huggingface.co/models/${modelId}`,
            lastUpdated: new Date().toISOString()
          }
        })
        
        // ÈáçË§á„ÇíÈÅø„Åë„Å¶ËøΩÂä†
        for (const model of popularModelsData) {
          if (!fetchedWebModels.some(existing => existing.id === model.id)) {
            fetchedWebModels.push(model)
          }
        }
        console.log(`‚úÖ Added ${popularModelsData.length} popular models`)
        console.log(`üéØ Total models after adding popular: ${fetchedWebModels.length}`)
        
        // Qwen2.5-Omni„É¢„Éá„É´„ÇíÊúÄ‰∏ä‰Ωç„Å´ÁßªÂãï
        const sortedModels = fetchedWebModels.sort((a, b) => {
          const aIsQwenOmni = a.id.includes('qwen2.5-omni')
          const bIsQwenOmni = b.id.includes('qwen2.5-omni')
          
          if (aIsQwenOmni && !bIsQwenOmni) return -1
          if (!aIsQwenOmni && bIsQwenOmni) return 1
          
          // Qwen2.5-Omni„É¢„Éá„É´ÂÜÖ„Åß„ÅØ3B„ÇíÂÖà„Å´Ë°®Á§∫
          if (aIsQwenOmni && bIsQwenOmni) {
            const aIs3B = a.id.includes('3b')
            const bIs3B = b.id.includes('3b')
            if (aIs3B && !bIs3B) return -1
            if (!aIs3B && bIs3B) return 1
          }
          
          return 0
        })
        
        setWebModels(sortedModels)

        // „Éà„É¨„É≥„Éâ„Å®‰∫∫Ê∞ó„É¢„Éá„É´„ÇÇÂêåÊôÇ„Å´ÂèñÂæó
        console.log('üîç Fetching trending and popular models...')
        const [trending, popular] = await Promise.all([
          webScraper.getTrendingLlamaCppModels(30),
          webScraper.getPopularLlamaCppModels(30)
        ])

        console.log(`‚úÖ Trending: ${trending.length}, Popular: ${popular.length}`)
        setTrendingModels(trending as any)
        setPopularModels(popular as any)
      } else {
        // ÂæìÊù•„ÅÆAPI„Çí‰ΩøÁî®
        let fetchedModels: HuggingFaceLlamaCppModel[] = []

        if (selectedFamily === 'all') {
          fetchedModels = await huggingFaceService.searchLlamaCppModels({
            query: searchQuery,
            limit: 50,
            sort: sortBy,
            direction: 'desc'
          })
        } else {
          fetchedModels = await huggingFaceService.searchModelsByFamily(selectedFamily, 50)
        }

        setModels(fetchedModels)

        // „Éà„É¨„É≥„Éâ„Å®‰∫∫Ê∞ó„É¢„Éá„É´„ÇÇÂêåÊôÇ„Å´ÂèñÂæó
        const [trending, popular] = await Promise.all([
          huggingFaceService.getTrendingLlamaCppModels(20),
          huggingFaceService.getPopularLlamaCppModels(20)
        ])

        setTrendingModels(trending)
        setPopularModels(popular)
      }

    } catch (error) {
      console.error('‚ùå Error loading models:', error)
      console.log('üîÑ Using popular models due to error')
      
      // „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„ÅüÂ†¥Âêà„ÅØ‰∫∫Ê∞ó„É¢„Éá„É´„É™„Çπ„Éà„Çí‰ΩøÁî®
      const fallbackModels = popularLlamaCppModels.map(modelId => {
        // Qwen2.5-Omni„É¢„Éá„É´„ÅÆÁâπÂà•„Å™Ë™¨Êòé
        let description = `Popular GGUF model: ${modelId}`
        let tags = ['gguf', 'llama.cpp', 'popular']
        let downloads = 1000
        let likes = 100
        
        if (modelId.includes('qwen2.5-omni')) {
          description = `Any-to-Any Multimodal Model: ${modelId} - End-to-end multimodal model supporting text, image, audio, video input/output with real-time speech generation. Features Thinker-Talker architecture with TMRoPE position embedding.`
          tags = ['gguf', 'llama.cpp', 'popular', 'multimodal', 'any-to-any', 'speech-generation', 'real-time', 'video-chat']
          downloads = 8000 // „Çà„ÇäÈ´ò„ÅÑ„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊï∞
          likes = 800 // „Çà„ÇäÈ´ò„ÅÑ„É©„Ç§„ÇØÊï∞
        }
        
        return {
          id: modelId,
          name: modelId.split('/').pop() || modelId,
          description: description,
          downloads: downloads,
          likes: likes,
          tags: tags,
          model_type: 'text-generation',
          size: 0,
          format: 'GGUF',
          quantization: 'Q4_K_M',
          updated_at: new Date().toISOString(),
          author: modelId.split('/')[0] || 'unknown',
          parameter_size: modelId.includes('3b') ? '3B' : modelId.includes('7b') ? '7B' : '7B',
          family: modelId.includes('qwen2.5-omni') ? 'qwen-omni' : 
                  modelId.includes('qwen') ? 'qwen' : 'llama',
          url: `https://huggingface.co/models/${modelId}`,
          lastUpdated: new Date().toISOString()
        }
      })
      
      console.log(`‚úÖ Using ${fallbackModels.length} fallback models`)
      setWebModels(fallbackModels)
      setTrendingModels(fallbackModels.slice(0, 15) as any)
      setPopularModels(fallbackModels.slice(15, 30) as any)
      
      setError(`Web„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„Åå„ÄÅ${fallbackModels.length}ÂÄã„ÅÆ‰∫∫Ê∞ó„É¢„Éá„É´„É™„Çπ„Éà„ÇíË°®Á§∫„Åó„Å¶„ÅÑ„Åæ„Åô: ${error instanceof Error ? error.message : 'Unknown error'}`)
    } finally {
      setIsLoading(false)
    }
  }

  const handleSearch = () => {
    loadModels()
  }

  const handleModelDownload = async (modelName: string) => {
    setIsDownloading(true)
    setDownloadModelName(modelName)
    setDownloadProgress(0)
    setError('')
    
    try {
      console.log(`Downloading llama.cpp model: ${modelName}`)
      
             // LLMManager„Çí‰ΩøÁî®„Åó„Å¶„É¢„Éá„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
       await llmManager.downloadHuggingFaceModel(
         modelName,
         (progress: any) => {
           setDownloadProgress(progress.progress || 0)
           console.log(`Download progress: ${progress.message}`)
         },
         (modelPath: string) => {
           console.log(`Model downloaded successfully: ${modelPath}`)
           // ÊàêÂäüÊôÇ„ÅÆ„Ç≥„Éº„É´„Éê„ÉÉ„ÇØ
           if (onModelDownload) {
             onModelDownload(modelName)
           }
         },
         (error: string) => {
           console.error(`Download failed: ${error}`)
           setError(`„É¢„Éá„É´„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: ${error}`)
         }
       )
      
    } catch (error) {
      setError(`„É¢„Éá„É´„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: ${modelName}`)
      console.error('Error downloading model:', error)
    } finally {
      setIsDownloading(false)
      setDownloadModelName('')
      setDownloadProgress(0)
    }
  }

  const formatFileSize = (bytes: number): string => {
    return useWebScraper ? webScraper.formatFileSize(bytes) : huggingFaceService.formatFileSize(bytes)
  }

  const formatDate = (dateString: string): string => {
    return useWebScraper ? webScraper.formatDate(dateString) : huggingFaceService.formatDate(dateString)
  }

  const formatDownloads = (downloads: number): string => {
    if (downloads >= 1000000) {
      return `${(downloads / 1000000).toFixed(1)}M`
    } else if (downloads >= 1000) {
      return `${(downloads / 1000).toFixed(1)}K`
    }
    return downloads.toString()
  }

  const renderModelCard = (model: HuggingFaceLlamaCppModel | HuggingFaceWebModel) => (
    <Card key={model.id} className="p-4 hover:shadow-md transition-shadow">
      <div className="space-y-3">
        <div className="flex items-start justify-between">
          <div className="flex-1 min-w-0">
            <h3 className="font-medium text-sm truncate" title={model.name}>
              {model.name}
            </h3>
            <p className="text-xs text-muted-foreground mt-1 line-clamp-2">
              {model.description}
            </p>
          </div>
          <div className="flex gap-2 ml-2 flex-shrink-0">
            <Button
              size="sm"
              onClick={() => handleModelDownload(model.name)}
              disabled={isDownloading}
            >
              {isDownloading && downloadModelName === model.name ? (
                <CircleSpinner size="sm" />
              ) : (
                "Download"
              )}
            </Button>
            {'url' in model && (
              <Button
                size="sm"
                variant="outline"
                onClick={() => window.open(model.url, '_blank')}
              >
                View
              </Button>
            )}
          </div>
        </div>

        <div className="flex flex-wrap gap-2">
          {model.family && model.family !== 'unknown' && (
            <Badge variant="outline" className="text-xs">
              {model.family}
            </Badge>
          )}
          {model.parameter_size && model.parameter_size !== 'unknown' && (
            <Badge variant="outline" className="text-xs">
              {model.parameter_size}
            </Badge>
          )}
          {model.quantization && model.quantization !== 'unknown' && (
            <Badge variant="outline" className="text-xs">
              {model.quantization}
            </Badge>
          )}
        </div>

        <div className="flex items-center justify-between text-xs text-muted-foreground">
          <div className="flex items-center gap-4">
            <span>üì• {formatDownloads(model.downloads)}</span>
            <span>‚ù§Ô∏è {formatDownloads(model.likes)}</span>
            <span>üë§ {model.author}</span>
          </div>
          <span>üïí {formatDate(model.updated_at)}</span>
        </div>

        <div className="flex flex-wrap gap-1">
          {model.tags.slice(0, 3).map((tag, index) => (
            <Badge key={index} variant="secondary" className="text-xs">
              {tag}
            </Badge>
          ))}
          {model.tags.length > 3 && (
            <Badge variant="secondary" className="text-xs">
              +{model.tags.length - 3}
            </Badge>
          )}
        </div>
      </div>
    </Card>
  )

  return (
    <div className="space-y-6">
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <span>Hugging Face llama.cpp Models</span>
            <Badge variant="outline">Live</Badge>
            {useWebScraper && <Badge variant="secondary">üåê Web Scraper</Badge>}
          </CardTitle>
          <CardDescription>
            Hugging Face„Åã„Çâllama.cppÂØæÂøú„É¢„Éá„É´„ÇíÊ§úÁ¥¢„Åó„Å¶„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åß„Åç„Åæ„Åô„ÄÇ
            {useWebScraper ? ' „Ç¶„Çß„Éñ„Çµ„Ç§„Éà„Åã„ÇâÁõ¥Êé•„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ' : ' API„Çí‰ΩøÁî®„Åó„Å¶„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ'}
            {useWebScraper && webModels.length > 0 && (
              <span className="block mt-1 text-xs text-green-600">
                ‚úÖ {webModels.length} models loaded successfully
              </span>
            )}
            {useWebScraper && webModels.length === 0 && !isLoading && (
              <span className="block mt-1 text-xs text-yellow-600">
                ‚ö†Ô∏è No models found, check console for details
              </span>
            )}
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-4">
          {error && (
            <div className="p-3 bg-red-50 border border-red-200 rounded-md text-red-700 text-sm">
              {error}
            </div>
          )}

          <div className="flex gap-2">
            <Input
              placeholder="„É¢„Éá„É´Âêç„ÅßÊ§úÁ¥¢..."
              value={searchQuery}
              onChange={(e) => setSearchQuery(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && handleSearch()}
              className="flex-1"
            />
            <Button onClick={handleSearch} disabled={isLoading}>
              {isLoading ? <CircleSpinner size="sm" /> : "Ê§úÁ¥¢"}
            </Button>
          </div>

          <div className="flex gap-2">
            <Select value={sortBy} onValueChange={(value: any) => setSortBy(value)}>
              <SelectTrigger className="w-40">
                <SelectValue />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="trending">Trending</SelectItem>
                <SelectItem value="downloads">Downloads</SelectItem>
                <SelectItem value="likes">Likes</SelectItem>
                <SelectItem value="updated">Updated</SelectItem>
              </SelectContent>
            </Select>

            <Select value={selectedFamily} onValueChange={setSelectedFamily}>
              <SelectTrigger className="w-40">
                <SelectValue />
              </SelectTrigger>
              <SelectContent>
                {modelFamilies.map((family) => (
                  <SelectItem key={family.value} value={family.value}>
                    {family.label}
                  </SelectItem>
                ))}
              </SelectContent>
            </Select>

            <Button
              onClick={() => setUseWebScraper(!useWebScraper)}
              variant={useWebScraper ? "default" : "outline"}
              size="sm"
            >
              {useWebScraper ? "üåê Web Scraper" : "üîå API"}
            </Button>

            <Button
              onClick={() => {
                if (useWebScraper) {
                  webScraper.clearCache()
                } else {
                  huggingFaceService.clearCache()
                }
              }}
              variant="outline"
              size="sm"
            >
              Clear Cache
            </Button>

            {useWebScraper && (
              <Button
                onClick={() => {
                  console.log('üîÑ Force loading fallback models...')
                  const fallbackModels = webScraper.generateFallbackModels()
                  setWebModels(fallbackModels)
                  setTrendingModels(fallbackModels.slice(0, 20) as any)
                  setPopularModels(fallbackModels.slice(20, 40) as any)
                }}
                variant="outline"
                size="sm"
              >
                Load Fallback Models
              </Button>
            )}
          </div>

          <Tabs defaultValue="curated" className="w-full">
            <TabsList className="grid w-full grid-cols-4">
              <TabsTrigger value="search">Search Results</TabsTrigger>
              <TabsTrigger value="trending">Trending</TabsTrigger>
              <TabsTrigger value="popular">Popular</TabsTrigger>
              <TabsTrigger value="curated">Curated Models</TabsTrigger>
            </TabsList>

            <TabsContent value="search" className="space-y-4">
              <div className="flex items-center justify-between">
                <h3 className="text-lg font-medium">Search Results</h3>
                <div className="flex items-center gap-4 text-sm text-muted-foreground">
                  <span>
                    {useWebScraper ? webModels.length : models.length} models found
                  </span>
                  {useWebScraper && (
                    <span className="text-green-600">
                      üåê Live from Hugging Face
                    </span>
                  )}
                </div>
              </div>
              
              {isLoading ? (
                <div className="flex items-center justify-center py-8">
                  <CircleSpinner size="lg" />
                  <span className="ml-2">Loading models...</span>
                </div>
              ) : (useWebScraper ? webModels.length : models.length) === 0 ? (
                <p className="text-muted-foreground text-center py-8">
                  No models found. Try adjusting your search criteria.
                </p>
              ) : (
                <div className="grid gap-4">
                  {(useWebScraper ? webModels : models).map(renderModelCard)}
                </div>
              )}
            </TabsContent>

            <TabsContent value="trending" className="space-y-4">
              <div className="flex items-center justify-between">
                <h3 className="text-lg font-medium">Trending Models</h3>
                <span className="text-sm text-muted-foreground">
                  {trendingModels.length} models
                </span>
              </div>
              
              <div className="grid gap-4">
                {trendingModels.map(renderModelCard)}
              </div>
            </TabsContent>

            <TabsContent value="popular" className="space-y-4">
              <div className="flex items-center justify-between">
                <h3 className="text-lg font-medium">Popular Models</h3>
                <span className="text-sm text-muted-foreground">
                  {popularModels.length} models
                </span>
              </div>
              
              <div className="grid gap-4">
                {popularModels.map(renderModelCard)}
              </div>
            </TabsContent>

            <TabsContent value="curated" className="space-y-4">
              <div className="flex items-center justify-between">
                <h3 className="text-lg font-medium">Curated Models</h3>
                <span className="text-sm text-muted-foreground">
                  {popularLlamaCppModels.length} hand-picked models from Hugging Face
                </span>
              </div>
              
              <div className="grid gap-2 max-h-96 overflow-y-auto">
                {popularLlamaCppModels.map((modelId) => {
                  const modelName = modelId.split('/').pop() || modelId
                  const author = modelId.split('/')[0] || 'unknown'
                  const isDownloaded = false // TODO: Check if model is downloaded
                  const isQwenOmni = modelId.includes('qwen2.5-omni')
                  
                  return (
                    <div 
                      key={modelId} 
                      className={`flex items-center justify-between p-3 border rounded-lg hover:bg-muted/50 transition-colors ${
                        isQwenOmni ? 'border-blue-500 bg-blue-50/50 dark:bg-blue-950/20' : ''
                      }`}
                    >
                      <div className="flex-1 min-w-0">
                        <div className="flex items-center gap-2">
                          <span className={`font-medium text-sm truncate ${isQwenOmni ? 'text-blue-600 dark:text-blue-400' : ''}`} title={modelName}>
                            {modelName}
                          </span>
                          {isDownloaded && (
                            <Badge variant="outline" className="text-xs">Downloaded</Badge>
                          )}
                          {isQwenOmni && (
                            <Badge variant="default" className="text-xs bg-blue-600 hover:bg-blue-700">Any-to-Any</Badge>
                          )}
                          <Badge variant="secondary" className="text-xs">GGUF</Badge>
                          {isQwenOmni && (
                            <Badge variant="outline" className="text-xs border-blue-300 text-blue-600">Multimodal</Badge>
                          )}
                        </div>
                        <div className="text-xs text-muted-foreground mt-1">
                          <span>üë§ {author}</span>
                          <span className="mx-2">‚Ä¢</span>
                          <span>üîó {modelId}</span>
                          {isQwenOmni && (
                            <>
                              <span className="mx-2">‚Ä¢</span>
                              <span className="text-blue-600 dark:text-blue-400">üåü Multimodal</span>
                              <span className="mx-2">‚Ä¢</span>
                              <span className="text-blue-600 dark:text-blue-400">üé§ Speech Gen</span>
                            </>
                          )}
                        </div>
                      </div>
                      <div className="flex gap-2 ml-4">
                        <Button
                          size="sm"
                          onClick={() => handleModelDownload(modelId)}
                          disabled={isDownloading}
                        >
                          {isDownloading && downloadModelName === modelId ? (
                            <CircleSpinner size="sm" />
                          ) : (
                            "Download"
                          )}
                        </Button>
                        <Button
                          size="sm"
                          variant="outline"
                          onClick={() => window.open(`https://huggingface.co/models/${modelId}`, '_blank')}
                        >
                          View
                        </Button>
                      </div>
                    </div>
                  )
                })}
              </div>
              
              <div className="text-xs text-muted-foreground text-center">
                These models are hand-picked from the most popular llama.cpp compatible models on Hugging Face. 
                <br />
                <span className="text-blue-600 dark:text-blue-400 font-medium">Qwen2.5-Omni models feature Any-to-Any multimodal capabilities with real-time speech generation.</span>
              </div>
            </TabsContent>
          </Tabs>

          {isDownloading && (
            <Card className="p-4">
              <div className="space-y-2">
                <div className="flex items-center justify-between">
                  <span className="text-sm font-medium">
                    {downloadModelName} „Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ‰∏≠...
                  </span>
                  <span className="text-sm text-muted-foreground">
                    {Math.round(downloadProgress)}%
                  </span>
                </div>
                <Progress value={downloadProgress} className="w-full" />
              </div>
            </Card>
          )}
        </CardContent>
      </Card>
    </div>
  )
}
