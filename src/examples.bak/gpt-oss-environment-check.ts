import { checkGptOssEnvironment, showGptOssModelInfo } from './gpt-oss-text-extraction-example'

/**
 * gpt-ossÁí∞Â¢É„ÉÅ„Çß„ÉÉ„ÇØ
 * 
 * „Åì„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„ÅØ„ÄÅgpt-oss„É¢„Éá„É´„ÅåÂãï‰Ωú„Åô„ÇãÁí∞Â¢É„Åã„Å©„ÅÜ„Åã„ÇíÁ¢∫Ë™ç„Åó„Åæ„Åô„ÄÇ
 * 
 * ÂèÇËÄÉ: https://qiita.com/rairaii/items/e76beb749649dac26794
 */

async function main() {
  console.log('üîç GptOss Environment Check\n')
  
  // 1. Áí∞Â¢É„ÉÅ„Çß„ÉÉ„ÇØ
  const env = checkGptOssEnvironment()
  
  if (!env.isNode) {
    console.log('‚ùå GptOss functionality requires Node.js environment')
    console.log('   This feature is not available in browser environment')
    return
  }
  
  console.log('‚úÖ Node.js environment detected')
  
  // 2. ÂøÖË¶Å„Å™„Éë„ÉÉ„Ç±„Éº„Ç∏„ÅÆÁ¢∫Ë™ç
  console.log('\nüì¶ Checking required packages...')
  
  try {
    // node-llama-cpp„ÅÆÁ¢∫Ë™ç
    const nodeLlamaCpp = await import('node-llama-cpp')
    console.log('‚úÖ node-llama-cpp package available')
  } catch (error) {
    console.log('‚ùå node-llama-cpp package not found')
    console.log('   Install with: npm install node-llama-cpp@3')
    return
  }
  
  try {
    // @langchain/community„ÅÆÁ¢∫Ë™ç
    const { ChatLlamaCpp } = await import('@langchain/community/chat_models/llama_cpp')
    console.log('‚úÖ @langchain/community package available')
  } catch (error) {
    console.log('‚ùå @langchain/community package not found')
    console.log('   Install with: npm install @langchain/community')
    return
  }
  
  // 3. „É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅÆÁ¢∫Ë™ç
  console.log('\nüìÅ Checking model files...')
  
  try {
    const fs = await import('fs')
    const path = await import('path')
    
    const modelsDir = './models'
    if (!fs.existsSync(modelsDir)) {
      console.log('‚ùå Models directory not found')
      console.log('   Create directory: mkdir models')
      console.log('   Download GGUF model files to ./models/')
      return
    }
    
    console.log('‚úÖ Models directory found')
    
    const files = fs.readdirSync(modelsDir)
    const ggufFiles = files.filter(file => file.endsWith('.gguf'))
    
    if (ggufFiles.length === 0) {
      console.log('‚ùå No GGUF model files found')
      console.log('   Download GGUF model files to ./models/')
      console.log('   Recommended gpt-oss models:')
      console.log('     - gpt-oss-20b-mxfp4.gguf (~15GB)')
      console.log('     - gpt-oss-20b-q4_0.gguf (~12GB)')
      console.log('     - gpt-oss-20b-q4_1.gguf (~13GB)')
      return
    }
    
    console.log('‚úÖ GGUF model files found:')
    ggufFiles.forEach(file => {
      const filePath = path.join(modelsDir, file)
      const stats = fs.statSync(filePath)
      const sizeGB = Math.round(stats.size / (1024 * 1024 * 1024) * 100) / 100
      console.log(`   - ${file} (${sizeGB} GB)`)
    })
    
    // gpt-oss„É¢„Éá„É´„ÅÆÁ¢∫Ë™ç
    const gptOssFiles = ggufFiles.filter(file => file.includes('gpt-oss'))
    if (gptOssFiles.length === 0) {
      console.log('\n‚ö†Ô∏è  No gpt-oss model files found')
      console.log('   For best performance, use gpt-oss models:')
      console.log('   - Download from: https://huggingface.co/ggml-org/gpt-oss-20b-GGUF')
      console.log('   - Recommended: gpt-oss-20b-mxfp4.gguf')
    } else {
      console.log('\n‚úÖ GptOss model files found:')
      gptOssFiles.forEach(file => {
        console.log(`   - ${file}`)
      })
    }
    
  } catch (error) {
    console.log('‚ùå Error checking model files:', error)
    return
  }
  
  // 4. „Ç∑„Çπ„ÉÜ„É†Ë¶Å‰ª∂„ÅÆÁ¢∫Ë™ç
  console.log('\nüíª Checking system requirements...')
  
  try {
    const os = await import('os')
    
    const totalMemory = Math.round(os.totalmem() / (1024 * 1024 * 1024))
    const freeMemory = Math.round(os.freemem() / (1024 * 1024 * 1024))
    const cpuCores = os.cpus().length
    
    console.log(`‚úÖ System Info:`)
    console.log(`   Total Memory: ${totalMemory} GB`)
    console.log(`   Free Memory: ${freeMemory} GB`)
    console.log(`   CPU Cores: ${cpuCores}`)
    
    // gpt-oss-20b„ÅÆÊé®Â•®Ë¶Å‰ª∂„ÉÅ„Çß„ÉÉ„ÇØ
    if (totalMemory < 16) {
      console.log('‚ö†Ô∏è  Warning: Less than 16GB RAM detected')
      console.log('   GptOss-20b requires at least 16GB RAM for optimal performance')
      console.log('   Consider using a smaller model or increasing RAM')
    }
    
    if (freeMemory < 8) {
      console.log('‚ö†Ô∏è  Warning: Less than 8GB free RAM detected')
      console.log('   Consider closing other applications for better performance')
    }
    
    if (cpuCores < 4) {
      console.log('‚ö†Ô∏è  Warning: Less than 4 CPU cores detected')
      console.log('   GptOss-20b may run slowly with limited CPU cores')
    }
    
  } catch (error) {
    console.log('‚ùå Error checking system requirements:', error)
  }
  
  // 5. gpt-oss„É¢„Éá„É´ÊÉÖÂ†±„ÅÆË°®Á§∫
  showGptOssModelInfo()
  
  // 6. Êé®Â•®Ë®≠ÂÆö
  console.log('\n‚öôÔ∏è  Recommended Configuration for GptOss:')
  console.log('   Model: gpt-oss-20b-mxfp4.gguf')
  console.log('   Context Size: 8192')
  console.log('   Threads: 4-8 (depending on CPU cores)')
  console.log('   GPU Layers: 0 (CPU only) or higher for GPU acceleration')
  console.log('   Temperature: 0.1 (for consistent extraction)')
  console.log('   Reasoning Level: medium (balanced performance)')
  
  // 7. „ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊâãÈ†Ü
  console.log('\nüì• Download Instructions:')
  console.log('1. Visit: https://huggingface.co/ggml-org/gpt-oss-20b-GGUF')
  console.log('2. Download: gpt-oss-20b-mxfp4.gguf (~15GB)')
  console.log('3. Place in: ./models/ directory')
  console.log('4. Run: npx tsx src/examples/gpt-oss-text-extraction-example.ts')
  
  // 8. ‰ΩøÁî®‰æã
  console.log('\nüí° Usage Example:')
  console.log('```typescript')
  console.log('import { createGptOssTextExtractionChain } from "../services/tts"')
  console.log('')
  console.log('const chain = createGptOssTextExtractionChain({')
  console.log('  modelPath: "./models/gpt-oss-20b-mxfp4.gguf",')
  console.log('  temperature: 0.1,')
  console.log('  maxTokens: 2048,')
  console.log('  contextSize: 8192,')
  console.log('  threads: 4,')
  console.log('  gpuLayers: 0,')
  console.log('  reasoningLevel: "medium"')
  console.log('})')
  console.log('')
  console.log('await chain.initialize()')
  console.log('const result = await chain.extractMainText(inputText)')
  console.log('```')
  
  console.log('\n‚úÖ GptOss environment check completed!')
  console.log('   GptOss text extraction should work in this environment')
}

// „É°„Ç§„É≥ÂÆüË°å
main().catch(console.error)
