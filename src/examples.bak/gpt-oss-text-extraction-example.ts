import { 
  GptOssTextExtractionChain, 
  createGptOssTextExtractionChain,
  GptOssTextExtractionAgent,
  createGptOssTextExtractionAgent
} from '../services/tts'

/**
 * gpt-ossãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ã®ä½¿ç”¨ä¾‹
 * 
 * ã“ã®ä¾‹ã§ã¯ã€OpenAIã®gpt-ossãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦æœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚
 * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒã§ã®ã¿å‹•ä½œã—ã¾ã™ã€‚
 * 
 * å‚è€ƒ: https://qiita.com/rairaii/items/e76beb749649dac26794
 */

// ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæä¾›ã—ãŸã‚‚ã®ï¼‰
const sampleText = `ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¨ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°æ™‚ä»£ï¼ˆViking Ageã€800å¹´ - 1050å¹´ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ç´„250å¹´é–“ã«è¥¿ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘æ²¿æµ·éƒ¨ã‚’ä¾µç•¥ã—ãŸã‚¹ã‚«ãƒ³ãƒ‡ã‚£ãƒŠãƒ´ã‚£ã‚¢ã€ãƒãƒ«ãƒˆæµ·æ²¿å²¸åœ°åŸŸã®æ­¦è£…é›†å›£ã‚’æŒ‡ã™è¨€è‘‰ã€‚
é€šä¿—çš„ã«ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯è§’ã®ã‚ã‚‹å…œã‚’è¢«ã£ãŸæµ·è³Šã‚„ç•¥å¥ªã‚’åƒãæˆ¦å£«ã§ã‚ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯å¾Œä¸–ã®æƒ³åƒã®å½±éŸ¿ãŒå¼·ãã€å®Ÿéš›ã«ã¯ç•¥å¥ªã‚’å°‚æ¥­ã¨ã—ã¦ã„ãŸã®ã§ã¯ãªãäº¤æ˜“æ°‘ã§ã‚‚ã‚ã‚Šã€æ•…åœ°ã«ãŠã„ã¦ã¯è¾²æ°‘ã§ã‚ã‚Šæ¼æ°‘ã§ã‚ã£ãŸã€‚
å„åœ°ã«é€²å‡ºã—ã€åŒ—ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®æ­´å²ã«å¤§ããªå½±éŸ¿ã‚’æ®‹ã—ãŸãŒã€æ¬¡ç¬¬ã«å„åœ°ã«åœŸç€ã—ã¦ã‚†ãã¨ã¨ã‚‚ã«æµ·ä¸Šã®æ°‘ã¨ã—ã¦ã®æ€§æ ¼ã‚’å¤±ã„ã€13ä¸–ç´€ã¾ã§ã«ã¯ã€æ®†ã©ã®ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯æ¶ˆæ»…ã—ãŸã€‚
ä¸Šè¨˜ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚`

/**
 * GptOssTextExtractionChainã®ä½¿ç”¨ä¾‹
 */
export async function demonstrateGptOssTextExtractionChain(modelPath: string) {
  console.log('=== GptOss TextExtractionChain Demo ===')
  
  try {
    // GptOssTextExtractionChainã‚’ä½œæˆ
    const extractionChain = createGptOssTextExtractionChain({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 8192, // gpt-oss-20bã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆ
      threads: 4,
      gpuLayers: 0,
      verbose: true,
      reasoningLevel: 'medium'
    })

    // åˆæœŸåŒ–
    await extractionChain.initialize()
    console.log('âœ… GptOss TextExtractionChain initialized')

    // æœ¬æ–‡æŠ½å‡ºã‚’å®Ÿè¡Œ
    console.log('\nğŸ“ Processing text...')
    const result = await extractionChain.extractMainText(sampleText)
    
    console.log('\nğŸ“Š Extraction Results:')
    console.log('Main Text:', result.mainText)
    console.log('Confidence:', result.confidence)
    console.log('Reasoning:', result.reasoning)
    console.log('Has Instructions:', result.hasInstructions)
    console.log('Instruction Type:', result.instructionType)

    // ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    const modelInfo = extractionChain.getModelInfo()
    console.log('\nğŸ”§ Model Info:')
    console.log('Model Path:', modelInfo.modelPath)
    console.log('Initialized:', modelInfo.isInitialized)
    console.log('Reasoning Level:', modelInfo.reasoningLevel)
    console.log('Model Type:', modelInfo.modelType)

    return result

  } catch (error) {
    console.error('âŒ GptOss TextExtractionChain demo failed:', error)
    throw error
  }
}

/**
 * æ¨è«–ãƒ¬ãƒ™ãƒ«ã‚’å¤‰æ›´ã—ãŸä¾‹
 */
export async function demonstrateReasoningLevels(modelPath: string) {
  console.log('\n=== GptOss Reasoning Levels Demo ===')
  
  try {
    const reasoningLevels: ('low' | 'medium' | 'high')[] = ['low', 'medium', 'high']
    const results = []

    for (const level of reasoningLevels) {
      console.log(`\nğŸ” Testing reasoning level: ${level}`)
      
      const extractionChain = createGptOssTextExtractionChain({
        modelPath: modelPath,
        temperature: 0.1,
        maxTokens: 2048,
        contextSize: 8192,
        threads: 4,
        gpuLayers: 0,
        verbose: false,
        reasoningLevel: level
      })

      await extractionChain.initialize()
      
      const startTime = Date.now()
      const result = await extractionChain.extractMainText(sampleText)
      const executionTime = Date.now() - startTime
      
      console.log(`âœ… ${level} level result:`)
      console.log(`  Confidence: ${result.confidence}`)
      console.log(`  Execution Time: ${executionTime}ms`)
      console.log(`  Reasoning: ${result.reasoning.substring(0, 100)}...`)
      
      results.push({ level, result, executionTime })
    }

    return results

  } catch (error) {
    console.error('âŒ Reasoning levels demo failed:', error)
    throw error
  }
}

/**
 * GptOssTextExtractionAgentã®ä½¿ç”¨ä¾‹
 */
export async function demonstrateGptOssTextExtractionAgent(modelPath: string) {
  console.log('\n=== GptOss TextExtractionAgent Demo ===')
  
  try {
    // GptOssTextExtractionAgentã‚’ä½œæˆ
    const extractionAgent = createGptOssTextExtractionAgent({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 8192,
      threads: 4,
      gpuLayers: 0,
      verbose: true,
      maxIterations: 3,
      reasoningLevel: 'medium'
    })

    // åˆæœŸåŒ–
    await extractionAgent.initialize()
    console.log('âœ… GptOss TextExtractionAgent initialized')

    // ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’å®Ÿè¡Œ
    console.log('\nğŸ“ Processing text with agent...')
    const result = await extractionAgent.processText(sampleText)
    
    console.log('\nğŸ“Š Agent Results:')
    console.log('Extracted Text:', result.extractedText)
    console.log('Confidence:', result.confidence)
    console.log('Reasoning:', result.reasoning)
    console.log('Execution Time:', result.executionTime, 'ms')
    
    if (result.ttsResult) {
      console.log('TTS Result:', result.ttsResult)
    }

    if (result.modelInfo) {
      console.log('\nğŸ”§ Model Info:')
      console.log('Model Path:', result.modelInfo.modelPath)
      console.log('Initialized:', result.modelInfo.isInitialized)
      console.log('Reasoning Level:', result.modelInfo.reasoningLevel)
      console.log('Model Type:', result.modelInfo.modelType)
    }

    return result

  } catch (error) {
    console.error('âŒ GptOss TextExtractionAgent demo failed:', error)
    throw error
  }
}

/**
 * ãƒãƒƒãƒå‡¦ç†ã®ä¾‹
 */
export async function demonstrateGptOssBatchProcessing(modelPath: string) {
  console.log('\n=== GptOss Batch Processing Demo ===')
  
  const texts = [
    'ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œã€‚ã“ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚',
    'ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚éŸ³å£°åŒ–ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚',
    'ã“ã‚Œã¯å˜ç´”ãªãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚',
    'è¤‡é›‘ãªèª¬æ˜æ–‡ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®éƒ¨åˆ†ã‚’éŸ³å£°ã§èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚'
  ]

  try {
    const extractionChain = createGptOssTextExtractionChain({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 8192,
      threads: 4,
      gpuLayers: 0,
      verbose: false,
      reasoningLevel: 'medium'
    })

    await extractionChain.initialize()
    console.log('âœ… GptOss batch processing initialized')

    const startTime = Date.now()
    const results = await extractionChain.extractBatch(texts)
    const totalTime = Date.now() - startTime
    
    console.log('\nğŸ“Š Batch Results:')
    results.forEach((result, index) => {
      console.log(`\n--- Text ${index + 1} ---`)
      console.log('Main Text:', result.mainText)
      console.log('Confidence:', result.confidence)
      console.log('Has Instructions:', result.hasInstructions)
    })
    
    console.log(`\nâ±ï¸  Total execution time: ${totalTime}ms`)
    console.log(`ğŸ“ˆ Average time per text: ${Math.round(totalTime / texts.length)}ms`)

    return results

  } catch (error) {
    console.error('âŒ GptOss batch processing demo failed:', error)
    throw error
  }
}

/**
 * çµ±åˆãƒ‡ãƒ¢
 */
export async function runGptOssTextExtractionDemo(modelPath: string) {
  console.log('ğŸš€ Starting GptOss Text Extraction Demo...\n')
  
  try {
    // 1. GptOssTextExtractionChainã®ãƒ‡ãƒ¢
    await demonstrateGptOssTextExtractionChain(modelPath)
    
    // 2. æ¨è«–ãƒ¬ãƒ™ãƒ«ã®æ¯”è¼ƒãƒ‡ãƒ¢
    await demonstrateReasoningLevels(modelPath)
    
    // 3. GptOssTextExtractionAgentã®ãƒ‡ãƒ¢
    await demonstrateGptOssTextExtractionAgent(modelPath)
    
    // 4. ãƒãƒƒãƒå‡¦ç†ã®ãƒ‡ãƒ¢
    await demonstrateGptOssBatchProcessing(modelPath)
    
    console.log('\nâœ… All GptOss demos completed successfully!')
    
  } catch (error) {
    console.error('âŒ GptOss demo failed:', error)
    throw error
  }
}

/**
 * ç’°å¢ƒãƒã‚§ãƒƒã‚¯
 */
export function checkGptOssEnvironment(): { isNode: boolean; isBrowser: boolean } {
  const isNode = typeof window === 'undefined'
  const isBrowser = typeof window !== 'undefined'
  
  console.log('ğŸ” GptOss Environment Check:')
  console.log('Node.js:', isNode)
  console.log('Browser:', isBrowser)
  
  if (!isNode) {
    console.warn('âš ï¸  GptOss functionality is only available in Node.js environment')
  }
  
  return { isNode, isBrowser }
}

/**
 * gpt-ossãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±ã‚’è¡¨ç¤º
 */
export function showGptOssModelInfo() {
  console.log('\nğŸ“‹ GptOss Model Information:')
  console.log('Model: gpt-oss-20b (OpenAI)')
  console.log('Parameters: ~20 billion')
  console.log('File Size: ~15GB (GGUF quantized)')
  console.log('Context Length: 8192 tokens')
  console.log('License: Apache 2.0')
  console.log('Knowledge Cutoff: 2024-06')
  console.log('Recommended RAM: 16GB+')
  console.log('Special Features:')
  console.log('  - OpenAIç¤¾å†…ãƒ¢ãƒ‡ãƒ«ã€Œo3-miniã€ã¨åŒç­‰ã®æ€§èƒ½')
  console.log('  - æ¨è«–ãƒ¬ãƒ™ãƒ«è¨­å®šï¼ˆlow/medium/highï¼‰')
  console.log('  - é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œ')
  console.log('  - æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã«å¯¾å¿œ')
}

// ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
/*
// ç’°å¢ƒãƒã‚§ãƒƒã‚¯
checkGptOssEnvironment()
showGptOssModelInfo()

// ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¦ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
const modelPath = './models/gpt-oss-20b-mxfp4.gguf'
runGptOssTextExtractionDemo(modelPath).catch(console.error)
*/
