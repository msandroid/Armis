import { 
  LlamaCppBackendService,
  createLlamaCppBackendService
} from '../services/tts'

/**
 * llama.cppãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆã®ä½¿ç”¨ä¾‹
 * 
 * ã“ã®ä¾‹ã§ã¯ã€Electronã‚„Node.jsã‚µãƒ¼ãƒãƒ¼ã§ã®ä½¿ç”¨ã‚’æƒ³å®šã—ãŸ
 * llama.cppæœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ã®çµ±åˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã™ã€‚
 */

// ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
const sampleTexts = [
  {
    name: 'ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã®èª¬æ˜æ–‡',
    text: `ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¨ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°æ™‚ä»£ï¼ˆViking Ageã€800å¹´ - 1050å¹´ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ç´„250å¹´é–“ã«è¥¿ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘æ²¿æµ·éƒ¨ã‚’ä¾µç•¥ã—ãŸã‚¹ã‚«ãƒ³ãƒ‡ã‚£ãƒŠãƒ´ã‚£ã‚¢ã€ãƒãƒ«ãƒˆæµ·æ²¿å²¸åœ°åŸŸã®æ­¦è£…é›†å›£ã‚’æŒ‡ã™è¨€è‘‰ã€‚é€šä¿—çš„ã«ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯è§’ã®ã‚ã‚‹å…œã‚’è¢«ã£ãŸæµ·è³Šã‚„ç•¥å¥ªã‚’åƒãæˆ¦å£«ã§ã‚ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯å¾Œä¸–ã®æƒ³åƒã®å½±éŸ¿ãŒå¼·ãã€å®Ÿéš›ã«ã¯ç•¥å¥ªã‚’å°‚æ¥­ã¨ã—ã¦ã„ãŸã®ã§ã¯ãªãäº¤æ˜“æ°‘ã§ã‚‚ã‚ã‚Šã€æ•…åœ°ã«ãŠã„ã¦ã¯è¾²æ°‘ã§ã‚ã‚Šæ¼æ°‘ã§ã‚ã£ãŸã€‚å„åœ°ã«é€²å‡ºã—ã€åŒ—ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®æ­´å²ã«å¤§ããªå½±éŸ¿ã‚’æ®‹ã—ãŸãŒã€æ¬¡ç¬¬ã«å„åœ°ã«åœŸç€ã—ã¦ã‚†ãã¨ã¨ã‚‚ã«æµ·ä¸Šã®æ°‘ã¨ã—ã¦ã®æ€§æ ¼ã‚’å¤±ã„ã€13ä¸–ç´€ã¾ã§ã«ã¯ã€æ®†ã©ã®ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯æ¶ˆæ»…ã—ãŸã€‚ä¸Šè¨˜ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚`
  },
  {
    name: 'ã‚·ãƒ³ãƒ—ãƒ«ãªTTSè¦æ±‚',
    text: 'ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œã€‚ã“ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚'
  },
  {
    name: 'æŒ‡ç¤ºæ–‡ãªã—ã®ãƒ†ã‚­ã‚¹ãƒˆ',
    text: 'ã“ã‚Œã¯å˜ç´”ãªãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ç‰¹ã«æŒ‡ç¤ºã¯ã‚ã‚Šã¾ã›ã‚“ã€‚'
  }
]

/**
 * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã®åŸºæœ¬ä½¿ç”¨ä¾‹
 */
export async function demonstrateBackendService(modelPath: string) {
  console.log('=== LlamaCpp Backend Service Demo ===')
  
  try {
    // ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œæˆ
    const backendService = createLlamaCppBackendService({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 4096,
      threads: 4,
      gpuLayers: 0,
      verbose: true,
      maxIterations: 3
    })

    // åˆæœŸåŒ–
    await backendService.initialize()
    console.log('âœ… Backend service initialized')

    // ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’ç¢ºèª
    const status = backendService.getStatus()
    console.log('\nğŸ“Š Service Status:')
    console.log('Initialized:', status.isInitialized)
    console.log('Model Path:', status.modelInfo?.modelPath)
    console.log('Model Initialized:', status.modelInfo?.isInitialized)
    console.log('Services:', status.services)

    // åŸºæœ¬çš„ãªæœ¬æ–‡æŠ½å‡º
    console.log('\nğŸ“ Basic Text Extraction:')
    const extractionResult = await backendService.extractText({
      text: sampleTexts[0].text,
      useAgent: false,
      batchMode: false
    })

    if (extractionResult.success) {
      console.log('âœ… Extraction successful:')
      console.log('Main Text:', extractionResult.data.mainText.substring(0, 100) + '...')
      console.log('Confidence:', extractionResult.data.confidence)
      console.log('Execution Time:', extractionResult.executionTime, 'ms')
    } else {
      console.error('âŒ Extraction failed:', extractionResult.error)
    }

    // Agentã‚’ä½¿ç”¨ã—ãŸå‡¦ç†
    console.log('\nğŸ¤– Agent-based Processing:')
    const agentResult = await backendService.extractText({
      text: sampleTexts[1].text,
      useAgent: true,
      batchMode: false
    })

    if (agentResult.success) {
      console.log('âœ… Agent processing successful:')
      console.log('Extracted Text:', agentResult.data.extractedText)
      console.log('Confidence:', agentResult.data.confidence)
      console.log('Execution Time:', agentResult.executionTime, 'ms')
    } else {
      console.error('âŒ Agent processing failed:', agentResult.error)
    }

    // TTSãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ†æ
    console.log('\nğŸµ TTS Request Analysis:')
    const ttsAnalysisResult = await backendService.analyzeTTSRequest(sampleTexts[0].text)

    if (ttsAnalysisResult.success) {
      console.log('âœ… TTS analysis successful:')
      console.log('Is TTS Request:', ttsAnalysisResult.data.isTTSRequest)
      console.log('TTS Text:', ttsAnalysisResult.data.ttsText?.substring(0, 100) + '...')
      console.log('Confidence:', ttsAnalysisResult.data.confidence)
      console.log('Execution Time:', ttsAnalysisResult.executionTime, 'ms')
    } else {
      console.error('âŒ TTS analysis failed:', ttsAnalysisResult.error)
    }

    // ãƒãƒƒãƒå‡¦ç†
    console.log('\nğŸ“¦ Batch Processing:')
    const batchTexts = sampleTexts.map(item => item.text)
    const batchResult = await backendService.extractBatch(batchTexts)

    if (batchResult.success) {
      console.log('âœ… Batch processing successful:')
      console.log('Results count:', batchResult.data.length)
      batchResult.data.forEach((result, index) => {
        console.log(`  ${index + 1}. ${sampleTexts[index].name}: ${result.confidence} confidence`)
      })
      console.log('Execution Time:', batchResult.executionTime, 'ms')
    } else {
      console.error('âŒ Batch processing failed:', batchResult.error)
    }

    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    await backendService.cleanup()
    console.log('\nâœ… Backend service cleaned up')

    return {
      extractionResult,
      agentResult,
      ttsAnalysisResult,
      batchResult
    }

  } catch (error) {
    console.error('âŒ Backend service demo failed:', error)
    throw error
  }
}

/**
 * Electronçµ±åˆã®ä¾‹
 */
export async function demonstrateElectronIntegration(modelPath: string) {
  console.log('\n=== Electron Integration Demo ===')
  
  try {
    const backendService = createLlamaCppBackendService({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 4096,
      threads: 4,
      gpuLayers: 0,
      verbose: false
    })

    await backendService.initialize()

    // Electron IPCãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ä¾‹
    const ipcHandlers = {
      // æœ¬æ–‡æŠ½å‡ºã®IPCãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      'extract-text': async (event: any, request: any) => {
        try {
          const result = await backendService.extractText(request)
          return result
        } catch (error) {
          return {
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            executionTime: 0
          }
        }
      },

      // TTSåˆ†æã®IPCãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      'analyze-tts': async (event: any, text: string) => {
        try {
          const result = await backendService.analyzeTTSRequest(text)
          return result
        } catch (error) {
          return {
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            executionTime: 0
          }
        }
      },

      // ãƒãƒƒãƒå‡¦ç†ã®IPCãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      'extract-batch': async (event: any, texts: string[]) => {
        try {
          const result = await backendService.extractBatch(texts)
          return result
        } catch (error) {
          return {
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            executionTime: 0
          }
        }
      },

      // ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹å–å¾—ã®IPCãƒãƒ³ãƒ‰ãƒ©ãƒ¼
      'get-status': () => {
        return backendService.getStatus()
      }
    }

    console.log('âœ… Electron IPC handlers configured')
    console.log('Available handlers:', Object.keys(ipcHandlers))

    // ä½¿ç”¨ä¾‹
    const testResult = await ipcHandlers['extract-text'](null, {
      text: sampleTexts[0].text,
      useAgent: false,
      batchMode: false
    })

    console.log('Test IPC call result:', testResult.success ? 'Success' : 'Failed')

    await backendService.cleanup()
    console.log('âœ… Electron integration demo completed')

    return ipcHandlers

  } catch (error) {
    console.error('âŒ Electron integration demo failed:', error)
    throw error
  }
}

/**
 * Node.jsã‚µãƒ¼ãƒãƒ¼çµ±åˆã®ä¾‹
 */
export async function demonstrateServerIntegration(modelPath: string) {
  console.log('\n=== Node.js Server Integration Demo ===')
  
  try {
    const backendService = createLlamaCppBackendService({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 4096,
      threads: 4,
      gpuLayers: 0,
      verbose: false
    })

    await backendService.initialize()

    // Express.jsãƒ«ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ä¾‹
    const expressRoutes = {
      // æœ¬æ–‡æŠ½å‡ºã®POSTã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
      'POST /api/extract-text': async (req: any, res: any) => {
        try {
          const { text, useAgent, batchMode } = req.body
          const result = await backendService.extractText({ text, useAgent, batchMode })
          res.json(result)
        } catch (error) {
          res.status(500).json({
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            executionTime: 0
          })
        }
      },

      // TTSåˆ†æã®POSTã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
      'POST /api/analyze-tts': async (req: any, res: any) => {
        try {
          const { text } = req.body
          const result = await backendService.analyzeTTSRequest(text)
          res.json(result)
        } catch (error) {
          res.status(500).json({
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            executionTime: 0
          })
        }
      },

      // ãƒãƒƒãƒå‡¦ç†ã®POSTã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
      'POST /api/extract-batch': async (req: any, res: any) => {
        try {
          const { texts } = req.body
          const result = await backendService.extractBatch(texts)
          res.json(result)
        } catch (error) {
          res.status(500).json({
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            executionTime: 0
          })
        }
      },

      // ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹å–å¾—ã®GETã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
      'GET /api/status': (req: any, res: any) => {
        res.json(backendService.getStatus())
      }
    }

    console.log('âœ… Express.js routes configured')
    console.log('Available routes:', Object.keys(expressRoutes))

    await backendService.cleanup()
    console.log('âœ… Server integration demo completed')

    return expressRoutes

  } catch (error) {
    console.error('âŒ Server integration demo failed:', error)
    throw error
  }
}

/**
 * çµ±åˆãƒ‡ãƒ¢
 */
export async function runLlamaCppBackendDemo(modelPath: string) {
  console.log('ğŸš€ Starting LlamaCpp Backend Integration Demo...\n')
  
  try {
    // 1. åŸºæœ¬çš„ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãƒ‡ãƒ¢
    await demonstrateBackendService(modelPath)
    
    // 2. Electronçµ±åˆãƒ‡ãƒ¢
    await demonstrateElectronIntegration(modelPath)
    
    // 3. Node.jsã‚µãƒ¼ãƒãƒ¼çµ±åˆãƒ‡ãƒ¢
    await demonstrateServerIntegration(modelPath)
    
    console.log('\nâœ… All backend integration demos completed successfully!')
    
  } catch (error) {
    console.error('âŒ Backend integration demo failed:', error)
    throw error
  }
}

// ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
/*
// ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¦ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
const modelPath = './models/llama-2-7b-chat.gguf'
runLlamaCppBackendDemo(modelPath).catch(console.error)
*/
