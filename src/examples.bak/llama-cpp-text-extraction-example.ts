import { 
  LlamaCppTextExtractionChain, 
  createLlamaCppTextExtractionChain,
  LlamaCppTextExtractionAgent,
  createLlamaCppTextExtractionAgent
} from '../services/tts'

/**
 * llama.cppã‚’ä½¿ç”¨ã—ãŸæœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ã®ä½¿ç”¨ä¾‹
 * 
 * ã“ã®ä¾‹ã§ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ä½¿ç”¨ã—ã¦æœ¬æ–‡æŠ½å‡ºæ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚
 * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç’°å¢ƒã§ã®ã¿å‹•ä½œã—ã¾ã™ã€‚
 */

// ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæä¾›ã—ãŸã‚‚ã®ï¼‰
const sampleText = `ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¨ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°æ™‚ä»£ï¼ˆViking Ageã€800å¹´ - 1050å¹´ï¼‰ã¨å‘¼ã°ã‚Œã‚‹ç´„250å¹´é–“ã«è¥¿ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘æ²¿æµ·éƒ¨ã‚’ä¾µç•¥ã—ãŸã‚¹ã‚«ãƒ³ãƒ‡ã‚£ãƒŠãƒ´ã‚£ã‚¢ã€ãƒãƒ«ãƒˆæµ·æ²¿å²¸åœ°åŸŸã®æ­¦è£…é›†å›£ã‚’æŒ‡ã™è¨€è‘‰ã€‚
é€šä¿—çš„ã«ã¯ã€ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯è§’ã®ã‚ã‚‹å…œã‚’è¢«ã£ãŸæµ·è³Šã‚„ç•¥å¥ªã‚’åƒãæˆ¦å£«ã§ã‚ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯å¾Œä¸–ã®æƒ³åƒã®å½±éŸ¿ãŒå¼·ãã€å®Ÿéš›ã«ã¯ç•¥å¥ªã‚’å°‚æ¥­ã¨ã—ã¦ã„ãŸã®ã§ã¯ãªãäº¤æ˜“æ°‘ã§ã‚‚ã‚ã‚Šã€æ•…åœ°ã«ãŠã„ã¦ã¯è¾²æ°‘ã§ã‚ã‚Šæ¼æ°‘ã§ã‚ã£ãŸã€‚
å„åœ°ã«é€²å‡ºã—ã€åŒ—ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã®æ­´å²ã«å¤§ããªå½±éŸ¿ã‚’æ®‹ã—ãŸãŒã€æ¬¡ç¬¬ã«å„åœ°ã«åœŸç€ã—ã¦ã‚†ãã¨ã¨ã‚‚ã«æµ·ä¸Šã®æ°‘ã¨ã—ã¦ã®æ€§æ ¼ã‚’å¤±ã„ã€13ä¸–ç´€ã¾ã§ã«ã¯ã€æ®†ã©ã®ãƒ´ã‚¡ã‚¤ã‚­ãƒ³ã‚°ã¯æ¶ˆæ»…ã—ãŸã€‚
ä¸Šè¨˜ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚`

/**
 * LlamaCppTextExtractionChainã®ä½¿ç”¨ä¾‹
 */
export async function demonstrateLlamaCppTextExtractionChain(modelPath: string) {
  console.log('=== LlamaCpp TextExtractionChain Demo ===')
  
  try {
    // LlamaCppTextExtractionChainã‚’ä½œæˆ
    const extractionChain = createLlamaCppTextExtractionChain({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 4096,
      threads: 4,
      gpuLayers: 0,
      verbose: true
    })

    // åˆæœŸåŒ–
    await extractionChain.initialize()
    console.log('âœ… LlamaCpp TextExtractionChain initialized')

    // æœ¬æ–‡æŠ½å‡ºã‚’å®Ÿè¡Œ
    console.log('\nğŸ“ Processing text...')
    const result = await extractionChain.extractMainText(sampleText)
    
    console.log('\nğŸ“Š Extraction Results:')
    console.log('Main Text:', result.mainText)
    console.log('Confidence:', result.confidence)
    console.log('Reasoning:', result.reasoning)
    console.log('Has Instructions:', result.hasInstructions)
    console.log('Instruction Type:', result.instructionType)

    // ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    const modelInfo = extractionChain.getModelInfo()
    console.log('\nğŸ”§ Model Info:')
    console.log('Model Path:', modelInfo.modelPath)
    console.log('Initialized:', modelInfo.isInitialized)

    return result

  } catch (error) {
    console.error('âŒ LlamaCpp TextExtractionChain demo failed:', error)
    throw error
  }
}

/**
 * LlamaCppTextExtractionAgentã®ä½¿ç”¨ä¾‹
 */
export async function demonstrateLlamaCppTextExtractionAgent(modelPath: string) {
  console.log('\n=== LlamaCpp TextExtractionAgent Demo ===')
  
  try {
    // LlamaCppTextExtractionAgentã‚’ä½œæˆ
    const extractionAgent = createLlamaCppTextExtractionAgent({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 4096,
      threads: 4,
      gpuLayers: 0,
      verbose: true,
      maxIterations: 3
    })

    // åˆæœŸåŒ–
    await extractionAgent.initialize()
    console.log('âœ… LlamaCpp TextExtractionAgent initialized')

    // ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’å®Ÿè¡Œ
    console.log('\nğŸ“ Processing text with agent...')
    const result = await extractionAgent.processText(sampleText)
    
    console.log('\nğŸ“Š Agent Results:')
    console.log('Extracted Text:', result.extractedText)
    console.log('Confidence:', result.confidence)
    console.log('Reasoning:', result.reasoning)
    console.log('Execution Time:', result.executionTime, 'ms')
    
    if (result.ttsResult) {
      console.log('TTS Result:', result.ttsResult)
    }

    if (result.modelInfo) {
      console.log('\nğŸ”§ Model Info:')
      console.log('Model Path:', result.modelInfo.modelPath)
      console.log('Initialized:', result.modelInfo.isInitialized)
    }

    return result

  } catch (error) {
    console.error('âŒ LlamaCpp TextExtractionAgent demo failed:', error)
    throw error
  }
}

/**
 * ãƒãƒƒãƒå‡¦ç†ã®ä¾‹
 */
export async function demonstrateLlamaCppBatchProcessing(modelPath: string) {
  console.log('\n=== LlamaCpp Batch Processing Demo ===')
  
  const texts = [
    'ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œã€‚ã“ã®æ–‡ç« ã‚’éŸ³å£°ã«ã—ã¦ãã ã•ã„ã€‚',
    'ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚éŸ³å£°åŒ–ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚',
    'ã“ã‚Œã¯å˜ç´”ãªãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚',
    'è¤‡é›‘ãªèª¬æ˜æ–‡ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®éƒ¨åˆ†ã‚’éŸ³å£°ã§èª­ã¿ä¸Šã’ã¦ãã ã•ã„ã€‚'
  ]

  try {
    const extractionChain = createLlamaCppTextExtractionChain({
      modelPath: modelPath,
      temperature: 0.1,
      maxTokens: 2048,
      contextSize: 4096,
      threads: 4,
      gpuLayers: 0,
      verbose: false
    })

    await extractionChain.initialize()
    console.log('âœ… LlamaCpp batch processing initialized')

    const results = await extractionChain.extractBatch(texts)
    
    console.log('\nğŸ“Š Batch Results:')
    results.forEach((result, index) => {
      console.log(`\n--- Text ${index + 1} ---`)
      console.log('Main Text:', result.mainText)
      console.log('Confidence:', result.confidence)
      console.log('Has Instructions:', result.hasInstructions)
    })

    return results

  } catch (error) {
    console.error('âŒ LlamaCpp batch processing demo failed:', error)
    throw error
  }
}

/**
 * çµ±åˆãƒ‡ãƒ¢
 */
export async function runLlamaCppTextExtractionDemo(modelPath: string) {
  console.log('ğŸš€ Starting LlamaCpp Text Extraction Demo...\n')
  
  try {
    // 1. LlamaCppTextExtractionChainã®ãƒ‡ãƒ¢
    await demonstrateLlamaCppTextExtractionChain(modelPath)
    
    // 2. LlamaCppTextExtractionAgentã®ãƒ‡ãƒ¢
    await demonstrateLlamaCppTextExtractionAgent(modelPath)
    
    // 3. ãƒãƒƒãƒå‡¦ç†ã®ãƒ‡ãƒ¢
    await demonstrateLlamaCppBatchProcessing(modelPath)
    
    console.log('\nâœ… All LlamaCpp demos completed successfully!')
    
  } catch (error) {
    console.error('âŒ LlamaCpp demo failed:', error)
    throw error
  }
}

/**
 * ç’°å¢ƒãƒã‚§ãƒƒã‚¯
 */
export function checkEnvironment(): { isNode: boolean; isBrowser: boolean } {
  const isNode = typeof window === 'undefined'
  const isBrowser = typeof window !== 'undefined'
  
  console.log('ğŸ” Environment Check:')
  console.log('Node.js:', isNode)
  console.log('Browser:', isBrowser)
  
  if (!isNode) {
    console.warn('âš ï¸  LlamaCpp functionality is only available in Node.js environment')
  }
  
  return { isNode, isBrowser }
}

// ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
/*
// ç’°å¢ƒãƒã‚§ãƒƒã‚¯
checkEnvironment()

// ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¦ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
const modelPath = './models/llama-2-7b-chat.gguf'
runLlamaCppTextExtractionDemo(modelPath).catch(console.error)
*/
