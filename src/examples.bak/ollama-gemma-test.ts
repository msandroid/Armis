import { OllamaService } from '@/services/llm/ollama-service'

async function testOllamaGemma() {
  console.log('ğŸš€ Testing Gemma3:1b with Ollama...\n')

  try {
    // OllamaServiceã®åˆæœŸåŒ–ï¼ˆgemma3:1bãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
    const ollamaService = new OllamaService({
      defaultModel: 'gemma3:1b',
      baseUrl: 'http://localhost:11434',
      timeout: 60000 // 1åˆ†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    })

    console.log('ğŸ“¥ Initializing Ollama Service...')
    await ollamaService.initialize()
    console.log('âœ… Ollama Service initialized successfully\n')

    // åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
    console.log('ğŸ§ª Testing basic text generation...')
    const response = await ollamaService.generate("ã“ã‚“ã«ã¡ã¯ï¼")
    console.log('ğŸ“ Response:', response.response)
    console.log('âœ… Basic text generation test passed\n')

    // ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã®ãƒ†ã‚¹ãƒˆ
    console.log('ğŸ’¬ Testing chat format...')
    const chatResponse = await ollamaService.generate("1+1ã¯ä½•ã§ã™ã‹ï¼Ÿ", {
      system: "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
    })
    console.log('ğŸ’­ Chat Response:', chatResponse.response)
    console.log('âœ… Chat format test passed\n')

    // æ¨è«–èƒ½åŠ›ã®ãƒ†ã‚¹ãƒˆ
    console.log('ğŸ§  Testing reasoning capabilities...')
    const reasoningPrompt = `
ä»¥ä¸‹ã®å•é¡Œã‚’è§£æ±ºã—ã¦ãã ã•ã„ï¼š

å¤ªéƒã¯5å€‹ã®ã‚Šã‚“ã”ã‚’æŒã£ã¦ã„ã¾ã™ã€‚èŠ±å­ã¯3å€‹ã®ã‚Šã‚“ã”ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
äºŒäººãŒã‚Šã‚“ã”ã‚’åˆã‚ã›ã‚‹ã¨ã€å…¨éƒ¨ã§ä½•å€‹ã«ãªã‚Šã¾ã™ã‹ï¼Ÿ
`
    
    const reasoningResponse = await ollamaService.generate(reasoningPrompt)
    console.log('ğŸ¤” Reasoning Response:', reasoningResponse.response)
    console.log('âœ… Reasoning test passed\n')

    console.log('ğŸ‰ All tests passed! Gemma3:1b with Ollama is working correctly.')

  } catch (error) {
    console.error('âŒ Test failed:', error)
    console.error('Error details:', error instanceof Error ? error.message : error)
  }
}

// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
testOllamaGemma().catch(console.error)
