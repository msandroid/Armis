import { LlamaService } from '@/services/llm/llama-service'
import { Phase1IntegrationManager, IntegrationConfig } from '@/services/integration/phase1-integration-manager'

/**
 * Phase 1çµ±åˆã®ä½¿ç”¨ä¾‹
 * 
 * ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€LangChainJSã€Haystackã€æ‹¡å¼µãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±åˆæ©Ÿèƒ½ã‚’
 * å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
 */

async function phase1IntegrationExample() {
  console.log('=== Phase 1 Integration Example ===')

  // 1. è¨­å®šã®æº–å‚™
  const config: IntegrationConfig = {
    enableLangChain: true,
    enableHaystack: true,
    enableEnhancedVectorDB: true,
    confidenceThreshold: 0.7,
    enableFallback: true
  }

  // 2. LLMã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ï¼ˆå®Ÿéš›ã®ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
  const llamaService = new LlamaService({
    modelPath: './models/llama-2-7b-chat.gguf',
    contextSize: 4096,
    temperature: 0.7
  })

  // 3. çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
  const integrationManager = new Phase1IntegrationManager(llamaService, config)
  
  try {
    await integrationManager.initialize()
    console.log('âœ… Integration manager initialized successfully')

    // 4. çµ±åˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ

    // 4.1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- Document Analysis Test ---')
    const sampleDocument = `
    Armisã¯ã€é«˜åº¦ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚
    ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€LangChainJSã€Haystackã€æ‹¡å¼µãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’çµ±åˆã—ã€
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ§˜ã€…ãªãƒ‹ãƒ¼ã‚ºã«å¯¾å¿œã™ã‚‹åŒ…æ‹¬çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚
    
    ä¸»ãªæ©Ÿèƒ½:
    - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç†è§£ã¨åˆ†æ
    - é«˜åº¦ãªæ¤œç´¢æ©Ÿèƒ½
    - è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ 
    - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†
    
    ã“ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯ã€ä¼æ¥­ã®æ¥­å‹™åŠ¹ç‡åŒ–ã¨æ„æ€æ±ºå®šæ”¯æ´ã«è²¢çŒ®ã—ã¾ã™ã€‚
    `

    const analysisResult = await integrationManager.analyzeDocument(sampleDocument, {
      source: 'example',
      category: 'platform_description'
    })

    console.log('ğŸ“„ Document Analysis Result:')
    console.log(`- Summary: ${analysisResult.summary}`)
    console.log(`- Language: ${analysisResult.language}`)
    console.log(`- Sentiment: ${analysisResult.sentiment.label} (${analysisResult.sentiment.score.toFixed(2)})`)
    console.log(`- Keywords: ${analysisResult.keywords.join(', ')}`)
    console.log(`- Topics: ${analysisResult.topics.join(', ')}`)
    console.log(`- Entities: ${analysisResult.entities.map(e => `${e.text} (${e.type})`).join(', ')}`)

    // 4.2 æ‹¡å¼µãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ 
    console.log('\n--- Enhanced Vector Database Test ---')
    const enhancedDoc = {
      id: 'doc_001',
      content: sampleDocument,
      metadata: {
        title: 'Armis Platform Description',
        author: 'AI Assistant',
        category: 'platform',
        tags: ['AI', 'platform', 'integration']
      }
    }

    await integrationManager.addEnhancedDocument(enhancedDoc)
    console.log('âœ… Document added to enhanced vector database')

    // 4.3 æ‹¡å¼µæ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- Enhanced Search Test ---')
    const searchQuery = {
      text: 'AI platform integration',
      filters: {
        topics: ['AI', 'platform'],
        language: 'ja'
      },
      weights: {
        semantic: 0.4,
        keyword: 0.3,
        topic: 0.2,
        entity: 0.1
      }
    }

    const searchResults = await integrationManager.enhancedSearch(searchQuery)
    console.log(`ğŸ” Enhanced Search Results: ${searchResults.length} documents found`)
    searchResults.forEach((result, index) => {
      console.log(`${index + 1}. Score: ${result.semanticScore?.toFixed(2) || 'N/A'}`)
      console.log(`   Content: ${result.content.substring(0, 100)}...`)
    })

    // 4.4 è³ªå•å¿œç­”ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- Question Answering Test ---')
    const question = 'Armisãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ä¸»ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ'
    const qaResult = await integrationManager.answerQuestion(question)
    
    console.log(`â“ Question: ${question}`)
    console.log(`ğŸ’¡ Answer: ${qaResult.answer}`)
    console.log(`ğŸ“Š Confidence: ${(qaResult.confidence * 100).toFixed(1)}%`)

    // 4.5 LangChainå¼·åŒ–ãƒ«ãƒ¼ã‚¿ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- LangChain Enhanced Router Test ---')
    const routerInput = 'ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„'
    const routerResult = await integrationManager.routeAndExecute(routerInput, {
      documentId: 'doc_001',
      userContext: 'analysis_request'
    })

    console.log(`ğŸ¤– Router Response:`)
    console.log(`- Content: ${routerResult.content}`)
    console.log(`- Confidence: ${routerResult.confidence}`)
    console.log(`- Execution Time: ${routerResult.executionTime}ms`)
    console.log(`- Metadata: ${JSON.stringify(routerResult.metadata, null, 2)}`)

    // 4.6 çµ±è¨ˆæƒ…å ±ã®å–å¾—
    console.log('\n--- Integration Status ---')
    const status = await integrationManager.getStatus()
    console.log('ğŸ“Š Integration Status:')
    console.log(`- LangChain: ${status.langchain.enabled ? 'âœ…' : 'âŒ'} (${status.langchain.agentsCount} agents)`)
    console.log(`- Haystack: ${status.haystack.enabled ? 'âœ…' : 'âŒ'} (${status.haystack.documentsCount} documents)`)
    console.log(`- Enhanced Vector DB: ${status.enhancedVectorDB.enabled ? 'âœ…' : 'âŒ'} (${status.enhancedVectorDB.documentsCount} documents)`)

    // 5. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    console.log('\n--- Cleanup ---')
    await integrationManager.cleanup()
    console.log('âœ… Cleanup completed')

  } catch (error) {
    console.error('âŒ Error in Phase 1 integration example:', error)
  }
}

/**
 * å€‹åˆ¥æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆé–¢æ•°
 */
async function testIndividualFeatures() {
  console.log('\n=== Individual Features Test ===')

  const config: IntegrationConfig = {
    enableLangChain: true,
    enableHaystack: true,
    enableEnhancedVectorDB: true,
    confidenceThreshold: 0.7,
    enableFallback: true
  }

  const llamaService = new LlamaService({
    modelPath: './models/llama-2-7b-chat.gguf',
    contextSize: 4096,
    temperature: 0.7
  })

  const integrationManager = new Phase1IntegrationManager(llamaService, config)

  try {
    await integrationManager.initialize()

    // Haystackã‚µãƒ¼ãƒ“ã‚¹ã®å€‹åˆ¥ãƒ†ã‚¹ãƒˆ
    const haystackService = integrationManager.getHaystackService()
    if (haystackService) {
      console.log('\n--- Haystack Service Test ---')
      
      // è¤‡æ•°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
      const documents = [
        'AIæŠ€è¡“ã¯æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã¾ã™ã€‚',
        'æ©Ÿæ¢°å­¦ç¿’ã¯ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®é‡è¦ãªåˆ†é‡ã§ã™ã€‚',
        'è‡ªç„¶è¨€èªå‡¦ç†ã¯AIã®ä¸»è¦ãªå¿œç”¨åˆ†é‡ã§ã™ã€‚'
      ]

      for (const doc of documents) {
        await haystackService.addDocument(doc, { category: 'ai_technology' })
      }

      // æ¤œç´¢ãƒ†ã‚¹ãƒˆ
      const searchResults = await haystackService.searchDocuments('AI æŠ€è¡“', 5)
      console.log(`Found ${searchResults.length} documents related to AI technology`)

      // è³ªå•å¿œç­”ãƒ†ã‚¹ãƒˆ
      const qaResult = await haystackService.answerQuestion('AIæŠ€è¡“ã®ç¾çŠ¶ã¯ï¼Ÿ')
      console.log(`QA Result: ${qaResult.answer}`)
    }

    // æ‹¡å¼µãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å€‹åˆ¥ãƒ†ã‚¹ãƒˆ
    const enhancedVectorDB = integrationManager.getEnhancedVectorDB()
    if (enhancedVectorDB) {
      console.log('\n--- Enhanced Vector Database Test ---')
      
      // çµ±è¨ˆæƒ…å ±ã®å–å¾—
      const stats = await enhancedVectorDB.getDocumentStats()
      console.log(`Database Stats: ${JSON.stringify(stats, null, 2)}`)

      // äººæ°—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å–å¾—
      const popularDocs = await enhancedVectorDB.getPopularDocuments(3)
      console.log(`Popular Documents: ${popularDocs.length} found`)
    }

    await integrationManager.cleanup()

  } catch (error) {
    console.error('âŒ Error in individual features test:', error)
  }
}

/**
 * ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ
 */
async function testErrorHandling() {
  console.log('\n=== Error Handling Test ===')

  const config: IntegrationConfig = {
    enableLangChain: false, // ç„¡åŠ¹åŒ–ã—ã¦ãƒ†ã‚¹ãƒˆ
    enableHaystack: true,
    enableEnhancedVectorDB: true,
    confidenceThreshold: 0.7,
    enableFallback: true
  }

  const llamaService = new LlamaService({
    modelPath: './models/llama-2-7b-chat.gguf',
    contextSize: 4096,
    temperature: 0.7
  })

  const integrationManager = new Phase1IntegrationManager(llamaService, config)

  try {
    await integrationManager.initialize()

    // LangChainãƒ«ãƒ¼ã‚¿ãƒ¼ãŒç„¡åŠ¹ãªå ´åˆã®ãƒ†ã‚¹ãƒˆ
    try {
      await integrationManager.routeAndExecute('test input')
    } catch (error) {
      console.log('âœ… Expected error caught: LangChain router not available')
    }

    // æ­£å¸¸ãªæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
    const analysisResult = await integrationManager.analyzeDocument('Test document content')
    console.log('âœ… Document analysis works even with LangChain disabled')

    await integrationManager.cleanup()

  } catch (error) {
    console.error('âŒ Error in error handling test:', error)
  }
}

// ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
export async function runPhase1IntegrationExamples() {
  console.log('ğŸš€ Starting Phase 1 Integration Examples...\n')

  try {
    // åŸºæœ¬çš„ãªçµ±åˆãƒ†ã‚¹ãƒˆ
    await phase1IntegrationExample()

    // å€‹åˆ¥æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
    await testIndividualFeatures()

    // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ
    await testErrorHandling()

    console.log('\nğŸ‰ All Phase 1 integration examples completed successfully!')

  } catch (error) {
    console.error('ğŸ’¥ Fatal error in Phase 1 integration examples:', error)
  }
}

// ç›´æ¥å®Ÿè¡Œæ™‚ã®å‡¦ç†
if (require.main === module) {
  runPhase1IntegrationExamples().catch(console.error)
}
