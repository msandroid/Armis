import { Qwen2_5OmniService } from '@/services/llm/qwen2.5-omni-service'

/**
 * Qwen2.5-Omni 3B „É¢„Éá„É´„ÅÆ‰ΩøÁî®‰æã
 * 
 * „Åì„ÅÆ„Éï„Ç°„Ç§„É´„ÅØ„ÄÅQwen2.5-Omni-3B-GGUF„É¢„Éá„É´„ÅÆÂü∫Êú¨ÁöÑ„Å™‰ΩøÁî®ÊñπÊ≥ï„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ
 * „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´Ê©üËÉΩÔºà„ÉÜ„Ç≠„Çπ„Éà„ÄÅÁîªÂÉè„ÄÅÈü≥Â£∞„ÄÅÂãïÁîªÔºâ„Å®Èü≥Â£∞ÁîüÊàêÊ©üËÉΩ„ÇíÂê´„Åø„Åæ„Åô„ÄÇ
 * 
 * ‰ΩøÁî®ÊñπÊ≥ï:
 * 1. „É¢„Éá„É´„Éï„Ç°„Ç§„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ: https://huggingface.co/unsloth/Qwen2.5-Omni-3B-GGUF
 * 2. „Åì„ÅÆ„Éï„Ç°„Ç§„É´„ÇíÂÆüË°å: npx tsx src/examples/qwen2.5-omni-3b-usage.ts
 */

async function main() {
  console.log('üöÄ Qwen2.5-Omni 3B ‰ΩøÁî®‰æã„ÇíÈñãÂßã„Åó„Åæ„Åô...')

  // Qwen2.5-Omni 3B„Çµ„Éº„Éì„Çπ„ÅÆÂàùÊúüÂåñ
  const qwenOmniService = new Qwen2_5OmniService({
    modelPath: './models/unsloth/Qwen2.5-Omni-3B-GGUF/Qwen2.5-Omni-3B-Q4_K_M.gguf',
    temperature: 0.7,
    maxTokens: 2048,
    topP: 0.9,
    topK: 40,
    contextSize: 32768,
    threads: 4,
    gpuLayers: 0,
    verbose: false,
    enableAudioOutput: false, // Èü≥Â£∞Âá∫Âäõ„ÅØÁèæÂú®Êú™ÂÆüË£Ö
    speaker: 'Chelsie',
    useAudioInVideo: true
  })

  try {
    // „Çµ„Éº„Éì„Çπ„ÅÆÂàùÊúüÂåñ
    console.log('üîß Qwen2.5-Omni 3B „Çµ„Éº„Éì„Çπ„ÇíÂàùÊúüÂåñ‰∏≠...')
    await qwenOmniService.initialize()
    console.log('‚úÖ ÂàùÊúüÂåñÂÆå‰∫Ü')

    // Âü∫Êú¨ÁöÑ„Å™„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê
    console.log('\nüìù Âü∫Êú¨ÁöÑ„Å™„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê„ÉÜ„Çπ„Éà...')
    const textResponse = await qwenOmniService.generateResponse(
      "Hello! I am Qwen2.5-Omni 3B. Can you tell me about your capabilities?"
    )
    console.log('üìÑ ÂøúÁ≠î:', textResponse.text)
    console.log('‚è±Ô∏è Âá¶ÁêÜÊôÇÈñì:', textResponse.duration, 'ms')
    console.log('üî¢ „Éà„Éº„ÇØ„É≥Êï∞:', textResponse.tokens)

    // „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´‰ºöË©±„ÅÆ‰æã
    console.log('\nüé≠ „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´‰ºöË©±„ÉÜ„Çπ„Éà...')
    const multimodalConversation = [
      {
        role: 'system' as const,
        content: [
          {
            type: 'text' as const,
            text: 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'
          }
        ]
      },
      {
        role: 'user' as const,
        content: [
          {
            type: 'text' as const,
            text: 'What are your main features as a multimodal AI model?'
          }
        ]
      }
    ]

    const multimodalResponse = await qwenOmniService.generateMultimodalResponse(
      multimodalConversation,
      { returnAudio: false, speaker: 'Ethan' }
    )
    console.log('üé≠ „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂøúÁ≠î:', multimodalResponse.text)
    console.log('‚è±Ô∏è Âá¶ÁêÜÊôÇÈñì:', multimodalResponse.duration, 'ms')

    // Èü≥Â£∞ÁîüÊàê„ÅÆ„ÉÜ„Çπ„ÉàÔºàÂ∞ÜÊù•ÂÆüË£Ö‰∫àÂÆöÔºâ
    console.log('\nüé§ Èü≥Â£∞ÁîüÊàê„ÉÜ„Çπ„ÉàÔºàÂ∞ÜÊù•ÂÆüË£Ö‰∫àÂÆöÔºâ...')
    const audioResponse = await qwenOmniService.generateAudio(
      "Hello! This is a test of audio generation with Qwen2.5-Omni 3B.",
      'Chelsie'
    )
    if (audioResponse) {
      console.log('üéµ Èü≥Â£∞ÁîüÊàêÊàêÂäü:', audioResponse.byteLength, 'bytes')
    } else {
      console.log('‚ö†Ô∏è Èü≥Â£∞ÁîüÊàê„ÅØÁèæÂú®Êú™ÂÆüË£Ö„Åß„Åô')
    }

    // Ë®≠ÂÆö„ÅÆÁ¢∫Ë™ç
    console.log('\n‚öôÔ∏è ÁèæÂú®„ÅÆË®≠ÂÆö:')
    const config = qwenOmniService.getConfig()
    console.log('üìÅ „É¢„Éá„É´„Éë„Çπ:', config.modelPath)
    console.log('üå°Ô∏è Ê∏©Â∫¶:', config.temperature)
    console.log('üî¢ ÊúÄÂ§ß„Éà„Éº„ÇØ„É≥Êï∞:', config.maxTokens)
    console.log('üé§ Èü≥Â£∞Âá∫Âäõ:', config.enableAudioOutput)
    console.log('üó£Ô∏è „Çπ„Éî„Éº„Ç´„Éº:', config.speaker)

    // Ê∫ñÂÇôÁä∂ÊÖã„ÅÆÁ¢∫Ë™ç
    console.log('\nüîç „Çµ„Éº„Éì„ÇπÊ∫ñÂÇôÁä∂ÊÖã:', qwenOmniService.isReady())

  } catch (error) {
    console.error('‚ùå „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü:', error)
  }
}

// Áí∞Â¢É„ÉÅ„Çß„ÉÉ„ÇØÈñ¢Êï∞
async function checkEnvironment() {
  console.log('üîç Áí∞Â¢É„ÉÅ„Çß„ÉÉ„ÇØ‰∏≠...')
  
  // Node.jsÁí∞Â¢É„ÅÆÁ¢∫Ë™ç
  if (typeof window !== 'undefined') {
    console.log('‚ö†Ô∏è „Éñ„É©„Ç¶„Ç∂Áí∞Â¢É„Åß„ÅØÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì')
    return false
  }

  // „Éï„Ç°„Ç§„É´„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ¢∫Ë™ç
  try {
    const fs = await import('fs')
    const path = await import('path')
    
    // „É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅÆÁ¢∫Ë™ç
    const modelPath = './models/unsloth/Qwen2.5-Omni-3B-GGUF/Qwen2.5-Omni-3B-Q4_K_M.gguf'
    if (fs.existsSync(modelPath)) {
      console.log('‚úÖ Qwen2.5-Omni 3B model file found')
    } else {
      console.log('‚ö†Ô∏è Qwen2.5-Omni 3B model file not found')
      console.log('   Please download from: https://huggingface.co/unsloth/Qwen2.5-Omni-3B-GGUF')
      console.log('   Expected path:', path.resolve(modelPath))
    }

    // „Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆÁ¢∫Ë™ç
    const modelDir = './models/unsloth/Qwen2.5-Omni-3B-GGUF'
    if (fs.existsSync(modelDir)) {
      console.log('‚úÖ Model directory exists')
      const files = fs.readdirSync(modelDir)
      console.log('üìÅ Available files:', files)
    } else {
      console.log('‚ö†Ô∏è Model directory not found')
    }

    return true
  } catch (error) {
    console.error('‚ùå Environment check failed:', error)
    return false
  }
}

// „É°„Ç§„É≥ÂÆüË°å
if (require.main === module) {
  checkEnvironment().then((isReady) => {
    if (isReady) {
      main().catch(console.error)
    } else {
      console.log('‚ùå Environment is not ready for Qwen2.5-Omni 3B')
    }
  })
}

export { main, checkEnvironment }
