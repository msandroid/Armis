import { Qwen2_5OmniService } from '@/services/llm/qwen2.5-omni-service'

/**
 * Qwen2.5-Omni „É¢„Éá„É´„ÅÆ‰ΩøÁî®‰æã
 * 
 * „Åì„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„ÅØ„ÄÅQwen2.5-Omni„É¢„Éá„É´„Çí‰ΩøÁî®„Åó„Å¶„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´AIÊé®Ë´ñ„ÇíË°å„ÅÜÊñπÊ≥ï„ÇíÁ§∫„Åó„Åæ„Åô„ÄÇ
 * 
 * ÂâçÊèêÊù°‰ª∂:
 * 1. node-llama-cpp„Éë„ÉÉ„Ç±„Éº„Ç∏„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„Çã
 * 2. Qwen2.5-Omni GGUF„É¢„Éá„É´„Éï„Ç°„Ç§„É´„Åå./models/„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´ÈÖçÁΩÆ„Åï„Çå„Å¶„ÅÑ„Çã
 * 3. Node.jsÁí∞Â¢É„ÅßÂÆüË°å„Åï„Çå„ÇãÔºà„Éñ„É©„Ç¶„Ç∂„Åß„ÅØÂãï‰Ωú„Åó„Åæ„Åõ„ÇìÔºâ
 */

async function main() {
  console.log('üöÄ Qwen2.5-Omni ‰ΩøÁî®‰æã„ÇíÈñãÂßã„Åó„Åæ„Åô...')

  // Qwen2.5-Omni„Çµ„Éº„Éì„Çπ„ÅÆÂàùÊúüÂåñ
  const qwenOmniService = new Qwen2_5OmniService({
    modelPath: './models/unsloth/Qwen2.5-Omni-7B-GGUF/Qwen2.5-Omni-7B-Q4_K_M.gguf',
    temperature: 0.7,
    maxTokens: 2048,
    topP: 0.9,
    topK: 40,
    contextSize: 32768,
    threads: 4,
    gpuLayers: 0,
    verbose: false,
    enableAudioOutput: false, // Èü≥Â£∞Âá∫Âäõ„ÅØÁèæÂú®Êú™ÂÆüË£Ö
    speaker: 'Chelsie',
    useAudioInVideo: true
  })

  try {
    // „Çµ„Éº„Éì„Çπ„ÅÆÂàùÊúüÂåñ
    console.log('üì• Qwen2.5-Omni„Çµ„Éº„Éì„Çπ„ÇíÂàùÊúüÂåñ‰∏≠...')
    await qwenOmniService.initialize()
    console.log('‚úÖ Qwen2.5-Omni„Çµ„Éº„Éì„Çπ„ÅåÂàùÊúüÂåñ„Åï„Çå„Åæ„Åó„Åü')

    // Âü∫Êú¨ÁöÑ„Å™„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê
    console.log('\nüìù Âü∫Êú¨ÁöÑ„Å™„ÉÜ„Ç≠„Çπ„ÉàÁîüÊàê„ÉÜ„Çπ„Éà...')
    const basicResponse = await qwenOmniService.generateResponse(
      "Hello! I am Qwen2.5-Omni, a multimodal AI model. Can you tell me about your capabilities?"
    )
    console.log('ü§ñ ÂøúÁ≠î:', basicResponse.text)
    console.log(`‚è±Ô∏è ÁîüÊàêÊôÇÈñì: ${basicResponse.duration}ms`)
    console.log(`üî¢ „Éà„Éº„ÇØ„É≥Êï∞: ${basicResponse.tokens}`)

    // „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´‰ºöË©±„ÅÆ‰æã
    console.log('\nüñºÔ∏è „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´‰ºöË©±„ÉÜ„Çπ„Éà...')
    const multimodalConversation = [
      {
        role: 'system' as const,
        content: [
          {
            type: 'text' as const,
            text: 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'
          }
        ]
      },
      {
        role: 'user' as const,
        content: [
          {
            type: 'text' as const,
            text: 'Hello! I have an image and some audio. Can you help me understand what you see and hear?'
          },
          {
            type: 'image' as const,
            image: '/path/to/image.jpg'
          },
          {
            type: 'audio' as const,
            audio: '/path/to/audio.wav'
          }
        ]
      }
    ]

    const multimodalResponse = await qwenOmniService.generateMultimodalResponse(
      multimodalConversation,
      {
        returnAudio: false,
        speaker: 'Ethan',
        useAudioInVideo: true
      }
    )
    console.log('ü§ñ „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂøúÁ≠î:', multimodalResponse.text)
    console.log(`üé§ „Çπ„Éî„Éº„Ç´„Éº: ${multimodalResponse.speaker}`)

    // Èü≥Â£∞ÁîüÊàê„ÅÆ„ÉÜ„Çπ„ÉàÔºàÁèæÂú®„ÅØ„Éó„É¨„Éº„Çπ„Éõ„É´„ÉÄ„ÉºÔºâ
    console.log('\nüé§ Èü≥Â£∞ÁîüÊàê„ÉÜ„Çπ„Éà...')
    const audioResponse = await qwenOmniService.generateAudio(
      "Hello! This is a test of audio generation with Qwen2.5-Omni.",
      'Chelsie'
    )
    if (audioResponse) {
      console.log('‚úÖ Èü≥Â£∞„ÅåÁîüÊàê„Åï„Çå„Åæ„Åó„Åü')
    } else {
      console.log('‚ö†Ô∏è Èü≥Â£∞ÁîüÊàê„ÅØÁèæÂú®Êú™ÂÆüË£Ö„Åß„Åô')
    }

    // Ë®≠ÂÆö„ÅÆÂ§âÊõ¥
    console.log('\n‚öôÔ∏è Ë®≠ÂÆöÂ§âÊõ¥„ÉÜ„Çπ„Éà...')
    qwenOmniService.setSpeaker('Ethan')
    qwenOmniService.enableAudioOutput()
    
    const config = qwenOmniService.getConfig()
    console.log('üìã ÁèæÂú®„ÅÆË®≠ÂÆö:', {
      speaker: config.speaker,
      enableAudioOutput: config.enableAudioOutput,
      temperature: config.temperature,
      contextSize: config.contextSize
    })

    // Ë§áÈõë„Å™‰ºöË©±„ÅÆ‰æã
    console.log('\nüí¨ Ë§áÈõë„Å™‰ºöË©±„ÉÜ„Çπ„Éà...')
    const complexConversation = [
      {
        role: 'system' as const,
        content: 'You are Qwen2.5-Omni, a helpful AI assistant with multimodal capabilities.'
      },
      {
        role: 'user' as const,
        content: 'Can you help me with a coding problem? I need to create a function that sorts an array of numbers.'
      },
      {
        role: 'assistant' as const,
        content: 'Of course! I can help you with coding problems. Here\'s a simple function to sort an array of numbers in JavaScript:'
      },
      {
        role: 'user' as const,
        content: 'Great! Can you also explain how the sorting algorithm works?'
      }
    ]

    const complexResponse = await qwenOmniService.generateMultimodalResponse(complexConversation)
    console.log('ü§ñ Ë§áÈõë„Å™‰ºöË©±ÂøúÁ≠î:', complexResponse.text)

    console.log('\n‚úÖ Qwen2.5-Omni ‰ΩøÁî®‰æã„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ')

  } catch (error) {
    console.error('‚ùå „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü:', error)
  }
}

// Áí∞Â¢É„ÉÅ„Çß„ÉÉ„ÇØÈñ¢Êï∞
async function checkEnvironment() {
  console.log('üîç Qwen2.5-Omni Áí∞Â¢É„ÉÅ„Çß„ÉÉ„ÇØ‰∏≠...')
  
  try {
    // Node.jsÁí∞Â¢É„ÅÆÁ¢∫Ë™ç
    if (typeof window !== 'undefined') {
      console.log('‚ùå „Éñ„É©„Ç¶„Ç∂Áí∞Â¢É„Åß„ÅØÂÆüË°å„Åß„Åç„Åæ„Åõ„Çì')
      return false
    }
    console.log('‚úÖ Node.jsÁí∞Â¢É„ÇíÁ¢∫Ë™ç')

    // node-llama-cpp„ÅÆÁ¢∫Ë™ç
    try {
      const nodeLlamaCpp = await import('node-llama-cpp')
      console.log('‚úÖ node-llama-cpp package available')
    } catch (error) {
      console.log('‚ùå node-llama-cpp package not found')
      console.log('   Install with: npm install node-llama-cpp@3')
      return false
    }

    // „Éï„Ç°„Ç§„É´„Ç∑„Çπ„ÉÜ„É†„ÅÆÁ¢∫Ë™ç
    const fs = await import('fs')
    const path = await import('path')
    console.log('‚úÖ File system access available')

    // „É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅÆÁ¢∫Ë™ç
    const modelPath = './models/unsloth/Qwen2.5-Omni-7B-GGUF/Qwen2.5-Omni-7B-Q4_K_M.gguf'
    if (fs.existsSync(modelPath)) {
      console.log('‚úÖ Qwen2.5-Omni model file found')
    } else {
      console.log('‚ö†Ô∏è Qwen2.5-Omni model file not found')
      console.log('   Please download from: https://huggingface.co/unsloth/Qwen2.5-Omni-7B-GGUF')
      console.log('   Expected path:', path.resolve(modelPath))
    }

    return true
  } catch (error) {
    console.error('‚ùå Environment check failed:', error)
    return false
  }
}

// „É°„Ç§„É≥ÂÆüË°å
if (require.main === module) {
  checkEnvironment().then((isReady) => {
    if (isReady) {
      main()
    } else {
      console.log('‚ùå Environment is not ready for Qwen2.5-Omni')
      process.exit(1)
    }
  })
}

export { main, checkEnvironment }
