

export interface HuggingFaceOllamaModel {
  id: string
  name: string
  description: string
  downloads: number
  likes: number
  tags: string[]
  model_type: string
  size: number
  format: string
  quantization: string
  updated_at: string
  author: string
  parameter_size?: string
  family?: string
}

export interface OllamaModelSearchOptions {
  query?: string
  limit?: number
  sort?: 'trending' | 'downloads' | 'likes' | 'updated'
  direction?: 'asc' | 'desc'
}

export class HuggingFaceOllamaService {
  private baseUrl = 'https://huggingface.co/api'
  private modelsCache: HuggingFaceOllamaModel[] = []
  private lastFetchTime: number = 0
  private cacheDuration = 5 * 60 * 1000 // 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥

  /**
   * Ollamaå¯¾å¿œãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢ã—ã¦å–å¾—
   */
  async searchOllamaModels(options: OllamaModelSearchOptions = {}): Promise<HuggingFaceOllamaModel[]> {
    const {
      query = '',
      limit = 50,
      sort = 'trending',
      direction = 'desc'
    } = options

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¿”ã™
    if (this.isCacheValid()) {
      return this.filterCachedModels(query, limit)
    }

    try {
      console.log(`ğŸ” Searching for Ollama models with query: "${query}"`)

      // Hugging Face APIã§GGUFãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
      const searchParams = new URLSearchParams({
        search: query ? `${query} gguf` : 'gguf',
        sort: sort,
        direction: direction === 'desc' ? '-1' : '1',
        limit: limit.toString()
      })

      const response = await fetch(`${this.baseUrl}/models?${searchParams}`)
      
      if (!response.ok) {
        throw new Error(`Failed to fetch models: ${response.status} ${response.statusText}`)
      }

      const data = await response.json()
      const models: HuggingFaceOllamaModel[] = []

      for (const model of data) {
        // GGUFã‚¿ã‚°ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        const hasGGUFTag = model.tags?.some((tag: string) => 
          tag.toLowerCase().includes('gguf')
        )

        if (hasGGUFTag) {
          // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’æŠ½å‡º
          const parameterSize = this.extractParameterSize(model.id, model.tags)
          
          // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æŠ½å‡º
          const family = this.extractModelFamily(model.id, model.tags)

          // é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ã‚’æŠ½å‡º
          const quantization = this.extractQuantization(model.id, model.tags)

          models.push({
            id: model.id,
            name: model.modelId || model.id,
            description: model.description || 'No description available',
            downloads: model.downloads || 0,
            likes: model.likes || 0,
            tags: model.tags || [],
            model_type: model.model_type || 'unknown',
            size: 0, // APIã‹ã‚‰ã¯ç›´æ¥å–å¾—ã§ããªã„ãŸã‚0ã«è¨­å®š
            format: 'GGUF',
            quantization: quantization,
            updated_at: model.lastModified || new Date().toISOString(),
            author: model.author || 'unknown',
            parameter_size: parameterSize,
            family: family
          })
        }
      }

      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
      this.modelsCache = models
      this.lastFetchTime = Date.now()

      console.log(`âœ… Found ${models.length} Ollama models`)
      return models

    } catch (error) {
      console.error('Error fetching Ollama models:', error)
      throw error
    }
  }

  /**
   * äººæ°—ã®Ollamaãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
   */
  async getPopularOllamaModels(limit: number = 20): Promise<HuggingFaceOllamaModel[]> {
    return this.searchOllamaModels({
      limit,
      sort: 'downloads',
      direction: 'desc'
    })
  }

  /**
   * ãƒˆãƒ¬ãƒ³ãƒ‰ã®Ollamaãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
   */
  async getTrendingOllamaModels(limit: number = 20): Promise<HuggingFaceOllamaModel[]> {
    return this.searchOllamaModels({
      limit,
      sort: 'trending',
      direction: 'desc'
    })
  }

  /**
   * ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œç´¢
   */
  async searchModelsByFamily(family: string, limit: number = 20): Promise<HuggingFaceOllamaModel[]> {
    const models = await this.searchOllamaModels({ limit: 100 })
    return models
      .filter(model => 
        model.family?.toLowerCase().includes(family.toLowerCase()) ||
        model.name.toLowerCase().includes(family.toLowerCase())
      )
      .slice(0, limit)
  }

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
   */
  private isCacheValid(): boolean {
    return Date.now() - this.lastFetchTime < this.cacheDuration
  }

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
   */
  private filterCachedModels(query: string, limit: number): HuggingFaceOllamaModel[] {
    if (!query) {
      return this.modelsCache.slice(0, limit)
    }

    const filtered = this.modelsCache.filter(model =>
      model.name.toLowerCase().includes(query.toLowerCase()) ||
      model.description.toLowerCase().includes(query.toLowerCase()) ||
      model.tags.some(tag => tag.toLowerCase().includes(query.toLowerCase()))
    )

    return filtered.slice(0, limit)
  }

  /**
   * ãƒ¢ãƒ‡ãƒ«IDã¨ã‚¿ã‚°ã‹ã‚‰é‡å­åŒ–ãƒ¬ãƒ™ãƒ«ã‚’æŠ½å‡º
   */
  private extractQuantization(modelId: string, tags: string[]): string {
    const quantizationPatterns = [
      /Q2_K/, /Q3_K/, /Q4_K/, /Q5_K/, /Q6_K/, /Q8_K/,
      /Q2/, /Q3/, /Q4/, /Q5/, /Q6/, /Q8/,
      /F16/, /F32/, /BF16/
    ]

    // ãƒ¢ãƒ‡ãƒ«IDã‹ã‚‰æ¤œç´¢
    for (const pattern of quantizationPatterns) {
      if (pattern.test(modelId)) {
        return pattern.source.replace(/[\/\\]/g, '')
      }
    }

    // ã‚¿ã‚°ã‹ã‚‰æ¤œç´¢
    for (const tag of tags) {
      for (const pattern of quantizationPatterns) {
        if (pattern.test(tag)) {
          return pattern.source.replace(/[\/\\]/g, '')
        }
      }
    }

    return 'unknown'
  }

  /**
   * ãƒ¢ãƒ‡ãƒ«IDã¨ã‚¿ã‚°ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’æŠ½å‡º
   */
  private extractParameterSize(modelId: string, tags: string[]): string {
    const sizePatterns = [
      /(\d+(?:\.\d+)?)b/i,
      /(\d+(?:\.\d+)?)B/i,
      /(\d+(?:\.\d+)?)billion/i
    ]

    // ãƒ¢ãƒ‡ãƒ«IDã‹ã‚‰æ¤œç´¢
    for (const pattern of sizePatterns) {
      const match = modelId.match(pattern)
      if (match) {
        return `${match[1]}B`
      }
    }

    // ã‚¿ã‚°ã‹ã‚‰æ¤œç´¢
    for (const tag of tags) {
      for (const pattern of sizePatterns) {
        const match = tag.match(pattern)
        if (match) {
          return `${match[1]}B`
        }
      }
    }

    return 'unknown'
  }

  /**
   * ãƒ¢ãƒ‡ãƒ«IDã¨ã‚¿ã‚°ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æŠ½å‡º
   */
  private extractModelFamily(modelId: string, tags: string[]): string {
    const familyPatterns = [
      /llama/i,
      /gemma/i,
      /qwen/i,
      /deepseek/i,
      /mistral/i,
      /phi/i,
      /llava/i,
      /codellama/i,
      /vicuna/i,
      /alpaca/i
    ]

    // ãƒ¢ãƒ‡ãƒ«IDã‹ã‚‰æ¤œç´¢
    for (const pattern of familyPatterns) {
      if (pattern.test(modelId)) {
        return pattern.source.replace(/[\/\\]/g, '').toLowerCase()
      }
    }

    // ã‚¿ã‚°ã‹ã‚‰æ¤œç´¢
    for (const tag of tags) {
      for (const pattern of familyPatterns) {
        if (pattern.test(tag)) {
          return pattern.source.replace(/[\/\\]/g, '').toLowerCase()
        }
      }
    }

    return 'unknown'
  }

  /**
   * ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
   */
  clearCache(): void {
    this.modelsCache = []
    this.lastFetchTime = 0
  }

  /**
   * ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
   */
  formatFileSize(bytes: number): string {
    if (bytes === 0) return '0 B'
    const k = 1024
    const sizes = ['B', 'KB', 'MB', 'GB', 'TB']
    const i = Math.floor(Math.log(bytes) / Math.log(k))
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i]
  }

  /**
   * æ—¥ä»˜ã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
   */
  formatDate(dateString: string): string {
    return new Date(dateString).toLocaleDateString('ja-JP', {
      year: 'numeric',
      month: 'short',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit'
    })
  }
}
