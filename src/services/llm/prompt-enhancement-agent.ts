import { ChatPromptTemplate } from '@langchain/core/prompts'
import { RunnableSequence } from '@langchain/core/runnables'
import { StructuredOutputParser } from '@langchain/core/output_parsers'
import { z } from 'zod'
import { LlamaService } from './llama-service'
import { OllamaService } from './ollama-service'

/**
 * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè£œå®Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­å®š
 */
export interface PromptEnhancementConfig {
  llmService: LlamaService | OllamaService
  enableQualityEvaluation?: boolean
  enableStyleTransfer?: boolean
  enableMultiLanguage?: boolean
}

/**
 * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè§£æçµæœ
 */
export interface PromptAnalysis {
  subject: string
  style: string
  mood: string
  composition: string
  lighting: string
  colorPalette: string
  details: string[]
  missingElements: string[]
  confidence: number
  suggestions: string[]
}

/**
 * å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
 */
export interface EnhancedPrompt {
  originalPrompt: string
  enhancedPrompt: string
  englishPrompt: string
  style: string
  quality: string
  metadata: {
    analysis: PromptAnalysis
    generationTime: string
    model: string
  }
}

/**
 * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡
 */
export interface PromptQualityEvaluation {
  clarity: number
  specificity: number
  creativity: number
  technicalAccuracy: number
  overallScore: number
  feedback: string
  recommendations: string[]
}

/**
 * LangChainãƒ™ãƒ¼ã‚¹ã®ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè£œå®Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
 * T2I-Copilotã®æ¦‚å¿µã‚’å–ã‚Šå…¥ã‚ŒãŸä¸‰æ®µæ§‹æˆã‚’å®Ÿè£…
 */
export class PromptEnhancementAgent {
  private config: PromptEnhancementConfig
  private inputInterpreter!: RunnableSequence
  private generationEngine!: RunnableSequence
  private qualityEvaluator!: RunnableSequence

  constructor(config: PromptEnhancementConfig) {
    this.config = config
    this.initializeChains()
  }

  /**
   * LangChainãƒã‚§ã‚¤ãƒ³ã‚’åˆæœŸåŒ–
   */
  private initializeChains() {
    // Step 1: Input Interpreter - å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è§£æ
    this.inputInterpreter = this.createInputInterpreter()
    
    // Step 2: Generation Engine - å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ
    this.generationEngine = this.createGenerationEngine()
    
    // Step 3: Quality Evaluator - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªã®è©•ä¾¡
    this.qualityEvaluator = this.createQualityEvaluator()
  }

  /**
   * Input Interpreterãƒã‚§ã‚¤ãƒ³ã‚’ä½œæˆ
   * å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ›–æ˜§ã•ã‚’æ•´ç†ã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸåˆ†æçµæœã‚’ç”Ÿæˆ
   */
  private createInputInterpreter(): RunnableSequence {
    const promptAnalysisParser = StructuredOutputParser.fromZodSchema(
      z.object({
        subject: z.string().describe("ç”»åƒã®ä¸»ãªè¢«å†™ä½“ã‚„ä¸»é¡Œ"),
        style: z.string().describe("ç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆrealistic, artistic, cartoon, abstractç­‰ï¼‰"),
        mood: z.string().describe("ç”»åƒã®é›°å›²æ°—ã‚„æ„Ÿæƒ…ï¼ˆpeaceful, dramatic, mysteriousç­‰ï¼‰"),
        composition: z.string().describe("æ§‹å›³ã®èª¬æ˜ï¼ˆclose-up, wide shot, portraitç­‰ï¼‰"),
        lighting: z.string().describe("ç…§æ˜ã®èª¬æ˜ï¼ˆnatural, dramatic, softç­‰ï¼‰"),
        colorPalette: z.string().describe("è‰²èª¿ã®èª¬æ˜ï¼ˆwarm, cool, monochromeç­‰ï¼‰"),
        details: z.array(z.string()).describe("è¿½åŠ ã™ã¹ãè©³ç´°è¦ç´ ã®ãƒªã‚¹ãƒˆ"),
        missingElements: z.array(z.string()).describe("ä¸è¶³ã—ã¦ã„ã‚‹è¦ç´ ã®ãƒªã‚¹ãƒˆ"),
        confidence: z.number().min(0).max(1).describe("è§£æã®ä¿¡é ¼åº¦"),
        suggestions: z.array(z.string()).describe("æ”¹å–„ææ¡ˆã®ãƒªã‚¹ãƒˆ")
      })
    )

    const prompt = ChatPromptTemplate.fromTemplate(`
ã‚ãªãŸã¯ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å°‚é–€åˆ†æè€…ã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è©³ç´°ã«è§£æã—ã€ç”»åƒç”Ÿæˆã«å¿…è¦ãªè¦ç´ ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

## å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
{input}

## è§£æã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
1. **ä¸»é¡Œã®ç‰¹å®š**: ä½•ã‚’æãã¹ãã‹ã‚’æ˜ç¢ºã«ã™ã‚‹
2. **ã‚¹ã‚¿ã‚¤ãƒ«ã®æ±ºå®š**: ãƒªã‚¢ãƒ«ã€ã‚¢ãƒ¼ãƒˆã€ã‚«ãƒ¼ãƒˆãƒ¼ãƒ³ã€æŠ½è±¡ãªã©
3. **é›°å›²æ°—ã®è¨­å®š**: æ„Ÿæƒ…ã‚„ãƒ ãƒ¼ãƒ‰ã‚’è¡¨ç¾
4. **æŠ€è¡“çš„è¦ç´ **: æ§‹å›³ã€ç…§æ˜ã€è‰²èª¿ã‚’æŒ‡å®š
5. **ä¸è¶³è¦ç´ ã®ç‰¹å®š**: ã‚ˆã‚Šè‰¯ã„ç”»åƒç”Ÿæˆã«å¿…è¦ãªè¿½åŠ æƒ…å ±

## å‡ºåŠ›å½¢å¼
{format_instructions}

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä¸å®Œå…¨ãªå ´åˆï¼ˆä¾‹ï¼šã€Œã‚³ã‚¢ãƒ©ã®ã—ã¦ãã ã•ã„ã€‚ã€ï¼‰ã¯ã€é©åˆ‡ãªè£œå®Œã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
`)

    const inputMapper = {
      input: (input: any) => input.prompt,
      format_instructions: () => promptAnalysisParser.getFormatInstructions()
    }

    return RunnableSequence.from([
      inputMapper,
      prompt,
      this.config.llmService.getModel(),
      promptAnalysisParser
    ])
  }

  /**
   * Generation Engineãƒã‚§ã‚¤ãƒ³ã‚’ä½œæˆ
   * è§£æçµæœã‚’åŸºã«å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
   */
  private createGenerationEngine(): RunnableSequence {
    const enhancedPromptParser = StructuredOutputParser.fromZodSchema(
      z.object({
        enhancedPrompt: z.string().describe("å¼·åŒ–ã•ã‚ŒãŸæ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"),
        englishPrompt: z.string().describe("è‹±èªç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆGemini APIç”¨ï¼‰"),
        style: z.string().describe("é©ç”¨ã•ã‚ŒãŸã‚¹ã‚¿ã‚¤ãƒ«"),
        quality: z.string().describe("å“è³ªè¨­å®šï¼ˆstandard, high, ultraï¼‰"),
        reasoning: z.string().describe("å¼·åŒ–ã®ç†ç”±ã¨èª¬æ˜")
      })
    )

    const prompt = ChatPromptTemplate.fromTemplate(`
ã‚ãªãŸã¯ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å°‚é–€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
è§£æçµæœã‚’åŸºã«ã€é«˜å“è³ªãªç”»åƒç”Ÿæˆã®ãŸã‚ã®å¼·åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè§£æçµæœ
{analysis}

## å¼·åŒ–ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
1. **å…·ä½“çš„ãªè©³ç´°**: æ›–æ˜§ãªè¡¨ç¾ã‚’å…·ä½“çš„ã«
2. **æŠ€è¡“çš„è¦ç´ **: ç…§æ˜ã€æ§‹å›³ã€è‰²èª¿ã‚’æ˜ç¤º
3. **ã‚¹ã‚¿ã‚¤ãƒ«çµ±ä¸€**: ä¸€è²«ã—ãŸã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¶­æŒ
4. **è‹±èªå¤‰æ›**: Gemini APIç”¨ã®è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚ç”Ÿæˆ
5. **å“è³ªæœ€é©åŒ–**: ç”Ÿæˆå“è³ªã‚’å‘ä¸Šã•ã›ã‚‹è¦ç´ ã‚’è¿½åŠ 

## å‡ºåŠ›å½¢å¼
{format_instructions}

å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ„å›³ã‚’ä¿æŒã—ãªãŒã‚‰ã€ã‚ˆã‚Šè©³ç´°ã§åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚
`)

    const analysisMapper = {
      analysis: (input: any) => JSON.stringify(input.analysis, null, 2),
      format_instructions: () => enhancedPromptParser.getFormatInstructions()
    }

    return RunnableSequence.from([
      analysisMapper,
      prompt,
      this.config.llmService.getModel(),
      enhancedPromptParser
    ])
  }

  /**
   * Quality Evaluatorãƒã‚§ã‚¤ãƒ³ã‚’ä½œæˆ
   * ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã‚’è©•ä¾¡
   */
  private createQualityEvaluator(): RunnableSequence {
    const qualityEvaluationParser = StructuredOutputParser.fromZodSchema(
      z.object({
        clarity: z.number().min(0).max(10).describe("æ˜ç¢ºæ€§ã®ã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰"),
        specificity: z.number().min(0).max(10).describe("å…·ä½“æ€§ã®ã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰"),
        creativity: z.number().min(0).max(10).describe("å‰µé€ æ€§ã®ã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰"),
        technicalAccuracy: z.number().min(0).max(10).describe("æŠ€è¡“çš„ç²¾åº¦ã®ã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰"),
        overallScore: z.number().min(0).max(10).describe("ç·åˆã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰"),
        feedback: z.string().describe("å“è³ªè©•ä¾¡ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"),
        recommendations: z.array(z.string()).describe("æ”¹å–„æ¨å¥¨äº‹é …ã®ãƒªã‚¹ãƒˆ")
      })
    )

    const prompt = ChatPromptTemplate.fromTemplate(`
ã‚ãªãŸã¯ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªè©•ä¾¡å°‚é–€å®¶ã§ã™ã€‚
ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã‚’å¤šè§’çš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

## å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
{originalPrompt}

## å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
{enhancedPrompt}

## è©•ä¾¡åŸºæº–
1. **æ˜ç¢ºæ€§**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæ˜ç¢ºã§ç†è§£ã—ã‚„ã™ã„ã‹
2. **å…·ä½“æ€§**: ååˆ†ã«å…·ä½“çš„ã§è©³ç´°ã‹
3. **å‰µé€ æ€§**: ç‹¬å‰µçš„ã§é­…åŠ›çš„ãªè¦ç´ ãŒã‚ã‚‹ã‹
4. **æŠ€è¡“çš„ç²¾åº¦**: ç”»åƒç”ŸæˆæŠ€è¡“ã«é©ã—ã¦ã„ã‚‹ã‹

## å‡ºåŠ›å½¢å¼
{format_instructions}

å„é …ç›®ã‚’0-10ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã€å…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ”¹å–„ææ¡ˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
`)

    const qualityMapper = {
      originalPrompt: (input: any) => input.originalPrompt,
      enhancedPrompt: (input: any) => input.enhancedPrompt,
      format_instructions: () => qualityEvaluationParser.getFormatInstructions()
    }

    return RunnableSequence.from([
      qualityMapper,
      prompt,
      this.config.llmService.getModel(),
      qualityEvaluationParser
    ])
  }

  /**
   * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–ã™ã‚‹
   */
  async enhancePrompt(inputPrompt: string): Promise<EnhancedPrompt> {
    try {
      console.log('ğŸ”„ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–é–‹å§‹:', inputPrompt)

      // Step 1: Input Interpreter - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè§£æ
      const analysis = await this.inputInterpreter.invoke({ prompt: inputPrompt })
      console.log('ğŸ“Š ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè§£æå®Œäº†:', analysis)

      // Step 2: Generation Engine - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–
      const enhanced = await this.generationEngine.invoke({ analysis })
      console.log('âœ¨ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–å®Œäº†:', enhanced)

      // Step 3: Quality Evaluator - å“è³ªè©•ä¾¡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
      let qualityEvaluation: PromptQualityEvaluation | null = null
      if (this.config.enableQualityEvaluation) {
        const evaluation = await this.qualityEvaluator.invoke({
          originalPrompt: inputPrompt,
          enhancedPrompt: enhanced.enhancedPrompt
        })
        qualityEvaluation = evaluation
        console.log('ğŸ“ˆ å“è³ªè©•ä¾¡å®Œäº†:', evaluation)
      }

      const result: EnhancedPrompt = {
        originalPrompt: inputPrompt,
        enhancedPrompt: enhanced.enhancedPrompt,
        englishPrompt: enhanced.englishPrompt,
        style: enhanced.style,
        quality: enhanced.quality,
        metadata: {
          analysis,
          generationTime: new Date().toISOString(),
          model: this.config.llmService.getModelName()
        }
      }

      console.log('âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–å®Œäº†')
      return result

    } catch (error) {
      console.error('âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–ã‚¨ãƒ©ãƒ¼:', error)
      throw new Error(`ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¼·åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }
  }

  /**
   * è¤‡æ•°ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå€™è£œã‚’ç”Ÿæˆ
   */
  async generatePromptVariations(inputPrompt: string, count: number = 3): Promise<EnhancedPrompt[]> {
    const variations: EnhancedPrompt[] = []
    
    for (let i = 0; i < count; i++) {
      try {
        const variation = await this.enhancePrompt(inputPrompt)
        variations.push(variation)
      } catch (error) {
        console.error(`ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ ${i + 1} ã®ç”Ÿæˆã«å¤±æ•—:`, error)
      }
    }

    return variations
  }

  /**
   * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã‚’è©•ä¾¡
   */
  async evaluatePromptQuality(prompt: string): Promise<PromptQualityEvaluation> {
    try {
      const evaluation = await this.qualityEvaluator.invoke({
        originalPrompt: prompt,
        enhancedPrompt: prompt
      })
      return evaluation
    } catch (error) {
      console.error('âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼:', error)
      throw new Error(`ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªè©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }
  }

  /**
   * ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€æ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
   */
  async applyStyleTransfer(prompt: string, targetStyle: string): Promise<string> {
    if (!this.config.enableStyleTransfer) {
      throw new Error('ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€æ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™')
    }

    const styleTransferPrompt = ChatPromptTemplate.fromTemplate(`
ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã€Œ{targetStyle}ã€ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

## å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
{originalPrompt}

## ç›®æ¨™ã‚¹ã‚¿ã‚¤ãƒ«
{targetStyle}

## å¤‰æ›ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
- å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸»é¡Œã¯ä¿æŒ
- ã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´ã‚’åæ˜ 
- è‡ªç„¶ã§ä¸€è²«ã—ãŸè¡¨ç¾ã«å¤‰æ›

å¤‰æ›ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
`)

    try {
      const result = await RunnableSequence.from([
        {
          originalPrompt: () => prompt,
          targetStyle: () => targetStyle
        },
        styleTransferPrompt,
        this.config.llmService.getModel()
      ]).invoke({})

      return result.content as string
    } catch (error) {
      console.error('âŒ ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€ã‚¨ãƒ©ãƒ¼:', error)
      throw new Error(`ã‚¹ã‚¿ã‚¤ãƒ«è»¢é€ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }
  }
}
